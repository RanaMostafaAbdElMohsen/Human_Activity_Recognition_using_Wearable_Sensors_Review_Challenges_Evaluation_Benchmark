{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HaChoi_2016_Paper.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP25/IMJWmTfKfAyi1NwZ0J"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ma0B8-JvDUAR","colab_type":"code","colab":{}},"source":["36## Ha Choi 2016 Paper\n","## Doi : 10.1109/IJCNN.2016.7727224"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x0i_S4fSHNlV","colab_type":"code","colab":{}},"source":["##Libraries\n","import sys\n","import numpy as np\n","import random\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","from sklearn.metrics.classification import accuracy_score, recall_score, f1_score\n","import scipy.stats as st\n","\n","from keras.layers import Input, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, Activation, concatenate, merge\n","from keras.callbacks import ReduceLROnPlateau, EarlyStopping, Callback\n","from keras.models import Model\n","from keras import backend as K\n","K.set_image_data_format('channels_first')\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MyMm9X7Vieu4","colab_type":"code","colab":{}},"source":["!pip install tensorflow==1.5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uIM8m6yfIqRd","colab_type":"code","colab":{}},"source":["!pip install numpy==1.16.1\n","!pip install keras==2.1.2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ziG0oowHIRtz","colab_type":"code","outputId":"49d3799b-0af5-4b70-f0d8-6caaf96a2a3e","executionInfo":{"status":"ok","timestamp":1586071168259,"user_tz":-120,"elapsed":23855,"user":{"displayName":"Rana mostafa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpLWLhJYcXKOOp7sprSKwnxN-x9hYM61yh__9kww=s64","userId":"07598775866819373078"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gT_QEBACIUDB","colab_type":"code","outputId":"fe92b6bd-3945-48d1-e453-95cf6e923da7","executionInfo":{"status":"ok","timestamp":1586071171892,"user_tz":-120,"elapsed":3618,"user":{"displayName":"Rana mostafa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpLWLhJYcXKOOp7sprSKwnxN-x9hYM61yh__9kww=s64","userId":"07598775866819373078"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","os.chdir(\"/content/drive/\")\n","!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["'My Drive'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gtqu-f8JIWZ1","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"My Drive/Computer_Vision_Masters/Wearable_Sensors_Code/\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-_A0DPqHz8K","colab_type":"code","colab":{}},"source":["def custom_model(X, idx_modalities, n_classes):\n","    img_cols1 = idx_modalities[0]\n","    img_cols2 = idx_modalities[1] - idx_modalities[0]\n","    img_cols3 = idx_modalities[2] - idx_modalities[1]\n","    img_cols4 = X.shape[3] - idx_modalities[2]\n","\n","    _, _, img_rows, img_cols = X.shape\n","    inp_modality1 = Input((1, img_rows, img_cols1))\n","    inp_modality2 = Input((1, img_rows, img_cols2))\n","    inp_modality3 = Input((1, img_rows, img_cols3))\n","    inp_modality4 = Input((1, img_rows, img_cols4))\n","\n","    H1 = Conv2D(filters=5, kernel_size=(5, 5))(inp_modality1)\n","    H1 = Activation('relu')(H1)\n","    H1 = MaxPooling2D(pool_size=(4, 4))(H1)\n","\n","    H2 = Conv2D(filters=5, kernel_size=(5, 5))(inp_modality2)\n","    H2 = Activation('relu')(H2)\n","    H2 = MaxPooling2D(pool_size=(4, 4))(H2)\n","\n","    H3 = Conv2D(filters=5, kernel_size=(5, 5))(inp_modality3)\n","    H3 = Activation('relu')(H3)\n","    H3 = MaxPooling2D(pool_size=(4, 4))(H3)\n","\n","    # H4 = Conv2D(filters=5, kernel_size=(5, 3))(inp_modality4)#For PAMAP\n","    H4 = Conv2D(filters=5, kernel_size=(5, 2))(inp_modality4)  # For MEHEALTH\n","    H4 = Activation('relu')(H4)\n","    H4 = MaxPooling2D(pool_size=(4, 1))(H4)\n","\n","    shape_1 = int(H2.shape[1].value)\n","    shape_2 = int(H2.shape[2].value)\n","    shape_3 = int(H2.shape[3].value)\n","    inp_zeros = Input((shape_1, shape_2, shape_3))  # Here is the features map shape\n","\n","    H = concatenate([H1, inp_zeros, H2, inp_zeros, H3, inp_zeros, H4], axis=3)\n","\n","    H = Conv2D(filters=10, kernel_size=(5, 5))(H)\n","    H = Activation('relu')(H)\n","    H = MaxPooling2D(pool_size=(2, 2))(H)\n","\n","    H = Flatten()(H)\n","    H = Dense(120)(H)\n","    H = Activation('relu')(H)\n","\n","    H = Dense(n_classes)(H)\n","    H = Activation('softmax')(H)\n","\n","    model = Model([inp_modality1, inp_modality2, inp_modality3, inp_modality4, inp_zeros], H)\n","\n","    return model, (shape_1, shape_2, shape_3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tb_3xdyEH501","colab_type":"code","colab":{}},"source":["def zero_padding_MHEALTH(X):\n","    # Groups the heterogenous sensors for MHEALTH\n","    idx_modalities = []\n","    idx_acc = [0, 1, 2, 5, 6, 7, 14, 15, 16]\n","    idx_gyro = [8, 9, 10, 17, 18, 19]\n","    idx_mag = [11, 12, 13, 20, 21, 22]\n","    idx_ele = [3, 4]\n","    X_acc = X[:, :, :, idx_acc]\n","    X_gyro = X[:, :, :, idx_gyro]\n","    X_mag = X[:, :, :, idx_mag]\n","    X_ele = X[:, :, :, idx_ele]\n","    X_zeros = np.zeros((X.shape[0], X.shape[1], X.shape[2], 2))  # Vertical Kernel-1 = 2\n","\n","    X = X_acc\n","    X = np.concatenate((X, X_zeros), axis=3)\n","    idx_modalities.append(X.shape[3])\n","\n","    X = np.concatenate((X, X_gyro), axis=3)\n","    X = np.concatenate((X, X_zeros),axis=3)\n","    idx_modalities.append(X.shape[3])\n","\n","    X = np.concatenate((X, X_mag),axis=3)\n","    X = np.concatenate((X, X_zeros),axis=3)\n","    idx_modalities.append(X.shape[3])\n","    X = np.concatenate((X, X_ele),axis=3)\n","\n","    return X, idx_modalities\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T6LxK13QH_go","colab_type":"code","colab":{}},"source":["def split_X(X, idx_modalities, zeros):\n","    X_tmp = []\n","    X_tmp.append(X[:, :, :, 0:idx_modalities[0]])\n","    X_tmp.append(X[:, :, :, idx_modalities[0]:idx_modalities[1]])\n","    X_tmp.append(X[:, :, :, idx_modalities[1]:idx_modalities[2]])\n","    X_tmp.append(X[:, :, :, idx_modalities[2]:X.shape[3]])\n","    X_tmp.append(zeros)\n","    return X_tmp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HHJ-NT1EJkOj","colab_type":"code","colab":{}},"source":["def custom_stopping(value=0.5, verbose=0):\n","    early = EarlyStoppingByLossVal(monitor='val_loss', value=value, verbose=verbose)\n","    return early\n","\n","class EarlyStoppingByLossVal(Callback):\n","    def __init__(self, monitor='val_acc', value=0.95, verbose=0):\n","        super(Callback, self).__init__()\n","        self.monitor = monitor\n","        self.value = value\n","        self.verbose = verbose\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        current = logs.get(self.monitor)\n","        # if current is None:\n","        # warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n","\n","        if current < self.value:\n","            if self.verbose > 0:\n","                print(\"Epoch %05d: early stopping THR\" % epoch)\n","            self.model.stop_training = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rQxQC9JSIBH0","colab_type":"code","colab":{}},"source":["def DataPreparation(data_input_file):\n","  np.random.seed(12227)\n","\n","  tmp = np.load(data_input_file)\n","  X = tmp['X']\n","  y = tmp['y']\n","  folds = tmp['folds']\n","\n","  n_class = y.shape[1]\n","\n","  X, idx_modalities = zero_padding_MHEALTH(X)\n","\n","  _, _, img_rows, img_cols = X.shape\n","  return X, y, folds, idx_modalities,n_class"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GqJa3JcrINzT","colab_type":"code","colab":{}},"source":["def TrainAndReportAccuracies(X,y,folds,idx_modalities,n_class):\n","  avg_acc = []\n","  avg_recall = []\n","  avg_f1 = []\n","  for i in range(0, len(folds)):\n","      train_idx = folds[i][0]\n","      test_idx = folds[i][1]\n","\n","      X_train = X[train_idx]\n","      X_test = X[test_idx]\n","\n","      model, inp_zeros = custom_model(X, idx_modalities, n_classes=n_class)\n","\n","      zeros_mat = np.zeros((X_train.shape[0], inp_zeros[0], inp_zeros[1], inp_zeros[2]))\n","      model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='Adadelta')\n","\n","      X_train = split_X(X_train, idx_modalities, zeros_mat)\n","      print(\"Start Training\")\n","      model.fit(X_train, y[train_idx], batch_size=100, epochs=60,\n","                verbose=1, callbacks=[custom_stopping(value=0.2, verbose=1)], validation_data=(X_train, y[train_idx]))\n","\n","      X_test = split_X(X_test, idx_modalities, zeros_mat)\n","\n","      y_pred = model.predict(X_test)\n","      y_pred = np.argmax(y_pred, axis=1)\n","\n","      y_true = np.argmax(y[test_idx], axis=1)\n","\n","      acc_fold = accuracy_score(y_true, y_pred)\n","      avg_acc.append(acc_fold)\n","\n","      recall_fold = recall_score(y_true, y_pred, average='macro')\n","      avg_recall.append(recall_fold)\n","\n","      f1_fold = f1_score(y_true, y_pred, average='macro')\n","      avg_f1.append(f1_fold)\n","\n","      print('Accuracy[{:.4f}] Recall[{:.4f}] F1[{:.4f}] at fold[{}]'.format(acc_fold, recall_fold, f1_fold, i))\n","      print('______________________________________________________')\n","      del model\n","  ic_acc = st.t.interval(0.9, len(avg_acc) - 1, loc=np.mean(avg_acc), scale=st.sem(avg_acc))\n","  ic_recall = st.t.interval(0.9, len(avg_recall) - 1, loc=np.mean(avg_recall), scale=st.sem(avg_recall))\n","  ic_f1 = st.t.interval(0.9, len(avg_f1) - 1, loc=np.mean(avg_f1), scale=st.sem(avg_f1))\n","  print('Mean Accuracy[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_acc), ic_acc[0], ic_acc[1]))\n","  print('Mean Recall[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_recall), ic_recall[0], ic_recall[1]))\n","  print('Mean F1[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_f1), ic_f1[0], ic_f1[1]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HmuDoc-zPZSv","colab_type":"code","colab":{}},"source":["def Run(data_input_file):\n","  X, y, folds, idx_modalities,n_class= DataPreparation(data_input_file)\n","  TrainAndReportAccuracies(X,y,folds,idx_modalities,n_class)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LkwqOpe_0nOu","colab_type":"code","colab":{}},"source":["def WisdomDataPreparation(data_input_file):\n","    np.random.seed(12227)\n","\n","    tmp = np.load(data_input_file)\n","    X = tmp['X']\n","    y = tmp['y']\n","    folds = tmp['folds']\n","\n","    n_class = y.shape[1]\n","    print(n_class)\n","    print(X.shape)\n","    print(y.shape)\n","    X=np.pad(X, ((0,0),(0,0), (150,0), (26, 0)), 'constant')\n","    print(X.shape)\n","    train_idx = folds[0][0]\n","    test_idx = folds[0][1]\n","\n","    X_train = X[train_idx]\n","    X_test = X[test_idx]\n","    print(X_train.shape)\n","    print(X_test.shape)\n","    idx_modalities=[11,19,27]\n","    print(idx_modalities)\n","    return X,y,folds,idx_modalities,n_class"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9SmJW6D9hDb9","colab_type":"code","colab":{}},"source":["def RunWisdom(data_input_file):\n","  X,y,folds,idx_modalities,n_class=WisdomDataPreparation(data_input_file)\n","  TrainAndReportAccuracies(X,y,folds,idx_modalities,n_class)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qPhY2p6i2YlU","colab_type":"code","colab":{}},"source":["def WHARFDataPreparation(data_input_file):\n","    np.random.seed(12227)\n","    tmp = np.load(data_input_file)\n","    X = tmp['X']\n","    y = tmp['y']\n","    folds = tmp['folds']\n","    X=np.pad(X, ((0,0),(0,0),(90,0), (26, 0)), 'constant')\n","    n_class = y.shape[1]\n","    print(n_class)\n","    print(X.shape)\n","    print(y.shape)\n","\n","    train_idx = folds[0][0]\n","    test_idx = folds[0][1]\n","\n","    X_train = X[train_idx]\n","    X_test = X[test_idx]\n","    print(X_train.shape)\n","    print(X_test.shape)\n","\n","    idx_modalities=[11,19,27]\n","    print(idx_modalities)\n","    return X,y,folds,idx_modalities,n_class"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jna3ZQPh6EUI","colab_type":"code","colab":{}},"source":["def RunWHARF(data_input_file):\n","  # Batch size 100\n","  X,y,folds,idx_modalities,n_class=WHARFDataPreparation(data_input_file)\n","  TrainAndReportAccuracies(X,y,folds,idx_modalities,n_class)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d2hujj0R6Wnx","colab_type":"code","outputId":"c98e012c-025f-4630-8234-b966dac1dbfb","executionInfo":{"status":"ok","timestamp":1586029199996,"user_tz":-120,"elapsed":776634,"user":{"displayName":"Rana mostafa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpLWLhJYcXKOOp7sprSKwnxN-x9hYM61yh__9kww=s64","userId":"07598775866819373078"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["RunWHARF('data/LOSO/WHARF.npz')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["12\n","(3871, 1, 250, 29)\n","(3871, 12)\n","(2189, 1, 250, 29)\n","(1682, 1, 250, 29)\n","[11, 19, 27]\n","Start Training\n","Train on 2189 samples, validate on 2189 samples\n","Epoch 1/60\n","2189/2189 [==============================] - 19s 9ms/step - loss: 2.3981 - acc: 0.2015 - val_loss: 2.0687 - val_acc: 0.3851\n","Epoch 2/60\n","2189/2189 [==============================] - 19s 8ms/step - loss: 1.9891 - acc: 0.4061 - val_loss: 2.0692 - val_acc: 0.3344\n","Epoch 3/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 1.8065 - acc: 0.4463 - val_loss: 1.6765 - val_acc: 0.4632\n","Epoch 4/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 1.6324 - acc: 0.4756 - val_loss: 1.5647 - val_acc: 0.4623\n","Epoch 5/60\n","2189/2189 [==============================] - 19s 9ms/step - loss: 1.4966 - acc: 0.4902 - val_loss: 1.4403 - val_acc: 0.5190\n","Epoch 6/60\n","2189/2189 [==============================] - 19s 8ms/step - loss: 1.4134 - acc: 0.5080 - val_loss: 1.4021 - val_acc: 0.4902\n","Epoch 7/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 1.3742 - acc: 0.5121 - val_loss: 1.4260 - val_acc: 0.4842\n","Epoch 8/60\n","2189/2189 [==============================] - 19s 8ms/step - loss: 1.3118 - acc: 0.5190 - val_loss: 1.2726 - val_acc: 0.5267\n","Epoch 9/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 1.2710 - acc: 0.5372 - val_loss: 1.3135 - val_acc: 0.5217\n","Epoch 10/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 1.2189 - acc: 0.5669 - val_loss: 1.2455 - val_acc: 0.5254\n","Epoch 11/60\n","2189/2189 [==============================] - 19s 8ms/step - loss: 1.1975 - acc: 0.5624 - val_loss: 1.1732 - val_acc: 0.5838\n","Epoch 12/60\n","2189/2189 [==============================] - 19s 8ms/step - loss: 1.1753 - acc: 0.5646 - val_loss: 1.1348 - val_acc: 0.5980\n","Epoch 13/60\n","2189/2189 [==============================] - 19s 9ms/step - loss: 1.1848 - acc: 0.5720 - val_loss: 1.1252 - val_acc: 0.5720\n","Epoch 14/60\n","2189/2189 [==============================] - 19s 9ms/step - loss: 1.1449 - acc: 0.5889 - val_loss: 1.0850 - val_acc: 0.6268\n","Epoch 15/60\n","2189/2189 [==============================] - 19s 8ms/step - loss: 1.1235 - acc: 0.5943 - val_loss: 1.0743 - val_acc: 0.6122\n","Epoch 16/60\n","2189/2189 [==============================] - 19s 9ms/step - loss: 1.0934 - acc: 0.6062 - val_loss: 1.0859 - val_acc: 0.6035\n","Epoch 17/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 1.0831 - acc: 0.6140 - val_loss: 1.1429 - val_acc: 0.5322\n","Epoch 18/60\n","2189/2189 [==============================] - 19s 9ms/step - loss: 1.0923 - acc: 0.6003 - val_loss: 1.0589 - val_acc: 0.6414\n","Epoch 19/60\n","2189/2189 [==============================] - 19s 9ms/step - loss: 1.0491 - acc: 0.6332 - val_loss: 1.0092 - val_acc: 0.6624\n","Epoch 20/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 1.0471 - acc: 0.6259 - val_loss: 1.0407 - val_acc: 0.6537\n","Epoch 21/60\n","2189/2189 [==============================] - 19s 9ms/step - loss: 1.0459 - acc: 0.6281 - val_loss: 0.9887 - val_acc: 0.6578\n","Epoch 22/60\n","2189/2189 [==============================] - 19s 9ms/step - loss: 1.0076 - acc: 0.6524 - val_loss: 0.9834 - val_acc: 0.6501\n","Epoch 23/60\n","2189/2189 [==============================] - 19s 9ms/step - loss: 0.9970 - acc: 0.6524 - val_loss: 0.9650 - val_acc: 0.6802\n","Epoch 24/60\n","2189/2189 [==============================] - 19s 9ms/step - loss: 0.9955 - acc: 0.6542 - val_loss: 0.9604 - val_acc: 0.6852\n","Epoch 25/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.9905 - acc: 0.6460 - val_loss: 0.9392 - val_acc: 0.6926\n","Epoch 26/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.9648 - acc: 0.6537 - val_loss: 0.9519 - val_acc: 0.6473\n","Epoch 27/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.9603 - acc: 0.6651 - val_loss: 0.9252 - val_acc: 0.6852\n","Epoch 28/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.9519 - acc: 0.6665 - val_loss: 0.9818 - val_acc: 0.6263\n","Epoch 29/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.9533 - acc: 0.6606 - val_loss: 0.9661 - val_acc: 0.6450\n","Epoch 30/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.9279 - acc: 0.6651 - val_loss: 0.8955 - val_acc: 0.6871\n","Epoch 31/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.9303 - acc: 0.6752 - val_loss: 0.8986 - val_acc: 0.6807\n","Epoch 32/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.9135 - acc: 0.6775 - val_loss: 0.8922 - val_acc: 0.6830\n","Epoch 33/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.9151 - acc: 0.6784 - val_loss: 0.8872 - val_acc: 0.6852\n","Epoch 34/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.8944 - acc: 0.6788 - val_loss: 0.8763 - val_acc: 0.6843\n","Epoch 35/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.8953 - acc: 0.6866 - val_loss: 0.9257 - val_acc: 0.6373\n","Epoch 36/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.9069 - acc: 0.6743 - val_loss: 0.8595 - val_acc: 0.7145\n","Epoch 37/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.8784 - acc: 0.6944 - val_loss: 0.8559 - val_acc: 0.7035\n","Epoch 38/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.8939 - acc: 0.6843 - val_loss: 0.8456 - val_acc: 0.7117\n","Epoch 39/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.8424 - acc: 0.7040 - val_loss: 0.8572 - val_acc: 0.7017\n","Epoch 40/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.8507 - acc: 0.6953 - val_loss: 0.9323 - val_acc: 0.6492\n","Epoch 41/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.8611 - acc: 0.6898 - val_loss: 0.8395 - val_acc: 0.7076\n","Epoch 42/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.8501 - acc: 0.7053 - val_loss: 0.8295 - val_acc: 0.6967\n","Epoch 43/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.8281 - acc: 0.7072 - val_loss: 0.8027 - val_acc: 0.7382\n","Epoch 44/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.8395 - acc: 0.6989 - val_loss: 0.8107 - val_acc: 0.7323\n","Epoch 45/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.8334 - acc: 0.6921 - val_loss: 0.8743 - val_acc: 0.7040\n","Epoch 46/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.8168 - acc: 0.7159 - val_loss: 0.8515 - val_acc: 0.7145\n","Epoch 47/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.8088 - acc: 0.7209 - val_loss: 0.7892 - val_acc: 0.7291\n","Epoch 48/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.8181 - acc: 0.7149 - val_loss: 0.9329 - val_acc: 0.6642\n","Epoch 49/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.8062 - acc: 0.7140 - val_loss: 0.7765 - val_acc: 0.7355\n","Epoch 50/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.7999 - acc: 0.7163 - val_loss: 0.7850 - val_acc: 0.7222\n","Epoch 51/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.7850 - acc: 0.7291 - val_loss: 0.8542 - val_acc: 0.6734\n","Epoch 52/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.7795 - acc: 0.7232 - val_loss: 0.7663 - val_acc: 0.7259\n","Epoch 53/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.7749 - acc: 0.7314 - val_loss: 0.7976 - val_acc: 0.7259\n","Epoch 54/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.7662 - acc: 0.7323 - val_loss: 0.7638 - val_acc: 0.7305\n","Epoch 55/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.7787 - acc: 0.7282 - val_loss: 0.7333 - val_acc: 0.7515\n","Epoch 56/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.7441 - acc: 0.7423 - val_loss: 0.7227 - val_acc: 0.7588\n","Epoch 57/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.7561 - acc: 0.7328 - val_loss: 0.7260 - val_acc: 0.7474\n","Epoch 58/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.7585 - acc: 0.7332 - val_loss: 0.7273 - val_acc: 0.7551\n","Epoch 59/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.7548 - acc: 0.7305 - val_loss: 0.7449 - val_acc: 0.7268\n","Epoch 60/60\n","2189/2189 [==============================] - 18s 8ms/step - loss: 0.7418 - acc: 0.7460 - val_loss: 0.7318 - val_acc: 0.7524\n","Accuracy[0.5642] Recall[0.4808] F1[0.4552] at fold[0]\n","______________________________________________________\n","Start Training\n","Train on 3684 samples, validate on 3684 samples\n","Epoch 1/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 2.6257 - acc: 0.2378 - val_loss: 2.2240 - val_acc: 0.2864\n","Epoch 2/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 2.1376 - acc: 0.3027 - val_loss: 1.9824 - val_acc: 0.3716\n","Epoch 3/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 1.8638 - acc: 0.3746 - val_loss: 1.7258 - val_acc: 0.3792\n","Epoch 4/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 1.6376 - acc: 0.4278 - val_loss: 1.4911 - val_acc: 0.4446\n","Epoch 5/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 1.4814 - acc: 0.4832 - val_loss: 1.4050 - val_acc: 0.5524\n","Epoch 6/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 1.3688 - acc: 0.5157 - val_loss: 1.3786 - val_acc: 0.4726\n","Epoch 7/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 1.3000 - acc: 0.5347 - val_loss: 1.3339 - val_acc: 0.5296\n","Epoch 8/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 1.2337 - acc: 0.5589 - val_loss: 1.2636 - val_acc: 0.5404\n","Epoch 9/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 1.1777 - acc: 0.5833 - val_loss: 1.1664 - val_acc: 0.5565\n","Epoch 10/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 1.1502 - acc: 0.5882 - val_loss: 1.1814 - val_acc: 0.5518\n","Epoch 11/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 1.1327 - acc: 0.5850 - val_loss: 1.1150 - val_acc: 0.5912\n","Epoch 12/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 1.1096 - acc: 0.6042 - val_loss: 1.0801 - val_acc: 0.6265\n","Epoch 13/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 1.0784 - acc: 0.6197 - val_loss: 1.1014 - val_acc: 0.5828\n","Epoch 14/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 1.0634 - acc: 0.6260 - val_loss: 1.0392 - val_acc: 0.6585\n","Epoch 15/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 1.0501 - acc: 0.6292 - val_loss: 1.0293 - val_acc: 0.6116\n","Epoch 16/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 1.0251 - acc: 0.6406 - val_loss: 1.0239 - val_acc: 0.6276\n","Epoch 17/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 1.0136 - acc: 0.6452 - val_loss: 1.0105 - val_acc: 0.6216\n","Epoch 18/60\n","3684/3684 [==============================] - 30s 8ms/step - loss: 1.0118 - acc: 0.6374 - val_loss: 0.9898 - val_acc: 0.6705\n","Epoch 19/60\n","3684/3684 [==============================] - 30s 8ms/step - loss: 0.9804 - acc: 0.6585 - val_loss: 0.9649 - val_acc: 0.6561\n","Epoch 20/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.9811 - acc: 0.6550 - val_loss: 0.9603 - val_acc: 0.6360\n","Epoch 21/60\n","3684/3684 [==============================] - 30s 8ms/step - loss: 0.9731 - acc: 0.6604 - val_loss: 1.0085 - val_acc: 0.6205\n","Epoch 22/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.9619 - acc: 0.6553 - val_loss: 0.9454 - val_acc: 0.6669\n","Epoch 23/60\n","3684/3684 [==============================] - 30s 8ms/step - loss: 0.9434 - acc: 0.6656 - val_loss: 0.9493 - val_acc: 0.6447\n","Epoch 24/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.9394 - acc: 0.6631 - val_loss: 0.8922 - val_acc: 0.7058\n","Epoch 25/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.9353 - acc: 0.6773 - val_loss: 0.9644 - val_acc: 0.6230\n","Epoch 26/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.9256 - acc: 0.6756 - val_loss: 0.8935 - val_acc: 0.6935\n","Epoch 27/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.9043 - acc: 0.6797 - val_loss: 0.9386 - val_acc: 0.6819\n","Epoch 28/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.9054 - acc: 0.6773 - val_loss: 0.8673 - val_acc: 0.6908\n","Epoch 29/60\n","3684/3684 [==============================] - 30s 8ms/step - loss: 0.8966 - acc: 0.6811 - val_loss: 0.8555 - val_acc: 0.7120\n","Epoch 30/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.8808 - acc: 0.6938 - val_loss: 0.8462 - val_acc: 0.7155\n","Epoch 31/60\n","3684/3684 [==============================] - 30s 8ms/step - loss: 0.8726 - acc: 0.6922 - val_loss: 0.8626 - val_acc: 0.6743\n","Epoch 32/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.8750 - acc: 0.6927 - val_loss: 0.8555 - val_acc: 0.6873\n","Epoch 33/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.8622 - acc: 0.7003 - val_loss: 0.8460 - val_acc: 0.7044\n","Epoch 34/60\n","3684/3684 [==============================] - 30s 8ms/step - loss: 0.8508 - acc: 0.7028 - val_loss: 0.9104 - val_acc: 0.6501\n","Epoch 35/60\n","3684/3684 [==============================] - 30s 8ms/step - loss: 0.8547 - acc: 0.7020 - val_loss: 0.8444 - val_acc: 0.6941\n","Epoch 36/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.8452 - acc: 0.7025 - val_loss: 0.8341 - val_acc: 0.7071\n","Epoch 37/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.8317 - acc: 0.7052 - val_loss: 0.7968 - val_acc: 0.7318\n","Epoch 38/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.8377 - acc: 0.6987 - val_loss: 0.7972 - val_acc: 0.7256\n","Epoch 39/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.8262 - acc: 0.7049 - val_loss: 0.8338 - val_acc: 0.6952\n","Epoch 40/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.8113 - acc: 0.7106 - val_loss: 0.8234 - val_acc: 0.7041\n","Epoch 41/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.8080 - acc: 0.7161 - val_loss: 0.8163 - val_acc: 0.7017\n","Epoch 42/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.7970 - acc: 0.7250 - val_loss: 0.7948 - val_acc: 0.7172\n","Epoch 43/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.7935 - acc: 0.7253 - val_loss: 0.7905 - val_acc: 0.7147\n","Epoch 44/60\n","3684/3684 [==============================] - 30s 8ms/step - loss: 0.7890 - acc: 0.7207 - val_loss: 0.7904 - val_acc: 0.7337\n","Epoch 45/60\n","3684/3684 [==============================] - 30s 8ms/step - loss: 0.7763 - acc: 0.7258 - val_loss: 0.7566 - val_acc: 0.7375\n","Epoch 46/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.7707 - acc: 0.7258 - val_loss: 0.7687 - val_acc: 0.7408\n","Epoch 47/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.7721 - acc: 0.7310 - val_loss: 0.7673 - val_acc: 0.7291\n","Epoch 48/60\n","3684/3684 [==============================] - 30s 8ms/step - loss: 0.7669 - acc: 0.7283 - val_loss: 0.7335 - val_acc: 0.7505\n","Epoch 49/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.7615 - acc: 0.7264 - val_loss: 0.7668 - val_acc: 0.7120\n","Epoch 50/60\n","3684/3684 [==============================] - 30s 8ms/step - loss: 0.7588 - acc: 0.7288 - val_loss: 0.7240 - val_acc: 0.7465\n","Epoch 51/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.7544 - acc: 0.7329 - val_loss: 0.7962 - val_acc: 0.6897\n","Epoch 52/60\n","3684/3684 [==============================] - 31s 9ms/step - loss: 0.7336 - acc: 0.7419 - val_loss: 0.7302 - val_acc: 0.7362\n","Epoch 53/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.7422 - acc: 0.7400 - val_loss: 0.7169 - val_acc: 0.7402\n","Epoch 54/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.7388 - acc: 0.7400 - val_loss: 0.7087 - val_acc: 0.7511\n","Epoch 55/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.7218 - acc: 0.7478 - val_loss: 0.7228 - val_acc: 0.7446\n","Epoch 56/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.7224 - acc: 0.7484 - val_loss: 0.8023 - val_acc: 0.7112\n","Epoch 57/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.7163 - acc: 0.7500 - val_loss: 0.7106 - val_acc: 0.7400\n","Epoch 58/60\n","3684/3684 [==============================] - 30s 8ms/step - loss: 0.7060 - acc: 0.7500 - val_loss: 0.6959 - val_acc: 0.7554\n","Epoch 59/60\n","3684/3684 [==============================] - 31s 8ms/step - loss: 0.7021 - acc: 0.7503 - val_loss: 0.6702 - val_acc: 0.7714\n","Epoch 60/60\n","3684/3684 [==============================] - 30s 8ms/step - loss: 0.6980 - acc: 0.7484 - val_loss: 0.7413 - val_acc: 0.7210\n","Accuracy[0.4332] Recall[0.2760] F1[0.2671] at fold[1]\n","______________________________________________________\n","Start Training\n","Train on 3756 samples, validate on 3756 samples\n","Epoch 1/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 2.4932 - acc: 0.1970 - val_loss: 2.2134 - val_acc: 0.3240\n","Epoch 2/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 2.0887 - acc: 0.3562 - val_loss: 2.0548 - val_acc: 0.2993\n","Epoch 3/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 1.7269 - acc: 0.4276 - val_loss: 1.4820 - val_acc: 0.5269\n","Epoch 4/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 1.4666 - acc: 0.4984 - val_loss: 1.3867 - val_acc: 0.5216\n","Epoch 5/60\n","3756/3756 [==============================] - 32s 8ms/step - loss: 1.3478 - acc: 0.5285 - val_loss: 1.2529 - val_acc: 0.5634\n","Epoch 6/60\n","3756/3756 [==============================] - 32s 8ms/step - loss: 1.2332 - acc: 0.5692 - val_loss: 1.2389 - val_acc: 0.5434\n","Epoch 7/60\n","3756/3756 [==============================] - 32s 8ms/step - loss: 1.2044 - acc: 0.5767 - val_loss: 1.1539 - val_acc: 0.5879\n","Epoch 8/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 1.1708 - acc: 0.5876 - val_loss: 1.1439 - val_acc: 0.5716\n","Epoch 9/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 1.1245 - acc: 0.5972 - val_loss: 1.1985 - val_acc: 0.5620\n","Epoch 10/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 1.1006 - acc: 0.6169 - val_loss: 1.0673 - val_acc: 0.6230\n","Epoch 11/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 1.0769 - acc: 0.6177 - val_loss: 1.0494 - val_acc: 0.6270\n","Epoch 12/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 1.0537 - acc: 0.6278 - val_loss: 1.1124 - val_acc: 0.5921\n","Epoch 13/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 1.0382 - acc: 0.6371 - val_loss: 1.0818 - val_acc: 0.6233\n","Epoch 14/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 1.0200 - acc: 0.6462 - val_loss: 1.0980 - val_acc: 0.6028\n","Epoch 15/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 1.0034 - acc: 0.6512 - val_loss: 1.1734 - val_acc: 0.4795\n","Epoch 16/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.9971 - acc: 0.6448 - val_loss: 0.9837 - val_acc: 0.6515\n","Epoch 17/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.9823 - acc: 0.6573 - val_loss: 0.9850 - val_acc: 0.6523\n","Epoch 18/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.9696 - acc: 0.6544 - val_loss: 0.9586 - val_acc: 0.6712\n","Epoch 19/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.9655 - acc: 0.6608 - val_loss: 0.9560 - val_acc: 0.6563\n","Epoch 20/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.9432 - acc: 0.6797 - val_loss: 0.9931 - val_acc: 0.6273\n","Epoch 21/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.9328 - acc: 0.6768 - val_loss: 0.9440 - val_acc: 0.6736\n","Epoch 22/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.9245 - acc: 0.6707 - val_loss: 0.9567 - val_acc: 0.6659\n","Epoch 23/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.9115 - acc: 0.6829 - val_loss: 0.9034 - val_acc: 0.6882\n","Epoch 24/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.9136 - acc: 0.6808 - val_loss: 0.9430 - val_acc: 0.6832\n","Epoch 25/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.8985 - acc: 0.6832 - val_loss: 0.9051 - val_acc: 0.6965\n","Epoch 26/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.8853 - acc: 0.6936 - val_loss: 0.8897 - val_acc: 0.6792\n","Epoch 27/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.8803 - acc: 0.6936 - val_loss: 0.8605 - val_acc: 0.7066\n","Epoch 28/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.8733 - acc: 0.6952 - val_loss: 0.9359 - val_acc: 0.6462\n","Epoch 29/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.8669 - acc: 0.6978 - val_loss: 0.8808 - val_acc: 0.6723\n","Epoch 30/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.8459 - acc: 0.7018 - val_loss: 0.8468 - val_acc: 0.6957\n","Epoch 31/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.8493 - acc: 0.6925 - val_loss: 0.8385 - val_acc: 0.7077\n","Epoch 32/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.8386 - acc: 0.6986 - val_loss: 0.8056 - val_acc: 0.7204\n","Epoch 33/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.8338 - acc: 0.7095 - val_loss: 0.8595 - val_acc: 0.6893\n","Epoch 34/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.8284 - acc: 0.7050 - val_loss: 0.8207 - val_acc: 0.7095\n","Epoch 35/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.8248 - acc: 0.7106 - val_loss: 0.7876 - val_acc: 0.7154\n","Epoch 36/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.8089 - acc: 0.7154 - val_loss: 0.8369 - val_acc: 0.6991\n","Epoch 37/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.8061 - acc: 0.7117 - val_loss: 0.8006 - val_acc: 0.7146\n","Epoch 38/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.8093 - acc: 0.7133 - val_loss: 0.7828 - val_acc: 0.7298\n","Epoch 39/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.7894 - acc: 0.7210 - val_loss: 0.7955 - val_acc: 0.7026\n","Epoch 40/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.7798 - acc: 0.7252 - val_loss: 0.8008 - val_acc: 0.6989\n","Epoch 41/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.7858 - acc: 0.7207 - val_loss: 0.7454 - val_acc: 0.7457\n","Epoch 42/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.7724 - acc: 0.7319 - val_loss: 0.7454 - val_acc: 0.7396\n","Epoch 43/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.7750 - acc: 0.7220 - val_loss: 0.8365 - val_acc: 0.6834\n","Epoch 44/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.7633 - acc: 0.7284 - val_loss: 0.7276 - val_acc: 0.7465\n","Epoch 45/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.7496 - acc: 0.7412 - val_loss: 0.7391 - val_acc: 0.7335\n","Epoch 46/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.7590 - acc: 0.7271 - val_loss: 0.7702 - val_acc: 0.7346\n","Epoch 47/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.7495 - acc: 0.7370 - val_loss: 0.7706 - val_acc: 0.7149\n","Epoch 48/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.7379 - acc: 0.7356 - val_loss: 0.8979 - val_acc: 0.6731\n","Epoch 49/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.7420 - acc: 0.7396 - val_loss: 0.7270 - val_acc: 0.7447\n","Epoch 50/60\n","3756/3756 [==============================] - 32s 8ms/step - loss: 0.7358 - acc: 0.7375 - val_loss: 0.7227 - val_acc: 0.7439\n","Epoch 51/60\n","3756/3756 [==============================] - 32s 8ms/step - loss: 0.7296 - acc: 0.7425 - val_loss: 0.7788 - val_acc: 0.7263\n","Epoch 52/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.7247 - acc: 0.7425 - val_loss: 0.7354 - val_acc: 0.7407\n","Epoch 53/60\n","3756/3756 [==============================] - 32s 8ms/step - loss: 0.7262 - acc: 0.7473 - val_loss: 0.7832 - val_acc: 0.7295\n","Epoch 54/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.7138 - acc: 0.7468 - val_loss: 0.7030 - val_acc: 0.7580\n","Epoch 55/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.7034 - acc: 0.7481 - val_loss: 0.7289 - val_acc: 0.7322\n","Epoch 56/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.7045 - acc: 0.7540 - val_loss: 0.6676 - val_acc: 0.7646\n","Epoch 57/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.6899 - acc: 0.7620 - val_loss: 0.7062 - val_acc: 0.7601\n","Epoch 58/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.6918 - acc: 0.7559 - val_loss: 0.6715 - val_acc: 0.7622\n","Epoch 59/60\n","3756/3756 [==============================] - 32s 8ms/step - loss: 0.6935 - acc: 0.7561 - val_loss: 0.6724 - val_acc: 0.7649\n","Epoch 60/60\n","3756/3756 [==============================] - 31s 8ms/step - loss: 0.6943 - acc: 0.7601 - val_loss: 0.7089 - val_acc: 0.7511\n","Accuracy[0.5565] Recall[0.3210] F1[0.3221] at fold[2]\n","______________________________________________________\n","Start Training\n","Train on 3747 samples, validate on 3747 samples\n","Epoch 1/60\n","3747/3747 [==============================] - 32s 8ms/step - loss: 2.4631 - acc: 0.2244 - val_loss: 2.1721 - val_acc: 0.2813\n","Epoch 2/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 2.0855 - acc: 0.3448 - val_loss: 1.9352 - val_acc: 0.3977\n","Epoch 3/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 1.8338 - acc: 0.4230 - val_loss: 1.7127 - val_acc: 0.4345\n","Epoch 4/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 1.5773 - acc: 0.4766 - val_loss: 1.4704 - val_acc: 0.4916\n","Epoch 5/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 1.4447 - acc: 0.5049 - val_loss: 1.5779 - val_acc: 0.4697\n","Epoch 6/60\n","3747/3747 [==============================] - 32s 8ms/step - loss: 1.3551 - acc: 0.5260 - val_loss: 1.2930 - val_acc: 0.5578\n","Epoch 7/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 1.2830 - acc: 0.5540 - val_loss: 1.2647 - val_acc: 0.5260\n","Epoch 8/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 1.2465 - acc: 0.5610 - val_loss: 1.1615 - val_acc: 0.5658\n","Epoch 9/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 1.1667 - acc: 0.5858 - val_loss: 1.2041 - val_acc: 0.5709\n","Epoch 10/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 1.1249 - acc: 0.5967 - val_loss: 1.2288 - val_acc: 0.5623\n","Epoch 11/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 1.1083 - acc: 0.6088 - val_loss: 1.1192 - val_acc: 0.5687\n","Epoch 12/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 1.0853 - acc: 0.6168 - val_loss: 1.1206 - val_acc: 0.5802\n","Epoch 13/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 1.0652 - acc: 0.6272 - val_loss: 1.0947 - val_acc: 0.6136\n","Epoch 14/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 1.0358 - acc: 0.6362 - val_loss: 1.0353 - val_acc: 0.6213\n","Epoch 15/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 1.0212 - acc: 0.6376 - val_loss: 0.9917 - val_acc: 0.6597\n","Epoch 16/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 1.0100 - acc: 0.6568 - val_loss: 1.0507 - val_acc: 0.6224\n","Epoch 17/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.9999 - acc: 0.6523 - val_loss: 1.0347 - val_acc: 0.6317\n","Epoch 18/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.9844 - acc: 0.6616 - val_loss: 0.9664 - val_acc: 0.6720\n","Epoch 19/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.9693 - acc: 0.6651 - val_loss: 0.9773 - val_acc: 0.6664\n","Epoch 20/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.9578 - acc: 0.6696 - val_loss: 0.9462 - val_acc: 0.6963\n","Epoch 21/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.9480 - acc: 0.6707 - val_loss: 1.0282 - val_acc: 0.6480\n","Epoch 22/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.9373 - acc: 0.6789 - val_loss: 0.9229 - val_acc: 0.6768\n","Epoch 23/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.9099 - acc: 0.6904 - val_loss: 0.9220 - val_acc: 0.6987\n","Epoch 24/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.9241 - acc: 0.6886 - val_loss: 0.9294 - val_acc: 0.6947\n","Epoch 25/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.9015 - acc: 0.6936 - val_loss: 0.8826 - val_acc: 0.7072\n","Epoch 26/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8990 - acc: 0.7046 - val_loss: 0.9283 - val_acc: 0.6715\n","Epoch 27/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8790 - acc: 0.7056 - val_loss: 0.9168 - val_acc: 0.6848\n","Epoch 28/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8857 - acc: 0.6966 - val_loss: 0.9025 - val_acc: 0.6765\n","Epoch 29/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8791 - acc: 0.6998 - val_loss: 0.8778 - val_acc: 0.7078\n","Epoch 30/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8674 - acc: 0.7064 - val_loss: 0.8386 - val_acc: 0.7171\n","Epoch 31/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8623 - acc: 0.7139 - val_loss: 0.8630 - val_acc: 0.7222\n","Epoch 32/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8597 - acc: 0.7043 - val_loss: 0.9348 - val_acc: 0.6624\n","Epoch 33/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8438 - acc: 0.7198 - val_loss: 0.9017 - val_acc: 0.6661\n","Epoch 34/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8414 - acc: 0.7192 - val_loss: 0.9047 - val_acc: 0.6731\n","Epoch 35/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8378 - acc: 0.7126 - val_loss: 0.8885 - val_acc: 0.6824\n","Epoch 36/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8299 - acc: 0.7216 - val_loss: 0.8265 - val_acc: 0.7171\n","Epoch 37/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8326 - acc: 0.7160 - val_loss: 0.8343 - val_acc: 0.7315\n","Epoch 38/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8237 - acc: 0.7232 - val_loss: 0.8285 - val_acc: 0.7232\n","Epoch 39/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8282 - acc: 0.7158 - val_loss: 0.8567 - val_acc: 0.6995\n","Epoch 40/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8169 - acc: 0.7227 - val_loss: 0.8039 - val_acc: 0.7270\n","Epoch 41/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8028 - acc: 0.7302 - val_loss: 0.8050 - val_acc: 0.7230\n","Epoch 42/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8092 - acc: 0.7208 - val_loss: 0.8773 - val_acc: 0.6902\n","Epoch 43/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.8117 - acc: 0.7251 - val_loss: 0.7746 - val_acc: 0.7393\n","Epoch 44/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.7904 - acc: 0.7350 - val_loss: 0.8200 - val_acc: 0.7227\n","Epoch 45/60\n","3747/3747 [==============================] - 32s 8ms/step - loss: 0.7935 - acc: 0.7337 - val_loss: 0.8221 - val_acc: 0.7152\n","Epoch 46/60\n","3747/3747 [==============================] - 32s 8ms/step - loss: 0.7899 - acc: 0.7331 - val_loss: 0.8624 - val_acc: 0.6926\n","Epoch 47/60\n","3747/3747 [==============================] - 32s 8ms/step - loss: 0.7891 - acc: 0.7294 - val_loss: 0.7667 - val_acc: 0.7441\n","Epoch 48/60\n","3747/3747 [==============================] - 32s 8ms/step - loss: 0.7671 - acc: 0.7390 - val_loss: 0.7695 - val_acc: 0.7371\n","Epoch 49/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.7695 - acc: 0.7406 - val_loss: 0.8174 - val_acc: 0.7222\n","Epoch 50/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.7694 - acc: 0.7371 - val_loss: 0.8417 - val_acc: 0.6912\n","Epoch 51/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.7633 - acc: 0.7411 - val_loss: 0.7958 - val_acc: 0.7046\n","Epoch 52/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.7565 - acc: 0.7433 - val_loss: 0.7369 - val_acc: 0.7459\n","Epoch 53/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.7584 - acc: 0.7433 - val_loss: 0.8147 - val_acc: 0.7030\n","Epoch 54/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.7642 - acc: 0.7411 - val_loss: 0.7432 - val_acc: 0.7334\n","Epoch 55/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.7407 - acc: 0.7491 - val_loss: 0.8587 - val_acc: 0.6835\n","Epoch 56/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.7340 - acc: 0.7534 - val_loss: 0.7511 - val_acc: 0.7291\n","Epoch 57/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.7473 - acc: 0.7478 - val_loss: 0.7900 - val_acc: 0.7235\n","Epoch 58/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.7298 - acc: 0.7529 - val_loss: 0.7842 - val_acc: 0.7203\n","Epoch 59/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.7357 - acc: 0.7457 - val_loss: 0.7330 - val_acc: 0.7406\n","Epoch 60/60\n","3747/3747 [==============================] - 31s 8ms/step - loss: 0.7405 - acc: 0.7470 - val_loss: 0.7298 - val_acc: 0.7590\n","Accuracy[0.5484] Recall[0.5205] F1[0.4539] at fold[3]\n","______________________________________________________\n","Start Training\n","Train on 3864 samples, validate on 3864 samples\n","Epoch 1/60\n","3864/3864 [==============================] - 33s 8ms/step - loss: 2.3539 - acc: 0.2091 - val_loss: 2.2330 - val_acc: 0.2096\n","Epoch 2/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 2.0464 - acc: 0.3163 - val_loss: 1.9292 - val_acc: 0.4004\n","Epoch 3/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.8073 - acc: 0.3983 - val_loss: 1.6481 - val_acc: 0.4379\n","Epoch 4/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.6477 - acc: 0.4488 - val_loss: 1.5407 - val_acc: 0.5005\n","Epoch 5/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.4952 - acc: 0.4878 - val_loss: 1.4045 - val_acc: 0.5114\n","Epoch 6/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.4335 - acc: 0.4966 - val_loss: 1.4792 - val_acc: 0.4739\n","Epoch 7/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.3839 - acc: 0.5194 - val_loss: 1.3498 - val_acc: 0.5427\n","Epoch 8/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.3220 - acc: 0.5411 - val_loss: 1.2685 - val_acc: 0.5691\n","Epoch 9/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.2765 - acc: 0.5525 - val_loss: 1.2891 - val_acc: 0.5587\n","Epoch 10/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.2654 - acc: 0.5479 - val_loss: 1.3493 - val_acc: 0.5238\n","Epoch 11/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.2330 - acc: 0.5644 - val_loss: 1.3041 - val_acc: 0.5259\n","Epoch 12/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.2025 - acc: 0.5665 - val_loss: 1.2390 - val_acc: 0.5450\n","Epoch 13/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.1751 - acc: 0.5813 - val_loss: 1.1277 - val_acc: 0.6077\n","Epoch 14/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.1441 - acc: 0.6014 - val_loss: 1.1428 - val_acc: 0.5958\n","Epoch 15/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.1158 - acc: 0.6056 - val_loss: 1.1383 - val_acc: 0.5898\n","Epoch 16/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.1111 - acc: 0.6206 - val_loss: 1.0776 - val_acc: 0.6310\n","Epoch 17/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.0823 - acc: 0.6203 - val_loss: 1.0664 - val_acc: 0.6214\n","Epoch 18/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.0544 - acc: 0.6302 - val_loss: 1.0689 - val_acc: 0.5996\n","Epoch 19/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.0520 - acc: 0.6366 - val_loss: 1.0807 - val_acc: 0.6227\n","Epoch 20/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.0275 - acc: 0.6356 - val_loss: 1.1068 - val_acc: 0.6131\n","Epoch 21/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.0148 - acc: 0.6475 - val_loss: 0.9935 - val_acc: 0.6669\n","Epoch 22/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 1.0041 - acc: 0.6470 - val_loss: 0.9925 - val_acc: 0.6328\n","Epoch 23/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.9892 - acc: 0.6617 - val_loss: 0.9825 - val_acc: 0.6685\n","Epoch 24/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.9842 - acc: 0.6506 - val_loss: 0.9658 - val_acc: 0.6682\n","Epoch 25/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.9621 - acc: 0.6737 - val_loss: 0.9377 - val_acc: 0.6871\n","Epoch 26/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.9596 - acc: 0.6695 - val_loss: 0.9607 - val_acc: 0.6530\n","Epoch 27/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.9621 - acc: 0.6638 - val_loss: 0.9819 - val_acc: 0.6669\n","Epoch 28/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.9372 - acc: 0.6770 - val_loss: 0.9623 - val_acc: 0.6649\n","Epoch 29/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.9335 - acc: 0.6739 - val_loss: 0.8890 - val_acc: 0.7039\n","Epoch 30/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.9243 - acc: 0.6773 - val_loss: 0.9424 - val_acc: 0.6439\n","Epoch 31/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.9223 - acc: 0.6731 - val_loss: 0.8994 - val_acc: 0.6819\n","Epoch 32/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.9078 - acc: 0.6871 - val_loss: 0.9196 - val_acc: 0.6641\n","Epoch 33/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.9010 - acc: 0.6869 - val_loss: 0.8836 - val_acc: 0.6946\n","Epoch 34/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.8925 - acc: 0.6897 - val_loss: 0.9491 - val_acc: 0.6465\n","Epoch 35/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.8869 - acc: 0.6884 - val_loss: 0.8815 - val_acc: 0.6975\n","Epoch 36/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.8804 - acc: 0.6925 - val_loss: 0.9033 - val_acc: 0.6835\n","Epoch 37/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.8771 - acc: 0.6920 - val_loss: 0.8944 - val_acc: 0.6612\n","Epoch 38/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.8672 - acc: 0.6933 - val_loss: 0.8369 - val_acc: 0.7164\n","Epoch 39/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.8626 - acc: 0.6962 - val_loss: 0.9210 - val_acc: 0.6848\n","Epoch 40/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.8543 - acc: 0.7029 - val_loss: 0.8529 - val_acc: 0.6913\n","Epoch 41/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.8675 - acc: 0.6975 - val_loss: 0.8450 - val_acc: 0.6998\n","Epoch 42/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.8441 - acc: 0.7047 - val_loss: 0.8253 - val_acc: 0.7114\n","Epoch 43/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.8266 - acc: 0.7174 - val_loss: 0.8409 - val_acc: 0.7047\n","Epoch 44/60\n","3864/3864 [==============================] - 33s 8ms/step - loss: 0.8356 - acc: 0.7120 - val_loss: 0.8427 - val_acc: 0.7107\n","Epoch 45/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.8225 - acc: 0.7117 - val_loss: 0.8637 - val_acc: 0.6969\n","Epoch 46/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.8300 - acc: 0.7117 - val_loss: 0.8034 - val_acc: 0.7218\n","Epoch 47/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.8077 - acc: 0.7182 - val_loss: 0.7808 - val_acc: 0.7270\n","Epoch 48/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.8058 - acc: 0.7140 - val_loss: 0.7894 - val_acc: 0.7311\n","Epoch 49/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.8046 - acc: 0.7210 - val_loss: 0.8562 - val_acc: 0.6920\n","Epoch 50/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.7955 - acc: 0.7249 - val_loss: 0.8061 - val_acc: 0.7065\n","Epoch 51/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.8146 - acc: 0.7166 - val_loss: 0.7848 - val_acc: 0.7197\n","Epoch 52/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.7887 - acc: 0.7298 - val_loss: 0.7864 - val_acc: 0.7101\n","Epoch 53/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.7795 - acc: 0.7270 - val_loss: 0.7802 - val_acc: 0.7267\n","Epoch 54/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.7715 - acc: 0.7267 - val_loss: 0.7511 - val_acc: 0.7407\n","Epoch 55/60\n","3864/3864 [==============================] - 32s 8ms/step - loss: 0.7797 - acc: 0.7337 - val_loss: 0.7772 - val_acc: 0.7249\n","Epoch 56/60\n","3864/3864 [==============================] - 33s 8ms/step - loss: 0.7606 - acc: 0.7384 - val_loss: 0.7962 - val_acc: 0.7226\n","Epoch 57/60\n","3864/3864 [==============================] - 33s 8ms/step - loss: 0.7757 - acc: 0.7319 - val_loss: 0.7646 - val_acc: 0.7332\n","Epoch 58/60\n","3864/3864 [==============================] - 33s 9ms/step - loss: 0.7536 - acc: 0.7360 - val_loss: 0.7663 - val_acc: 0.7249\n","Epoch 59/60\n","3864/3864 [==============================] - 33s 8ms/step - loss: 0.7521 - acc: 0.7399 - val_loss: 0.7520 - val_acc: 0.7384\n","Epoch 60/60\n","3864/3864 [==============================] - 33s 8ms/step - loss: 0.7634 - acc: 0.7327 - val_loss: 0.7295 - val_acc: 0.7472\n","Accuracy[0.8571] Recall[0.5000] F1[0.5000] at fold[4]\n","______________________________________________________\n","Start Training\n","Train on 3437 samples, validate on 3437 samples\n","Epoch 1/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 2.2133 - acc: 0.2528 - val_loss: 2.0266 - val_acc: 0.3672\n","Epoch 2/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 1.8748 - acc: 0.3736 - val_loss: 1.6679 - val_acc: 0.4326\n","Epoch 3/60\n","3437/3437 [==============================] - 31s 9ms/step - loss: 1.6277 - acc: 0.4283 - val_loss: 1.7411 - val_acc: 0.4175\n","Epoch 4/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 1.5293 - acc: 0.4422 - val_loss: 1.3861 - val_acc: 0.5051\n","Epoch 5/60\n","3437/3437 [==============================] - 29s 9ms/step - loss: 1.4020 - acc: 0.4949 - val_loss: 1.5940 - val_acc: 0.4338\n","Epoch 6/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 1.3525 - acc: 0.5121 - val_loss: 1.4154 - val_acc: 0.4105\n","Epoch 7/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 1.2333 - acc: 0.5403 - val_loss: 1.2475 - val_acc: 0.5124\n","Epoch 8/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 1.2108 - acc: 0.5540 - val_loss: 1.1453 - val_acc: 0.6029\n","Epoch 9/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 1.1667 - acc: 0.5819 - val_loss: 1.1467 - val_acc: 0.5863\n","Epoch 10/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 1.1434 - acc: 0.5749 - val_loss: 1.1051 - val_acc: 0.6151\n","Epoch 11/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 1.1073 - acc: 0.6116 - val_loss: 1.1841 - val_acc: 0.5650\n","Epoch 12/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 1.1046 - acc: 0.6087 - val_loss: 1.1321 - val_acc: 0.5313\n","Epoch 13/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 1.0762 - acc: 0.6119 - val_loss: 1.1108 - val_acc: 0.5953\n","Epoch 14/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 1.0534 - acc: 0.6293 - val_loss: 1.0579 - val_acc: 0.6261\n","Epoch 15/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 1.0318 - acc: 0.6360 - val_loss: 0.9959 - val_acc: 0.6526\n","Epoch 16/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 1.0069 - acc: 0.6424 - val_loss: 1.1492 - val_acc: 0.5857\n","Epoch 17/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 1.0163 - acc: 0.6386 - val_loss: 1.2021 - val_acc: 0.4713\n","Epoch 18/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 1.0012 - acc: 0.6465 - val_loss: 1.0908 - val_acc: 0.5967\n","Epoch 19/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.9857 - acc: 0.6558 - val_loss: 0.9883 - val_acc: 0.6517\n","Epoch 20/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.9666 - acc: 0.6555 - val_loss: 0.9976 - val_acc: 0.6363\n","Epoch 21/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.9640 - acc: 0.6619 - val_loss: 0.9410 - val_acc: 0.6898\n","Epoch 22/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.9488 - acc: 0.6660 - val_loss: 1.0076 - val_acc: 0.6337\n","Epoch 23/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.9409 - acc: 0.6724 - val_loss: 0.9363 - val_acc: 0.6683\n","Epoch 24/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.9378 - acc: 0.6759 - val_loss: 0.9288 - val_acc: 0.6878\n","Epoch 25/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.9243 - acc: 0.6858 - val_loss: 0.9615 - val_acc: 0.6578\n","Epoch 26/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.9215 - acc: 0.6846 - val_loss: 0.9206 - val_acc: 0.6642\n","Epoch 27/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.9146 - acc: 0.6832 - val_loss: 0.9064 - val_acc: 0.6826\n","Epoch 28/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.9031 - acc: 0.6855 - val_loss: 0.9623 - val_acc: 0.6479\n","Epoch 29/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.8932 - acc: 0.6960 - val_loss: 0.9023 - val_acc: 0.6785\n","Epoch 30/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.8923 - acc: 0.6936 - val_loss: 0.8906 - val_acc: 0.6829\n","Epoch 31/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.8862 - acc: 0.6925 - val_loss: 0.8789 - val_acc: 0.7032\n","Epoch 32/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.8719 - acc: 0.7000 - val_loss: 0.9310 - val_acc: 0.6724\n","Epoch 33/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.8699 - acc: 0.7009 - val_loss: 0.8492 - val_acc: 0.7079\n","Epoch 34/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.8547 - acc: 0.7015 - val_loss: 0.8922 - val_acc: 0.6788\n","Epoch 35/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.8551 - acc: 0.7035 - val_loss: 0.8953 - val_acc: 0.6904\n","Epoch 36/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.8460 - acc: 0.7067 - val_loss: 0.8411 - val_acc: 0.7056\n","Epoch 37/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.8485 - acc: 0.7006 - val_loss: 0.8708 - val_acc: 0.6869\n","Epoch 38/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.8381 - acc: 0.7035 - val_loss: 0.8744 - val_acc: 0.6741\n","Epoch 39/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.8393 - acc: 0.7090 - val_loss: 0.9254 - val_acc: 0.6625\n","Epoch 40/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.8261 - acc: 0.7088 - val_loss: 0.8293 - val_acc: 0.7061\n","Epoch 41/60\n","3437/3437 [==============================] - 30s 9ms/step - loss: 0.8245 - acc: 0.7105 - val_loss: 0.8100 - val_acc: 0.7114\n","Epoch 42/60\n","3437/3437 [==============================] - 29s 9ms/step - loss: 0.8161 - acc: 0.7137 - val_loss: 0.8538 - val_acc: 0.6811\n","Epoch 43/60\n","3437/3437 [==============================] - 29s 9ms/step - loss: 0.8181 - acc: 0.7108 - val_loss: 0.8396 - val_acc: 0.7006\n","Epoch 44/60\n","3437/3437 [==============================] - 29s 9ms/step - loss: 0.8009 - acc: 0.7195 - val_loss: 0.8322 - val_acc: 0.7128\n","Epoch 45/60\n","3437/3437 [==============================] - 29s 8ms/step - loss: 0.8044 - acc: 0.7213 - val_loss: 0.7965 - val_acc: 0.7213\n","Epoch 46/60\n","3437/3437 [==============================] - 29s 8ms/step - loss: 0.7903 - acc: 0.7224 - val_loss: 0.8570 - val_acc: 0.6788\n","Epoch 47/60\n","3437/3437 [==============================] - 29s 8ms/step - loss: 0.7931 - acc: 0.7195 - val_loss: 0.9655 - val_acc: 0.6238\n","Epoch 48/60\n","3437/3437 [==============================] - 29s 8ms/step - loss: 0.7974 - acc: 0.7216 - val_loss: 0.7889 - val_acc: 0.7294\n","Epoch 49/60\n","3437/3437 [==============================] - 29s 8ms/step - loss: 0.7750 - acc: 0.7329 - val_loss: 0.7703 - val_acc: 0.7306\n","Epoch 50/60\n","3437/3437 [==============================] - 29s 8ms/step - loss: 0.7713 - acc: 0.7317 - val_loss: 0.7700 - val_acc: 0.7364\n","Epoch 51/60\n","3437/3437 [==============================] - 29s 8ms/step - loss: 0.7689 - acc: 0.7306 - val_loss: 0.7698 - val_acc: 0.7288\n","Epoch 52/60\n","3437/3437 [==============================] - 29s 9ms/step - loss: 0.7634 - acc: 0.7288 - val_loss: 0.8637 - val_acc: 0.6692\n","Epoch 53/60\n","3437/3437 [==============================] - 29s 8ms/step - loss: 0.7610 - acc: 0.7379 - val_loss: 0.7730 - val_acc: 0.7227\n","Epoch 54/60\n","3437/3437 [==============================] - 29s 8ms/step - loss: 0.7506 - acc: 0.7312 - val_loss: 0.7592 - val_acc: 0.7207\n","Epoch 55/60\n","3437/3437 [==============================] - 29s 9ms/step - loss: 0.7561 - acc: 0.7347 - val_loss: 0.8030 - val_acc: 0.7108\n","Epoch 56/60\n","3437/3437 [==============================] - 29s 9ms/step - loss: 0.7500 - acc: 0.7390 - val_loss: 0.7792 - val_acc: 0.7122\n","Epoch 57/60\n","3437/3437 [==============================] - 29s 8ms/step - loss: 0.7398 - acc: 0.7495 - val_loss: 0.7396 - val_acc: 0.7329\n","Epoch 58/60\n","3437/3437 [==============================] - 29s 9ms/step - loss: 0.7331 - acc: 0.7454 - val_loss: 0.8287 - val_acc: 0.6983\n","Epoch 59/60\n","3437/3437 [==============================] - 29s 9ms/step - loss: 0.7298 - acc: 0.7457 - val_loss: 0.7151 - val_acc: 0.7576\n","Epoch 60/60\n","3437/3437 [==============================] - 29s 9ms/step - loss: 0.7222 - acc: 0.7501 - val_loss: 0.7356 - val_acc: 0.7349\n","Accuracy[0.6613] Recall[0.5563] F1[0.5414] at fold[5]\n","______________________________________________________\n","Start Training\n","Train on 3594 samples, validate on 3594 samples\n","Epoch 1/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 2.4262 - acc: 0.2040 - val_loss: 2.1479 - val_acc: 0.3472\n","Epoch 2/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.9342 - acc: 0.3895 - val_loss: 1.7502 - val_acc: 0.3817\n","Epoch 3/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.6486 - acc: 0.4399 - val_loss: 1.5433 - val_acc: 0.4686\n","Epoch 4/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.4660 - acc: 0.4858 - val_loss: 1.4545 - val_acc: 0.4521\n","Epoch 5/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.3699 - acc: 0.5181 - val_loss: 1.3503 - val_acc: 0.5442\n","Epoch 6/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.3091 - acc: 0.5320 - val_loss: 1.3511 - val_acc: 0.5103\n","Epoch 7/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.2590 - acc: 0.5440 - val_loss: 1.1638 - val_acc: 0.5715\n","Epoch 8/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.1976 - acc: 0.5832 - val_loss: 1.1394 - val_acc: 0.6336\n","Epoch 9/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.1631 - acc: 0.5865 - val_loss: 1.1279 - val_acc: 0.5982\n","Epoch 10/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.1503 - acc: 0.5968 - val_loss: 1.1071 - val_acc: 0.5843\n","Epoch 11/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.1053 - acc: 0.6141 - val_loss: 1.0897 - val_acc: 0.6369\n","Epoch 12/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.0857 - acc: 0.6235 - val_loss: 1.0679 - val_acc: 0.6305\n","Epoch 13/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.0702 - acc: 0.6208 - val_loss: 1.0563 - val_acc: 0.6138\n","Epoch 14/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.0577 - acc: 0.6291 - val_loss: 1.0188 - val_acc: 0.6564\n","Epoch 15/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.0457 - acc: 0.6291 - val_loss: 1.0061 - val_acc: 0.6636\n","Epoch 16/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.0345 - acc: 0.6349 - val_loss: 1.0009 - val_acc: 0.6427\n","Epoch 17/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.0119 - acc: 0.6500 - val_loss: 0.9926 - val_acc: 0.6597\n","Epoch 18/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 1.0160 - acc: 0.6405 - val_loss: 0.9771 - val_acc: 0.6614\n","Epoch 19/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 0.9909 - acc: 0.6553 - val_loss: 0.9516 - val_acc: 0.6772\n","Epoch 20/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 0.9873 - acc: 0.6533 - val_loss: 0.9669 - val_acc: 0.6647\n","Epoch 21/60\n","3594/3594 [==============================] - 31s 9ms/step - loss: 0.9704 - acc: 0.6689 - val_loss: 0.9578 - val_acc: 0.6672\n","Epoch 22/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.9576 - acc: 0.6630 - val_loss: 0.9497 - val_acc: 0.6700\n","Epoch 23/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.9647 - acc: 0.6583 - val_loss: 0.9326 - val_acc: 0.6786\n","Epoch 24/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.9504 - acc: 0.6586 - val_loss: 0.9199 - val_acc: 0.6825\n","Epoch 25/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.9412 - acc: 0.6681 - val_loss: 0.9305 - val_acc: 0.6717\n","Epoch 26/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.9339 - acc: 0.6672 - val_loss: 0.9054 - val_acc: 0.6800\n","Epoch 27/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.9198 - acc: 0.6822 - val_loss: 0.9362 - val_acc: 0.6817\n","Epoch 28/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.9230 - acc: 0.6795 - val_loss: 0.9576 - val_acc: 0.6425\n","Epoch 29/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.9139 - acc: 0.6792 - val_loss: 0.8819 - val_acc: 0.6937\n","Epoch 30/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.9030 - acc: 0.6845 - val_loss: 0.9042 - val_acc: 0.6692\n","Epoch 31/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.9093 - acc: 0.6764 - val_loss: 0.8742 - val_acc: 0.6912\n","Epoch 32/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8956 - acc: 0.6859 - val_loss: 0.8793 - val_acc: 0.6881\n","Epoch 33/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8839 - acc: 0.6861 - val_loss: 0.8946 - val_acc: 0.6795\n","Epoch 34/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8858 - acc: 0.6928 - val_loss: 0.8728 - val_acc: 0.6964\n","Epoch 35/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8760 - acc: 0.6912 - val_loss: 0.8621 - val_acc: 0.6945\n","Epoch 36/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8624 - acc: 0.6942 - val_loss: 0.8470 - val_acc: 0.7148\n","Epoch 37/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8629 - acc: 0.6984 - val_loss: 0.8269 - val_acc: 0.7134\n","Epoch 38/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8624 - acc: 0.6992 - val_loss: 0.8344 - val_acc: 0.7104\n","Epoch 39/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8530 - acc: 0.6953 - val_loss: 0.8403 - val_acc: 0.7092\n","Epoch 40/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8469 - acc: 0.7014 - val_loss: 0.8193 - val_acc: 0.7126\n","Epoch 41/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8400 - acc: 0.7051 - val_loss: 0.8274 - val_acc: 0.7037\n","Epoch 42/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8378 - acc: 0.7073 - val_loss: 0.8388 - val_acc: 0.7078\n","Epoch 43/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8341 - acc: 0.7059 - val_loss: 0.8305 - val_acc: 0.7012\n","Epoch 44/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8363 - acc: 0.7056 - val_loss: 0.8158 - val_acc: 0.7045\n","Epoch 45/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8162 - acc: 0.7126 - val_loss: 0.8001 - val_acc: 0.7120\n","Epoch 46/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8152 - acc: 0.7195 - val_loss: 0.8520 - val_acc: 0.6928\n","Epoch 47/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8116 - acc: 0.7137 - val_loss: 0.7832 - val_acc: 0.7334\n","Epoch 48/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.8096 - acc: 0.7170 - val_loss: 0.8052 - val_acc: 0.7092\n","Epoch 49/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.7997 - acc: 0.7165 - val_loss: 0.7772 - val_acc: 0.7373\n","Epoch 50/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.7912 - acc: 0.7295 - val_loss: 0.7810 - val_acc: 0.7257\n","Epoch 51/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.7922 - acc: 0.7198 - val_loss: 0.7979 - val_acc: 0.7104\n","Epoch 52/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.7963 - acc: 0.7204 - val_loss: 0.7732 - val_acc: 0.7262\n","Epoch 53/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.7875 - acc: 0.7287 - val_loss: 0.7573 - val_acc: 0.7487\n","Epoch 54/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.7724 - acc: 0.7346 - val_loss: 0.7504 - val_acc: 0.7407\n","Epoch 55/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.7722 - acc: 0.7332 - val_loss: 0.8365 - val_acc: 0.6873\n","Epoch 56/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.7658 - acc: 0.7340 - val_loss: 0.7687 - val_acc: 0.7429\n","Epoch 57/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.7685 - acc: 0.7332 - val_loss: 0.7492 - val_acc: 0.7396\n","Epoch 58/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.7582 - acc: 0.7371 - val_loss: 0.7649 - val_acc: 0.7282\n","Epoch 59/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.7525 - acc: 0.7410 - val_loss: 0.7833 - val_acc: 0.7206\n","Epoch 60/60\n","3594/3594 [==============================] - 30s 8ms/step - loss: 0.7550 - acc: 0.7373 - val_loss: 0.7435 - val_acc: 0.7418\n","Accuracy[0.6173] Recall[0.6311] F1[0.5610] at fold[6]\n","______________________________________________________\n","Start Training\n","Train on 3585 samples, validate on 3585 samples\n","Epoch 1/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 2.3326 - acc: 0.2748 - val_loss: 2.1768 - val_acc: 0.3774\n","Epoch 2/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 2.1171 - acc: 0.3478 - val_loss: 2.0491 - val_acc: 0.2895\n","Epoch 3/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 1.8700 - acc: 0.3897 - val_loss: 1.7382 - val_acc: 0.4215\n","Epoch 4/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 1.6182 - acc: 0.4477 - val_loss: 1.5787 - val_acc: 0.4594\n","Epoch 5/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 1.4516 - acc: 0.4893 - val_loss: 1.3859 - val_acc: 0.5199\n","Epoch 6/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 1.3722 - acc: 0.5194 - val_loss: 1.2732 - val_acc: 0.5688\n","Epoch 7/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 1.2867 - acc: 0.5425 - val_loss: 1.2677 - val_acc: 0.5384\n","Epoch 8/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 1.2277 - acc: 0.5727 - val_loss: 1.3223 - val_acc: 0.5372\n","Epoch 9/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 1.1889 - acc: 0.5796 - val_loss: 1.1203 - val_acc: 0.6059\n","Epoch 10/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 1.1811 - acc: 0.5802 - val_loss: 1.1037 - val_acc: 0.6165\n","Epoch 11/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 1.1334 - acc: 0.5994 - val_loss: 1.0683 - val_acc: 0.6212\n","Epoch 12/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 1.1080 - acc: 0.6179 - val_loss: 1.1720 - val_acc: 0.5847\n","Epoch 13/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 1.0836 - acc: 0.6206 - val_loss: 1.0496 - val_acc: 0.6382\n","Epoch 14/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 1.0656 - acc: 0.6326 - val_loss: 1.0684 - val_acc: 0.6494\n","Epoch 15/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 1.0497 - acc: 0.6354 - val_loss: 1.0184 - val_acc: 0.6407\n","Epoch 16/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 1.0208 - acc: 0.6441 - val_loss: 1.0014 - val_acc: 0.6572\n","Epoch 17/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 1.0107 - acc: 0.6483 - val_loss: 1.0060 - val_acc: 0.6404\n","Epoch 18/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.9998 - acc: 0.6583 - val_loss: 0.9962 - val_acc: 0.6583\n","Epoch 19/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.9910 - acc: 0.6608 - val_loss: 1.0319 - val_acc: 0.6580\n","Epoch 20/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.9851 - acc: 0.6575 - val_loss: 1.0528 - val_acc: 0.6195\n","Epoch 21/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.9723 - acc: 0.6591 - val_loss: 1.0073 - val_acc: 0.6536\n","Epoch 22/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.9584 - acc: 0.6653 - val_loss: 0.9708 - val_acc: 0.6647\n","Epoch 23/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.9555 - acc: 0.6658 - val_loss: 0.9344 - val_acc: 0.6798\n","Epoch 24/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.9317 - acc: 0.6781 - val_loss: 0.8960 - val_acc: 0.6923\n","Epoch 25/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.9291 - acc: 0.6773 - val_loss: 0.9394 - val_acc: 0.6547\n","Epoch 26/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.9226 - acc: 0.6812 - val_loss: 0.9063 - val_acc: 0.6806\n","Epoch 27/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.9152 - acc: 0.6770 - val_loss: 0.8872 - val_acc: 0.6987\n","Epoch 28/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.9099 - acc: 0.6868 - val_loss: 0.8898 - val_acc: 0.6915\n","Epoch 29/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.9188 - acc: 0.6817 - val_loss: 0.8718 - val_acc: 0.6976\n","Epoch 30/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8919 - acc: 0.6918 - val_loss: 0.8857 - val_acc: 0.7068\n","Epoch 31/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8885 - acc: 0.6954 - val_loss: 0.8526 - val_acc: 0.7119\n","Epoch 32/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8906 - acc: 0.6960 - val_loss: 0.8954 - val_acc: 0.6722\n","Epoch 33/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8839 - acc: 0.6890 - val_loss: 0.8381 - val_acc: 0.7169\n","Epoch 34/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8606 - acc: 0.6929 - val_loss: 0.8872 - val_acc: 0.6954\n","Epoch 35/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8683 - acc: 0.6968 - val_loss: 0.8710 - val_acc: 0.6912\n","Epoch 36/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8574 - acc: 0.6957 - val_loss: 0.8220 - val_acc: 0.7202\n","Epoch 37/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8384 - acc: 0.7043 - val_loss: 0.8412 - val_acc: 0.7121\n","Epoch 38/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8546 - acc: 0.6996 - val_loss: 0.8164 - val_acc: 0.7222\n","Epoch 39/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8376 - acc: 0.7071 - val_loss: 0.8060 - val_acc: 0.7172\n","Epoch 40/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8393 - acc: 0.7032 - val_loss: 0.8158 - val_acc: 0.7183\n","Epoch 41/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8281 - acc: 0.7169 - val_loss: 0.8249 - val_acc: 0.7202\n","Epoch 42/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8209 - acc: 0.7180 - val_loss: 0.7980 - val_acc: 0.7286\n","Epoch 43/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8154 - acc: 0.7194 - val_loss: 0.7987 - val_acc: 0.7247\n","Epoch 44/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8085 - acc: 0.7227 - val_loss: 0.7963 - val_acc: 0.7180\n","Epoch 45/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8209 - acc: 0.7188 - val_loss: 0.7929 - val_acc: 0.7250\n","Epoch 46/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8151 - acc: 0.7119 - val_loss: 0.8004 - val_acc: 0.7213\n","Epoch 47/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.8022 - acc: 0.7269 - val_loss: 0.7746 - val_acc: 0.7314\n","Epoch 48/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.7860 - acc: 0.7278 - val_loss: 0.7587 - val_acc: 0.7445\n","Epoch 49/60\n","3585/3585 [==============================] - 31s 9ms/step - loss: 0.7872 - acc: 0.7227 - val_loss: 0.7730 - val_acc: 0.7322\n","Epoch 50/60\n","3585/3585 [==============================] - 31s 9ms/step - loss: 0.7890 - acc: 0.7358 - val_loss: 0.7853 - val_acc: 0.7361\n","Epoch 51/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.7692 - acc: 0.7319 - val_loss: 0.7648 - val_acc: 0.7428\n","Epoch 52/60\n","3585/3585 [==============================] - 31s 9ms/step - loss: 0.7765 - acc: 0.7350 - val_loss: 0.7665 - val_acc: 0.7283\n","Epoch 53/60\n","3585/3585 [==============================] - 31s 9ms/step - loss: 0.7702 - acc: 0.7378 - val_loss: 0.7388 - val_acc: 0.7529\n","Epoch 54/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.7606 - acc: 0.7317 - val_loss: 0.7355 - val_acc: 0.7568\n","Epoch 55/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.7499 - acc: 0.7473 - val_loss: 0.7757 - val_acc: 0.7238\n","Epoch 56/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.7450 - acc: 0.7445 - val_loss: 0.8058 - val_acc: 0.7230\n","Epoch 57/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.7521 - acc: 0.7381 - val_loss: 0.7140 - val_acc: 0.7615\n","Epoch 58/60\n","3585/3585 [==============================] - 30s 8ms/step - loss: 0.7343 - acc: 0.7442 - val_loss: 0.7092 - val_acc: 0.7562\n","Epoch 59/60\n","3585/3585 [==============================] - 31s 9ms/step - loss: 0.7268 - acc: 0.7540 - val_loss: 0.7275 - val_acc: 0.7537\n","Epoch 60/60\n","3585/3585 [==============================] - 31s 9ms/step - loss: 0.7289 - acc: 0.7487 - val_loss: 0.7410 - val_acc: 0.7392\n","Accuracy[0.4301] Recall[0.3319] F1[0.2902] at fold[7]\n","______________________________________________________\n","Start Training\n","Train on 3846 samples, validate on 3846 samples\n","Epoch 1/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 2.4277 - acc: 0.2184 - val_loss: 2.2185 - val_acc: 0.3437\n","Epoch 2/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 2.1403 - acc: 0.3432 - val_loss: 1.9423 - val_acc: 0.4225\n","Epoch 3/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 1.7837 - acc: 0.4285 - val_loss: 1.6058 - val_acc: 0.4353\n","Epoch 4/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 1.5183 - acc: 0.4769 - val_loss: 1.4726 - val_acc: 0.4272\n","Epoch 5/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 1.3877 - acc: 0.5036 - val_loss: 1.3677 - val_acc: 0.4826\n","Epoch 6/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 1.3033 - acc: 0.5343 - val_loss: 1.2796 - val_acc: 0.5218\n","Epoch 7/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 1.2459 - acc: 0.5465 - val_loss: 1.2024 - val_acc: 0.5705\n","Epoch 8/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 1.1977 - acc: 0.5634 - val_loss: 1.2120 - val_acc: 0.5603\n","Epoch 9/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 1.1698 - acc: 0.5783 - val_loss: 1.1319 - val_acc: 0.6108\n","Epoch 10/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 1.1403 - acc: 0.5944 - val_loss: 1.1327 - val_acc: 0.5546\n","Epoch 11/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 1.1002 - acc: 0.6043 - val_loss: 1.1835 - val_acc: 0.5744\n","Epoch 12/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 1.1113 - acc: 0.5952 - val_loss: 1.1158 - val_acc: 0.5567\n","Epoch 13/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 1.0728 - acc: 0.6121 - val_loss: 1.0352 - val_acc: 0.6368\n","Epoch 14/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 1.0475 - acc: 0.6336 - val_loss: 1.0339 - val_acc: 0.6323\n","Epoch 15/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 1.0357 - acc: 0.6336 - val_loss: 1.0493 - val_acc: 0.6373\n","Epoch 16/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 1.0247 - acc: 0.6362 - val_loss: 1.0654 - val_acc: 0.5991\n","Epoch 17/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 1.0140 - acc: 0.6401 - val_loss: 1.0268 - val_acc: 0.6227\n","Epoch 18/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 0.9928 - acc: 0.6492 - val_loss: 1.0059 - val_acc: 0.6001\n","Epoch 19/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 0.9798 - acc: 0.6505 - val_loss: 1.0221 - val_acc: 0.6165\n","Epoch 20/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 0.9743 - acc: 0.6518 - val_loss: 0.9436 - val_acc: 0.6589\n","Epoch 21/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 0.9580 - acc: 0.6635 - val_loss: 0.9904 - val_acc: 0.6417\n","Epoch 22/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 0.9453 - acc: 0.6752 - val_loss: 1.2094 - val_acc: 0.5120\n","Epoch 23/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.9429 - acc: 0.6646 - val_loss: 0.9372 - val_acc: 0.6500\n","Epoch 24/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.9280 - acc: 0.6700 - val_loss: 0.9417 - val_acc: 0.6625\n","Epoch 25/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.9261 - acc: 0.6750 - val_loss: 0.9906 - val_acc: 0.6313\n","Epoch 26/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.9179 - acc: 0.6687 - val_loss: 0.9519 - val_acc: 0.6352\n","Epoch 27/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.9032 - acc: 0.6771 - val_loss: 0.9012 - val_acc: 0.6583\n","Epoch 28/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.8944 - acc: 0.6885 - val_loss: 0.9580 - val_acc: 0.6274\n","Epoch 29/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 0.8766 - acc: 0.6986 - val_loss: 0.8858 - val_acc: 0.6976\n","Epoch 30/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 0.8876 - acc: 0.6799 - val_loss: 0.8736 - val_acc: 0.6815\n","Epoch 31/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.8668 - acc: 0.6893 - val_loss: 0.8855 - val_acc: 0.6617\n","Epoch 32/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.8682 - acc: 0.6927 - val_loss: 0.9160 - val_acc: 0.6573\n","Epoch 33/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.8546 - acc: 0.7002 - val_loss: 0.8437 - val_acc: 0.6945\n","Epoch 34/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.8548 - acc: 0.6973 - val_loss: 0.8463 - val_acc: 0.6994\n","Epoch 35/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.8372 - acc: 0.7080 - val_loss: 0.8754 - val_acc: 0.7168\n","Epoch 36/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.8362 - acc: 0.7098 - val_loss: 0.8439 - val_acc: 0.7018\n","Epoch 37/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.8322 - acc: 0.7088 - val_loss: 0.8756 - val_acc: 0.6724\n","Epoch 38/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.8251 - acc: 0.7171 - val_loss: 0.8652 - val_acc: 0.6997\n","Epoch 39/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.8095 - acc: 0.7259 - val_loss: 0.8354 - val_acc: 0.6872\n","Epoch 40/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.8082 - acc: 0.7111 - val_loss: 0.8097 - val_acc: 0.7012\n","Epoch 41/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.8000 - acc: 0.7181 - val_loss: 0.7973 - val_acc: 0.7166\n","Epoch 42/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.8118 - acc: 0.7132 - val_loss: 0.8993 - val_acc: 0.6485\n","Epoch 43/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.7921 - acc: 0.7241 - val_loss: 0.8012 - val_acc: 0.7007\n","Epoch 44/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.7856 - acc: 0.7254 - val_loss: 0.7957 - val_acc: 0.7192\n","Epoch 45/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.7853 - acc: 0.7228 - val_loss: 0.8278 - val_acc: 0.7067\n","Epoch 46/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.7761 - acc: 0.7317 - val_loss: 0.7977 - val_acc: 0.6856\n","Epoch 47/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.7785 - acc: 0.7288 - val_loss: 0.7464 - val_acc: 0.7543\n","Epoch 48/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.7658 - acc: 0.7348 - val_loss: 0.7409 - val_acc: 0.7548\n","Epoch 49/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.7621 - acc: 0.7361 - val_loss: 0.7487 - val_acc: 0.7309\n","Epoch 50/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.7634 - acc: 0.7335 - val_loss: 0.8171 - val_acc: 0.7158\n","Epoch 51/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.7565 - acc: 0.7434 - val_loss: 0.7314 - val_acc: 0.7538\n","Epoch 52/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.7489 - acc: 0.7376 - val_loss: 0.8788 - val_acc: 0.6669\n","Epoch 53/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.7527 - acc: 0.7376 - val_loss: 0.7797 - val_acc: 0.7350\n","Epoch 54/60\n","3846/3846 [==============================] - 32s 8ms/step - loss: 0.7391 - acc: 0.7423 - val_loss: 0.7286 - val_acc: 0.7454\n","Epoch 55/60\n","3846/3846 [==============================] - 33s 8ms/step - loss: 0.7231 - acc: 0.7525 - val_loss: 0.7488 - val_acc: 0.7462\n","Epoch 56/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 0.7201 - acc: 0.7559 - val_loss: 0.6997 - val_acc: 0.7626\n","Epoch 57/60\n","3846/3846 [==============================] - 33s 8ms/step - loss: 0.7195 - acc: 0.7556 - val_loss: 0.7641 - val_acc: 0.7285\n","Epoch 58/60\n","3846/3846 [==============================] - 33s 8ms/step - loss: 0.7205 - acc: 0.7488 - val_loss: 0.7396 - val_acc: 0.7293\n","Epoch 59/60\n","3846/3846 [==============================] - 33s 9ms/step - loss: 0.7158 - acc: 0.7538 - val_loss: 0.7348 - val_acc: 0.7319\n","Epoch 60/60\n","3846/3846 [==============================] - 33s 8ms/step - loss: 0.7067 - acc: 0.7579 - val_loss: 0.8251 - val_acc: 0.6994\n","Accuracy[0.7200] Recall[0.4676] F1[0.5054] at fold[8]\n","______________________________________________________\n","Start Training\n","Train on 3705 samples, validate on 3705 samples\n","Epoch 1/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 2.2333 - acc: 0.3063 - val_loss: 2.0231 - val_acc: 0.3625\n","Epoch 2/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 1.8573 - acc: 0.4049 - val_loss: 1.9111 - val_acc: 0.3695\n","Epoch 3/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.6834 - acc: 0.4391 - val_loss: 1.7121 - val_acc: 0.4173\n","Epoch 4/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.5582 - acc: 0.4683 - val_loss: 1.6296 - val_acc: 0.4211\n","Epoch 5/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.4881 - acc: 0.4804 - val_loss: 1.5532 - val_acc: 0.4529\n","Epoch 6/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.4218 - acc: 0.4961 - val_loss: 1.5251 - val_acc: 0.4521\n","Epoch 7/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.3808 - acc: 0.5150 - val_loss: 1.3579 - val_acc: 0.5085\n","Epoch 8/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.3259 - acc: 0.5320 - val_loss: 1.4811 - val_acc: 0.5018\n","Epoch 9/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.2907 - acc: 0.5452 - val_loss: 1.4803 - val_acc: 0.4059\n","Epoch 10/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.2628 - acc: 0.5601 - val_loss: 1.3974 - val_acc: 0.4904\n","Epoch 11/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.2329 - acc: 0.5779 - val_loss: 1.5498 - val_acc: 0.4605\n","Epoch 12/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.2180 - acc: 0.5919 - val_loss: 1.3142 - val_acc: 0.5808\n","Epoch 13/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.1940 - acc: 0.5987 - val_loss: 1.2417 - val_acc: 0.5665\n","Epoch 14/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.1744 - acc: 0.5922 - val_loss: 1.1871 - val_acc: 0.5700\n","Epoch 15/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 1.1609 - acc: 0.6040 - val_loss: 1.2599 - val_acc: 0.5533\n","Epoch 16/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 1.1460 - acc: 0.6103 - val_loss: 1.1629 - val_acc: 0.5892\n","Epoch 17/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.1412 - acc: 0.6076 - val_loss: 1.2579 - val_acc: 0.5579\n","Epoch 18/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 1.1328 - acc: 0.6113 - val_loss: 1.1970 - val_acc: 0.5884\n","Epoch 19/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.1152 - acc: 0.6143 - val_loss: 1.2069 - val_acc: 0.5760\n","Epoch 20/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 1.1076 - acc: 0.6148 - val_loss: 1.1463 - val_acc: 0.5987\n","Epoch 21/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 1.0981 - acc: 0.6232 - val_loss: 1.1691 - val_acc: 0.5825\n","Epoch 22/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 1.0885 - acc: 0.6283 - val_loss: 1.1239 - val_acc: 0.5960\n","Epoch 23/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 1.0826 - acc: 0.6265 - val_loss: 1.1313 - val_acc: 0.6229\n","Epoch 24/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.0752 - acc: 0.6335 - val_loss: 1.1381 - val_acc: 0.6065\n","Epoch 25/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.0631 - acc: 0.6399 - val_loss: 1.1183 - val_acc: 0.5911\n","Epoch 26/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.0616 - acc: 0.6343 - val_loss: 1.1538 - val_acc: 0.5706\n","Epoch 27/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.0534 - acc: 0.6386 - val_loss: 1.2089 - val_acc: 0.5808\n","Epoch 28/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.0499 - acc: 0.6413 - val_loss: 1.0699 - val_acc: 0.6318\n","Epoch 29/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.0418 - acc: 0.6418 - val_loss: 1.0650 - val_acc: 0.6305\n","Epoch 30/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.0362 - acc: 0.6397 - val_loss: 1.0568 - val_acc: 0.6343\n","Epoch 31/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.0287 - acc: 0.6467 - val_loss: 1.0602 - val_acc: 0.6267\n","Epoch 32/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.0216 - acc: 0.6470 - val_loss: 1.0584 - val_acc: 0.6421\n","Epoch 33/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.0182 - acc: 0.6494 - val_loss: 1.1243 - val_acc: 0.6065\n","Epoch 34/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.0142 - acc: 0.6537 - val_loss: 1.0340 - val_acc: 0.6221\n","Epoch 35/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 1.0083 - acc: 0.6526 - val_loss: 1.0248 - val_acc: 0.6429\n","Epoch 36/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 1.0026 - acc: 0.6599 - val_loss: 1.0305 - val_acc: 0.6370\n","Epoch 37/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.9986 - acc: 0.6596 - val_loss: 1.0803 - val_acc: 0.6024\n","Epoch 38/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 0.9923 - acc: 0.6534 - val_loss: 1.1754 - val_acc: 0.5860\n","Epoch 39/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.9932 - acc: 0.6605 - val_loss: 1.0274 - val_acc: 0.6238\n","Epoch 40/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.9885 - acc: 0.6545 - val_loss: 1.0455 - val_acc: 0.6035\n","Epoch 41/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.9799 - acc: 0.6596 - val_loss: 1.0427 - val_acc: 0.6375\n","Epoch 42/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.9723 - acc: 0.6664 - val_loss: 1.0424 - val_acc: 0.6305\n","Epoch 43/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.9689 - acc: 0.6699 - val_loss: 0.9693 - val_acc: 0.6740\n","Epoch 44/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.9679 - acc: 0.6659 - val_loss: 0.9770 - val_acc: 0.6596\n","Epoch 45/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.9620 - acc: 0.6715 - val_loss: 1.1391 - val_acc: 0.5914\n","Epoch 46/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.9615 - acc: 0.6661 - val_loss: 1.0244 - val_acc: 0.6224\n","Epoch 47/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.9514 - acc: 0.6777 - val_loss: 0.9490 - val_acc: 0.6775\n","Epoch 48/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 0.9495 - acc: 0.6715 - val_loss: 1.2035 - val_acc: 0.5730\n","Epoch 49/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.9469 - acc: 0.6764 - val_loss: 0.9803 - val_acc: 0.6497\n","Epoch 50/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.9417 - acc: 0.6718 - val_loss: 0.9722 - val_acc: 0.6645\n","Epoch 51/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.9355 - acc: 0.6777 - val_loss: 0.9237 - val_acc: 0.6823\n","Epoch 52/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.9355 - acc: 0.6704 - val_loss: 1.0480 - val_acc: 0.6389\n","Epoch 53/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 0.9336 - acc: 0.6788 - val_loss: 0.9646 - val_acc: 0.6478\n","Epoch 54/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.9258 - acc: 0.6772 - val_loss: 0.9313 - val_acc: 0.6810\n","Epoch 55/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 0.9258 - acc: 0.6802 - val_loss: 0.9759 - val_acc: 0.6575\n","Epoch 56/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 0.9215 - acc: 0.6799 - val_loss: 1.0485 - val_acc: 0.6162\n","Epoch 57/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.9143 - acc: 0.6788 - val_loss: 1.0074 - val_acc: 0.6418\n","Epoch 58/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 0.9137 - acc: 0.6831 - val_loss: 0.9250 - val_acc: 0.6772\n","Epoch 59/60\n","3705/3705 [==============================] - 32s 9ms/step - loss: 0.9094 - acc: 0.6831 - val_loss: 1.1083 - val_acc: 0.5960\n","Epoch 60/60\n","3705/3705 [==============================] - 31s 8ms/step - loss: 0.8997 - acc: 0.6901 - val_loss: 0.8977 - val_acc: 0.6939\n","Accuracy[0.5783] Recall[0.4309] F1[0.4397] at fold[9]\n","______________________________________________________\n","Start Training\n","Train on 3707 samples, validate on 3707 samples\n","Epoch 1/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 2.4079 - acc: 0.2250 - val_loss: 2.1834 - val_acc: 0.2919\n","Epoch 2/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 1.9863 - acc: 0.3636 - val_loss: 2.0970 - val_acc: 0.3434\n","Epoch 3/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 1.7245 - acc: 0.4192 - val_loss: 2.4928 - val_acc: 0.1597\n","Epoch 4/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 1.5672 - acc: 0.4653 - val_loss: 1.7264 - val_acc: 0.3852\n","Epoch 5/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 1.4266 - acc: 0.5058 - val_loss: 1.7469 - val_acc: 0.4529\n","Epoch 6/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 1.3820 - acc: 0.5085 - val_loss: 1.4346 - val_acc: 0.4365\n","Epoch 7/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 1.3307 - acc: 0.5198 - val_loss: 1.4517 - val_acc: 0.4980\n","Epoch 8/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 1.2862 - acc: 0.5484 - val_loss: 1.3393 - val_acc: 0.5511\n","Epoch 9/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 1.2519 - acc: 0.5573 - val_loss: 1.6302 - val_acc: 0.4076\n","Epoch 10/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 1.2294 - acc: 0.5730 - val_loss: 1.3989 - val_acc: 0.5139\n","Epoch 11/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 1.1992 - acc: 0.5813 - val_loss: 1.4441 - val_acc: 0.4683\n","Epoch 12/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 1.1954 - acc: 0.5765 - val_loss: 1.9809 - val_acc: 0.3890\n","Epoch 13/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 1.1666 - acc: 0.6048 - val_loss: 1.2086 - val_acc: 0.5357\n","Epoch 14/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 1.1342 - acc: 0.6043 - val_loss: 1.3102 - val_acc: 0.5576\n","Epoch 15/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 1.1179 - acc: 0.6164 - val_loss: 1.3096 - val_acc: 0.5414\n","Epoch 16/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 1.1136 - acc: 0.6148 - val_loss: 1.2739 - val_acc: 0.5258\n","Epoch 17/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 1.1109 - acc: 0.6118 - val_loss: 1.1461 - val_acc: 0.5805\n","Epoch 18/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 1.0755 - acc: 0.6307 - val_loss: 1.1202 - val_acc: 0.6035\n","Epoch 19/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 1.0827 - acc: 0.6258 - val_loss: 1.2569 - val_acc: 0.5239\n","Epoch 20/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 1.0585 - acc: 0.6366 - val_loss: 1.6104 - val_acc: 0.4071\n","Epoch 21/60\n","3707/3707 [==============================] - 32s 8ms/step - loss: 1.0591 - acc: 0.6415 - val_loss: 1.1326 - val_acc: 0.5827\n","Epoch 22/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 1.0331 - acc: 0.6517 - val_loss: 1.4827 - val_acc: 0.4618\n","Epoch 23/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 1.0338 - acc: 0.6531 - val_loss: 1.1856 - val_acc: 0.5549\n","Epoch 24/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 1.0205 - acc: 0.6507 - val_loss: 1.1415 - val_acc: 0.5587\n","Epoch 25/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 1.0100 - acc: 0.6625 - val_loss: 1.0335 - val_acc: 0.6347\n","Epoch 26/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 1.0056 - acc: 0.6531 - val_loss: 1.2864 - val_acc: 0.5352\n","Epoch 27/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 1.0033 - acc: 0.6552 - val_loss: 1.2654 - val_acc: 0.5692\n","Epoch 28/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.9944 - acc: 0.6623 - val_loss: 1.1808 - val_acc: 0.5935\n","Epoch 29/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 0.9854 - acc: 0.6685 - val_loss: 1.3169 - val_acc: 0.5212\n","Epoch 30/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 0.9764 - acc: 0.6695 - val_loss: 1.2624 - val_acc: 0.5581\n","Epoch 31/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 0.9715 - acc: 0.6722 - val_loss: 1.0829 - val_acc: 0.6059\n","Epoch 32/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 0.9568 - acc: 0.6741 - val_loss: 1.0970 - val_acc: 0.6094\n","Epoch 33/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.9560 - acc: 0.6779 - val_loss: 1.1715 - val_acc: 0.5770\n","Epoch 34/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 0.9524 - acc: 0.6768 - val_loss: 1.4224 - val_acc: 0.4907\n","Epoch 35/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 0.9565 - acc: 0.6820 - val_loss: 0.9971 - val_acc: 0.6369\n","Epoch 36/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.9363 - acc: 0.6820 - val_loss: 0.9548 - val_acc: 0.6652\n","Epoch 37/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.9357 - acc: 0.6841 - val_loss: 1.4247 - val_acc: 0.4823\n","Epoch 38/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.9350 - acc: 0.6798 - val_loss: 1.0234 - val_acc: 0.6399\n","Epoch 39/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.9135 - acc: 0.6946 - val_loss: 0.9663 - val_acc: 0.6747\n","Epoch 40/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.9148 - acc: 0.6822 - val_loss: 0.9350 - val_acc: 0.6701\n","Epoch 41/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.9091 - acc: 0.6903 - val_loss: 0.9283 - val_acc: 0.6868\n","Epoch 42/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 0.9084 - acc: 0.6906 - val_loss: 1.1473 - val_acc: 0.5223\n","Epoch 43/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.9093 - acc: 0.6979 - val_loss: 0.9413 - val_acc: 0.6663\n","Epoch 44/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.8948 - acc: 0.7008 - val_loss: 1.1423 - val_acc: 0.5743\n","Epoch 45/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 0.8877 - acc: 0.7043 - val_loss: 1.0130 - val_acc: 0.6399\n","Epoch 46/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.8825 - acc: 0.7070 - val_loss: 1.0115 - val_acc: 0.6342\n","Epoch 47/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 0.8833 - acc: 0.7008 - val_loss: 0.9573 - val_acc: 0.6323\n","Epoch 48/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.8720 - acc: 0.7025 - val_loss: 1.1323 - val_acc: 0.5692\n","Epoch 49/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.8686 - acc: 0.7130 - val_loss: 1.0398 - val_acc: 0.6453\n","Epoch 50/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 0.8712 - acc: 0.7084 - val_loss: 1.1390 - val_acc: 0.5182\n","Epoch 51/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 0.8637 - acc: 0.7108 - val_loss: 1.1480 - val_acc: 0.5662\n","Epoch 52/60\n","3707/3707 [==============================] - 32s 9ms/step - loss: 0.8602 - acc: 0.7092 - val_loss: 0.9863 - val_acc: 0.6248\n","Epoch 53/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.8529 - acc: 0.7143 - val_loss: 0.9786 - val_acc: 0.6555\n","Epoch 54/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.8373 - acc: 0.7208 - val_loss: 0.8898 - val_acc: 0.6615\n","Epoch 55/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.8336 - acc: 0.7216 - val_loss: 0.9529 - val_acc: 0.6685\n","Epoch 56/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.8410 - acc: 0.7178 - val_loss: 0.9205 - val_acc: 0.6841\n","Epoch 57/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.8265 - acc: 0.7297 - val_loss: 1.0106 - val_acc: 0.6339\n","Epoch 58/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.8410 - acc: 0.7203 - val_loss: 0.8257 - val_acc: 0.7176\n","Epoch 59/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.8227 - acc: 0.7265 - val_loss: 1.1598 - val_acc: 0.6029\n","Epoch 60/60\n","3707/3707 [==============================] - 31s 8ms/step - loss: 0.8103 - acc: 0.7305 - val_loss: 0.8161 - val_acc: 0.7151\n","Accuracy[0.3415] Recall[0.2642] F1[0.1683] at fold[10]\n","______________________________________________________\n","Start Training\n","Train on 3714 samples, validate on 3714 samples\n","Epoch 1/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 2.9021 - acc: 0.1451 - val_loss: 2.4967 - val_acc: 0.1136\n","Epoch 2/60\n","3714/3714 [==============================] - 31s 8ms/step - loss: 2.3326 - acc: 0.1804 - val_loss: 2.3763 - val_acc: 0.1325\n","Epoch 3/60\n","3714/3714 [==============================] - 31s 8ms/step - loss: 2.1960 - acc: 0.2507 - val_loss: 2.2169 - val_acc: 0.2744\n","Epoch 4/60\n","3714/3714 [==============================] - 31s 8ms/step - loss: 2.0764 - acc: 0.3207 - val_loss: 2.0450 - val_acc: 0.3274\n","Epoch 5/60\n","3714/3714 [==============================] - 31s 8ms/step - loss: 1.8637 - acc: 0.3963 - val_loss: 1.7646 - val_acc: 0.3842\n","Epoch 6/60\n","3714/3714 [==============================] - 31s 8ms/step - loss: 1.6533 - acc: 0.4308 - val_loss: 1.8676 - val_acc: 0.3665\n","Epoch 7/60\n","3714/3714 [==============================] - 31s 8ms/step - loss: 1.5415 - acc: 0.4698 - val_loss: 1.5594 - val_acc: 0.4475\n","Epoch 8/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.4806 - acc: 0.4922 - val_loss: 1.5971 - val_acc: 0.4260\n","Epoch 9/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.4038 - acc: 0.5175 - val_loss: 1.7266 - val_acc: 0.4173\n","Epoch 10/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.3867 - acc: 0.5210 - val_loss: 1.6263 - val_acc: 0.4227\n","Epoch 11/60\n","3714/3714 [==============================] - 31s 8ms/step - loss: 1.3428 - acc: 0.5334 - val_loss: 1.4934 - val_acc: 0.4693\n","Epoch 12/60\n","3714/3714 [==============================] - 31s 8ms/step - loss: 1.3105 - acc: 0.5393 - val_loss: 1.5704 - val_acc: 0.4976\n","Epoch 13/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.2808 - acc: 0.5460 - val_loss: 1.2864 - val_acc: 0.5415\n","Epoch 14/60\n","3714/3714 [==============================] - 33s 9ms/step - loss: 1.2547 - acc: 0.5630 - val_loss: 1.3774 - val_acc: 0.4968\n","Epoch 15/60\n","3714/3714 [==============================] - 33s 9ms/step - loss: 1.2288 - acc: 0.5722 - val_loss: 1.3424 - val_acc: 0.5339\n","Epoch 16/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.1983 - acc: 0.5740 - val_loss: 1.4161 - val_acc: 0.4855\n","Epoch 17/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.1740 - acc: 0.5856 - val_loss: 1.3884 - val_acc: 0.5135\n","Epoch 18/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.1623 - acc: 0.5837 - val_loss: 1.2287 - val_acc: 0.5633\n","Epoch 19/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.1629 - acc: 0.5781 - val_loss: 1.2239 - val_acc: 0.5819\n","Epoch 20/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.1320 - acc: 0.5886 - val_loss: 1.3868 - val_acc: 0.4556\n","Epoch 21/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.1186 - acc: 0.5899 - val_loss: 1.3207 - val_acc: 0.5557\n","Epoch 22/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.0932 - acc: 0.6228 - val_loss: 1.1394 - val_acc: 0.6015\n","Epoch 23/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.0864 - acc: 0.6160 - val_loss: 1.3602 - val_acc: 0.5132\n","Epoch 24/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.0747 - acc: 0.6150 - val_loss: 1.2739 - val_acc: 0.5097\n","Epoch 25/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.0602 - acc: 0.6187 - val_loss: 1.1080 - val_acc: 0.5735\n","Epoch 26/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.0410 - acc: 0.6333 - val_loss: 1.2068 - val_acc: 0.5291\n","Epoch 27/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.0428 - acc: 0.6244 - val_loss: 1.1756 - val_acc: 0.5565\n","Epoch 28/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.0310 - acc: 0.6309 - val_loss: 1.1815 - val_acc: 0.5797\n","Epoch 29/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.0208 - acc: 0.6319 - val_loss: 1.2421 - val_acc: 0.5845\n","Epoch 30/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.0071 - acc: 0.6467 - val_loss: 1.1894 - val_acc: 0.5267\n","Epoch 31/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 1.0165 - acc: 0.6395 - val_loss: 1.0561 - val_acc: 0.6002\n","Epoch 32/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 0.9818 - acc: 0.6511 - val_loss: 1.0877 - val_acc: 0.6373\n","Epoch 33/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 0.9819 - acc: 0.6470 - val_loss: 1.2462 - val_acc: 0.5232\n","Epoch 34/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 0.9766 - acc: 0.6484 - val_loss: 1.1784 - val_acc: 0.5934\n","Epoch 35/60\n","3714/3714 [==============================] - 33s 9ms/step - loss: 0.9638 - acc: 0.6591 - val_loss: 1.0507 - val_acc: 0.6010\n","Epoch 36/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 0.9645 - acc: 0.6618 - val_loss: 0.9677 - val_acc: 0.6653\n","Epoch 37/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 0.9482 - acc: 0.6642 - val_loss: 0.9973 - val_acc: 0.6602\n","Epoch 38/60\n","3714/3714 [==============================] - 35s 9ms/step - loss: 0.9447 - acc: 0.6704 - val_loss: 1.0463 - val_acc: 0.6290\n","Epoch 39/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 0.9407 - acc: 0.6747 - val_loss: 0.9475 - val_acc: 0.6885\n","Epoch 40/60\n","3714/3714 [==============================] - 34s 9ms/step - loss: 0.9232 - acc: 0.6729 - val_loss: 1.0319 - val_acc: 0.6346\n","Epoch 41/60\n","3714/3714 [==============================] - 33s 9ms/step - loss: 0.9320 - acc: 0.6742 - val_loss: 1.0667 - val_acc: 0.6039\n","Epoch 42/60\n","3714/3714 [==============================] - 33s 9ms/step - loss: 0.9285 - acc: 0.6721 - val_loss: 1.2227 - val_acc: 0.5872\n","Epoch 43/60\n","3714/3714 [==============================] - 34s 9ms/step - loss: 0.9159 - acc: 0.6788 - val_loss: 1.0132 - val_acc: 0.6419\n","Epoch 44/60\n","3714/3714 [==============================] - 33s 9ms/step - loss: 0.8994 - acc: 0.6869 - val_loss: 1.1846 - val_acc: 0.6058\n","Epoch 45/60\n","3714/3714 [==============================] - 33s 9ms/step - loss: 0.9083 - acc: 0.6753 - val_loss: 0.9328 - val_acc: 0.6634\n","Epoch 46/60\n","3714/3714 [==============================] - 33s 9ms/step - loss: 0.9151 - acc: 0.6758 - val_loss: 1.0715 - val_acc: 0.5991\n","Epoch 47/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 0.9064 - acc: 0.6815 - val_loss: 0.9714 - val_acc: 0.6475\n","Epoch 48/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 0.8790 - acc: 0.6947 - val_loss: 0.8961 - val_acc: 0.6747\n","Epoch 49/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 0.8895 - acc: 0.6815 - val_loss: 1.0305 - val_acc: 0.6034\n","Epoch 50/60\n","3714/3714 [==============================] - 35s 9ms/step - loss: 0.8816 - acc: 0.6947 - val_loss: 1.0128 - val_acc: 0.6179\n","Epoch 51/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 0.8568 - acc: 0.6998 - val_loss: 1.0890 - val_acc: 0.5924\n","Epoch 52/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 0.8699 - acc: 0.6904 - val_loss: 0.9237 - val_acc: 0.6311\n","Epoch 53/60\n","3714/3714 [==============================] - 32s 8ms/step - loss: 0.8595 - acc: 0.6976 - val_loss: 0.9638 - val_acc: 0.6309\n","Epoch 54/60\n","3714/3714 [==============================] - 34s 9ms/step - loss: 0.8581 - acc: 0.7036 - val_loss: 0.9972 - val_acc: 0.6287\n","Epoch 55/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 0.8484 - acc: 0.7022 - val_loss: 1.2141 - val_acc: 0.5347\n","Epoch 56/60\n","3714/3714 [==============================] - 31s 8ms/step - loss: 0.8497 - acc: 0.6987 - val_loss: 0.9083 - val_acc: 0.6769\n","Epoch 57/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 0.8444 - acc: 0.7001 - val_loss: 0.9844 - val_acc: 0.6279\n","Epoch 58/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 0.8479 - acc: 0.7003 - val_loss: 0.9825 - val_acc: 0.6271\n","Epoch 59/60\n","3714/3714 [==============================] - 32s 9ms/step - loss: 0.8370 - acc: 0.7046 - val_loss: 0.8162 - val_acc: 0.7149\n","Epoch 60/60\n","3714/3714 [==============================] - 33s 9ms/step - loss: 0.8260 - acc: 0.7143 - val_loss: 0.8715 - val_acc: 0.7001\n","Accuracy[0.7707] Recall[0.3722] F1[0.3621] at fold[11]\n","______________________________________________________\n","Start Training\n","Train on 3725 samples, validate on 3725 samples\n","Epoch 1/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 2.2816 - acc: 0.2011 - val_loss: 2.1377 - val_acc: 0.3248\n","Epoch 2/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 1.9436 - acc: 0.4059 - val_loss: 1.7501 - val_acc: 0.4505\n","Epoch 3/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 1.6207 - acc: 0.4612 - val_loss: 1.5157 - val_acc: 0.5055\n","Epoch 4/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 1.4178 - acc: 0.5085 - val_loss: 1.4544 - val_acc: 0.5323\n","Epoch 5/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 1.3124 - acc: 0.5281 - val_loss: 1.3032 - val_acc: 0.5173\n","Epoch 6/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 1.2563 - acc: 0.5495 - val_loss: 1.3126 - val_acc: 0.5192\n","Epoch 7/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 1.1899 - acc: 0.5681 - val_loss: 1.4640 - val_acc: 0.4642\n","Epoch 8/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 1.1390 - acc: 0.5909 - val_loss: 1.1867 - val_acc: 0.5750\n","Epoch 9/60\n","3725/3725 [==============================] - 32s 8ms/step - loss: 1.1340 - acc: 0.5868 - val_loss: 1.2179 - val_acc: 0.5356\n","Epoch 10/60\n","3725/3725 [==============================] - 32s 8ms/step - loss: 1.1007 - acc: 0.6005 - val_loss: 1.0886 - val_acc: 0.6118\n","Epoch 11/60\n","3725/3725 [==============================] - 31s 8ms/step - loss: 1.0716 - acc: 0.6156 - val_loss: 1.0507 - val_acc: 0.6311\n","Epoch 12/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 1.0519 - acc: 0.6282 - val_loss: 1.0397 - val_acc: 0.6244\n","Epoch 13/60\n","3725/3725 [==============================] - 32s 8ms/step - loss: 1.0264 - acc: 0.6430 - val_loss: 1.1645 - val_acc: 0.5758\n","Epoch 14/60\n","3725/3725 [==============================] - 31s 8ms/step - loss: 1.0155 - acc: 0.6438 - val_loss: 1.0880 - val_acc: 0.6086\n","Epoch 15/60\n","3725/3725 [==============================] - 32s 8ms/step - loss: 1.0007 - acc: 0.6454 - val_loss: 1.0413 - val_acc: 0.6338\n","Epoch 16/60\n","3725/3725 [==============================] - 31s 8ms/step - loss: 0.9726 - acc: 0.6644 - val_loss: 0.9889 - val_acc: 0.6301\n","Epoch 17/60\n","3725/3725 [==============================] - 32s 8ms/step - loss: 0.9613 - acc: 0.6609 - val_loss: 0.9488 - val_acc: 0.6738\n","Epoch 18/60\n","3725/3725 [==============================] - 31s 8ms/step - loss: 0.9581 - acc: 0.6668 - val_loss: 1.0844 - val_acc: 0.6118\n","Epoch 19/60\n","3725/3725 [==============================] - 31s 8ms/step - loss: 0.9472 - acc: 0.6663 - val_loss: 1.0123 - val_acc: 0.6217\n","Epoch 20/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.9337 - acc: 0.6830 - val_loss: 0.9366 - val_acc: 0.6636\n","Epoch 21/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.9202 - acc: 0.6744 - val_loss: 0.9718 - val_acc: 0.6451\n","Epoch 22/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.9150 - acc: 0.6881 - val_loss: 0.8856 - val_acc: 0.7052\n","Epoch 23/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.9032 - acc: 0.6902 - val_loss: 0.9212 - val_acc: 0.6749\n","Epoch 24/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.8949 - acc: 0.6854 - val_loss: 0.9763 - val_acc: 0.6470\n","Epoch 25/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.8959 - acc: 0.6940 - val_loss: 0.9060 - val_acc: 0.7001\n","Epoch 26/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.8727 - acc: 0.7095 - val_loss: 0.9078 - val_acc: 0.6915\n","Epoch 27/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.8746 - acc: 0.6988 - val_loss: 0.9528 - val_acc: 0.6583\n","Epoch 28/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.8690 - acc: 0.6977 - val_loss: 0.8752 - val_acc: 0.6921\n","Epoch 29/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.8618 - acc: 0.7042 - val_loss: 0.9028 - val_acc: 0.6685\n","Epoch 30/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.8542 - acc: 0.7007 - val_loss: 0.9007 - val_acc: 0.6709\n","Epoch 31/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.8383 - acc: 0.7103 - val_loss: 0.9710 - val_acc: 0.6521\n","Epoch 32/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.8367 - acc: 0.7251 - val_loss: 1.0119 - val_acc: 0.6231\n","Epoch 33/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.8316 - acc: 0.7114 - val_loss: 0.8229 - val_acc: 0.7138\n","Epoch 34/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.8284 - acc: 0.7211 - val_loss: 0.9013 - val_acc: 0.6797\n","Epoch 35/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.8195 - acc: 0.7195 - val_loss: 1.1817 - val_acc: 0.5877\n","Epoch 36/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.8155 - acc: 0.7286 - val_loss: 0.7901 - val_acc: 0.7315\n","Epoch 37/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.8014 - acc: 0.7318 - val_loss: 0.8424 - val_acc: 0.7039\n","Epoch 38/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.7980 - acc: 0.7262 - val_loss: 0.8202 - val_acc: 0.7004\n","Epoch 39/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.7902 - acc: 0.7283 - val_loss: 0.7860 - val_acc: 0.7358\n","Epoch 40/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.7855 - acc: 0.7289 - val_loss: 0.8327 - val_acc: 0.6932\n","Epoch 41/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.7843 - acc: 0.7348 - val_loss: 0.8284 - val_acc: 0.7103\n","Epoch 42/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.7767 - acc: 0.7321 - val_loss: 0.8121 - val_acc: 0.7026\n","Epoch 43/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.7706 - acc: 0.7323 - val_loss: 0.7449 - val_acc: 0.7434\n","Epoch 44/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.7749 - acc: 0.7326 - val_loss: 0.8939 - val_acc: 0.6666\n","Epoch 45/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.7613 - acc: 0.7364 - val_loss: 0.8365 - val_acc: 0.7052\n","Epoch 46/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.7559 - acc: 0.7377 - val_loss: 0.8008 - val_acc: 0.7197\n","Epoch 47/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.7595 - acc: 0.7369 - val_loss: 0.8741 - val_acc: 0.6779\n","Epoch 48/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.7564 - acc: 0.7393 - val_loss: 0.8702 - val_acc: 0.7012\n","Epoch 49/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.7421 - acc: 0.7447 - val_loss: 0.8143 - val_acc: 0.7165\n","Epoch 50/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.7326 - acc: 0.7546 - val_loss: 0.7687 - val_acc: 0.7254\n","Epoch 51/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.7270 - acc: 0.7501 - val_loss: 0.7917 - val_acc: 0.7423\n","Epoch 52/60\n","3725/3725 [==============================] - 33s 9ms/step - loss: 0.7311 - acc: 0.7511 - val_loss: 0.7246 - val_acc: 0.7423\n","Epoch 53/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.7200 - acc: 0.7579 - val_loss: 0.7263 - val_acc: 0.7495\n","Epoch 54/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.7214 - acc: 0.7458 - val_loss: 0.7862 - val_acc: 0.7200\n","Epoch 55/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.7137 - acc: 0.7549 - val_loss: 0.8396 - val_acc: 0.7162\n","Epoch 56/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.7161 - acc: 0.7536 - val_loss: 0.7352 - val_acc: 0.7514\n","Epoch 57/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.7082 - acc: 0.7560 - val_loss: 0.7383 - val_acc: 0.7460\n","Epoch 58/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.7088 - acc: 0.7554 - val_loss: 0.7821 - val_acc: 0.7256\n","Epoch 59/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.6967 - acc: 0.7581 - val_loss: 0.7271 - val_acc: 0.7560\n","Epoch 60/60\n","3725/3725 [==============================] - 32s 9ms/step - loss: 0.7000 - acc: 0.7557 - val_loss: 0.7516 - val_acc: 0.7396\n","Accuracy[0.9110] Recall[0.5799] F1[0.5796] at fold[12]\n","______________________________________________________\n","Start Training\n","Train on 3842 samples, validate on 3842 samples\n","Epoch 1/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 2.2608 - acc: 0.2736 - val_loss: 1.9683 - val_acc: 0.3738\n","Epoch 2/60\n","3842/3842 [==============================] - 33s 8ms/step - loss: 1.8272 - acc: 0.4055 - val_loss: 1.6963 - val_acc: 0.4591\n","Epoch 3/60\n","3842/3842 [==============================] - 33s 8ms/step - loss: 1.5297 - acc: 0.4883 - val_loss: 1.4463 - val_acc: 0.4896\n","Epoch 4/60\n","3842/3842 [==============================] - 32s 8ms/step - loss: 1.3793 - acc: 0.5213 - val_loss: 1.3347 - val_acc: 0.5073\n","Epoch 5/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 1.2697 - acc: 0.5591 - val_loss: 1.3162 - val_acc: 0.5195\n","Epoch 6/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 1.2359 - acc: 0.5526 - val_loss: 1.2069 - val_acc: 0.5903\n","Epoch 7/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 1.1557 - acc: 0.5924 - val_loss: 1.1266 - val_acc: 0.5789\n","Epoch 8/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 1.1195 - acc: 0.6041 - val_loss: 1.1404 - val_acc: 0.5755\n","Epoch 9/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 1.1002 - acc: 0.6130 - val_loss: 1.1105 - val_acc: 0.6244\n","Epoch 10/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 1.0553 - acc: 0.6359 - val_loss: 1.0521 - val_acc: 0.6364\n","Epoch 11/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 1.0208 - acc: 0.6528 - val_loss: 1.0581 - val_acc: 0.6088\n","Epoch 12/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 1.0213 - acc: 0.6502 - val_loss: 1.0274 - val_acc: 0.6338\n","Epoch 13/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.9679 - acc: 0.6731 - val_loss: 1.0246 - val_acc: 0.6437\n","Epoch 14/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.9595 - acc: 0.6715 - val_loss: 0.9358 - val_acc: 0.6871\n","Epoch 15/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.9368 - acc: 0.6827 - val_loss: 1.0314 - val_acc: 0.6309\n","Epoch 16/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.9194 - acc: 0.6897 - val_loss: 0.9426 - val_acc: 0.6754\n","Epoch 17/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.9038 - acc: 0.6921 - val_loss: 0.9539 - val_acc: 0.6619\n","Epoch 18/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.8921 - acc: 0.6989 - val_loss: 0.8749 - val_acc: 0.6882\n","Epoch 19/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.8823 - acc: 0.6957 - val_loss: 0.9379 - val_acc: 0.6627\n","Epoch 20/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.8775 - acc: 0.7043 - val_loss: 0.8295 - val_acc: 0.7332\n","Epoch 21/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.8424 - acc: 0.7249 - val_loss: 0.9558 - val_acc: 0.6421\n","Epoch 22/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.8498 - acc: 0.7090 - val_loss: 0.8251 - val_acc: 0.7184\n","Epoch 23/60\n","3842/3842 [==============================] - 33s 8ms/step - loss: 0.8281 - acc: 0.7205 - val_loss: 0.8342 - val_acc: 0.7160\n","Epoch 24/60\n","3842/3842 [==============================] - 32s 8ms/step - loss: 0.8305 - acc: 0.7231 - val_loss: 0.8148 - val_acc: 0.7290\n","Epoch 25/60\n","3842/3842 [==============================] - 32s 8ms/step - loss: 0.8178 - acc: 0.7317 - val_loss: 0.8893 - val_acc: 0.6921\n","Epoch 26/60\n","3842/3842 [==============================] - 32s 8ms/step - loss: 0.8048 - acc: 0.7330 - val_loss: 0.8052 - val_acc: 0.7290\n","Epoch 27/60\n","3842/3842 [==============================] - 33s 8ms/step - loss: 0.8002 - acc: 0.7314 - val_loss: 0.8119 - val_acc: 0.7106\n","Epoch 28/60\n","3842/3842 [==============================] - 33s 8ms/step - loss: 0.8007 - acc: 0.7335 - val_loss: 0.8225 - val_acc: 0.7106\n","Epoch 29/60\n","3842/3842 [==============================] - 32s 8ms/step - loss: 0.7828 - acc: 0.7426 - val_loss: 0.7859 - val_acc: 0.7311\n","Epoch 30/60\n","3842/3842 [==============================] - 32s 8ms/step - loss: 0.7896 - acc: 0.7335 - val_loss: 0.7654 - val_acc: 0.7457\n","Epoch 31/60\n","3842/3842 [==============================] - 32s 8ms/step - loss: 0.7750 - acc: 0.7397 - val_loss: 0.7883 - val_acc: 0.7288\n","Epoch 32/60\n","3842/3842 [==============================] - 32s 8ms/step - loss: 0.7669 - acc: 0.7413 - val_loss: 0.7867 - val_acc: 0.7309\n","Epoch 33/60\n","3842/3842 [==============================] - 32s 8ms/step - loss: 0.7611 - acc: 0.7421 - val_loss: 0.9297 - val_acc: 0.6424\n","Epoch 34/60\n","3842/3842 [==============================] - 32s 8ms/step - loss: 0.7535 - acc: 0.7512 - val_loss: 0.7627 - val_acc: 0.7527\n","Epoch 35/60\n","3842/3842 [==============================] - 32s 8ms/step - loss: 0.7524 - acc: 0.7499 - val_loss: 0.7893 - val_acc: 0.7228\n","Epoch 36/60\n","3842/3842 [==============================] - 32s 8ms/step - loss: 0.7433 - acc: 0.7522 - val_loss: 0.7223 - val_acc: 0.7663\n","Epoch 37/60\n","3842/3842 [==============================] - 33s 8ms/step - loss: 0.7369 - acc: 0.7572 - val_loss: 0.7182 - val_acc: 0.7644\n","Epoch 38/60\n","3842/3842 [==============================] - 33s 8ms/step - loss: 0.7330 - acc: 0.7595 - val_loss: 0.7498 - val_acc: 0.7512\n","Epoch 39/60\n","3842/3842 [==============================] - 32s 8ms/step - loss: 0.7221 - acc: 0.7616 - val_loss: 0.7658 - val_acc: 0.7452\n","Epoch 40/60\n","3842/3842 [==============================] - 33s 8ms/step - loss: 0.7283 - acc: 0.7579 - val_loss: 0.7803 - val_acc: 0.7298\n","Epoch 41/60\n","3842/3842 [==============================] - 33s 8ms/step - loss: 0.7163 - acc: 0.7611 - val_loss: 0.7694 - val_acc: 0.7395\n","Epoch 42/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.7174 - acc: 0.7621 - val_loss: 0.7210 - val_acc: 0.7556\n","Epoch 43/60\n","3842/3842 [==============================] - 33s 8ms/step - loss: 0.7094 - acc: 0.7650 - val_loss: 0.7310 - val_acc: 0.7496\n","Epoch 44/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.6992 - acc: 0.7678 - val_loss: 0.7519 - val_acc: 0.7418\n","Epoch 45/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.7088 - acc: 0.7590 - val_loss: 0.7147 - val_acc: 0.7595\n","Epoch 46/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.6984 - acc: 0.7637 - val_loss: 0.7400 - val_acc: 0.7350\n","Epoch 47/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.6894 - acc: 0.7811 - val_loss: 0.6864 - val_acc: 0.7712\n","Epoch 48/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.6967 - acc: 0.7634 - val_loss: 0.7284 - val_acc: 0.7496\n","Epoch 49/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.6889 - acc: 0.7699 - val_loss: 0.6878 - val_acc: 0.7670\n","Epoch 50/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.6821 - acc: 0.7694 - val_loss: 0.6571 - val_acc: 0.7821\n","Epoch 51/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.6790 - acc: 0.7754 - val_loss: 0.6575 - val_acc: 0.7876\n","Epoch 52/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.6713 - acc: 0.7762 - val_loss: 0.6670 - val_acc: 0.7811\n","Epoch 53/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.6637 - acc: 0.7795 - val_loss: 0.7151 - val_acc: 0.7626\n","Epoch 54/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.6748 - acc: 0.7699 - val_loss: 0.6442 - val_acc: 0.7855\n","Epoch 55/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.6554 - acc: 0.7821 - val_loss: 0.6817 - val_acc: 0.7538\n","Epoch 56/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.6541 - acc: 0.7775 - val_loss: 0.6745 - val_acc: 0.7743\n","Epoch 57/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.6617 - acc: 0.7769 - val_loss: 0.6373 - val_acc: 0.7832\n","Epoch 58/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.6494 - acc: 0.7824 - val_loss: 0.6507 - val_acc: 0.7782\n","Epoch 59/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.6427 - acc: 0.7884 - val_loss: 0.6543 - val_acc: 0.7832\n","Epoch 60/60\n","3842/3842 [==============================] - 33s 9ms/step - loss: 0.6431 - acc: 0.7881 - val_loss: 0.6250 - val_acc: 0.7928\n","Accuracy[0.2069] Recall[0.1034] F1[0.1714] at fold[13]\n","______________________________________________________\n","Start Training\n","Train on 3833 samples, validate on 3833 samples\n","Epoch 1/60\n","3833/3833 [==============================] - 34s 9ms/step - loss: 2.5445 - acc: 0.1826 - val_loss: 2.3450 - val_acc: 0.1281\n","Epoch 2/60\n","3833/3833 [==============================] - 33s 9ms/step - loss: 2.2400 - acc: 0.2810 - val_loss: 2.1514 - val_acc: 0.3707\n","Epoch 3/60\n","3833/3833 [==============================] - 33s 9ms/step - loss: 1.9124 - acc: 0.3879 - val_loss: 1.9138 - val_acc: 0.3603\n","Epoch 4/60\n","3833/3833 [==============================] - 33s 9ms/step - loss: 1.5668 - acc: 0.4673 - val_loss: 1.6699 - val_acc: 0.3681\n","Epoch 5/60\n","3833/3833 [==============================] - 33s 8ms/step - loss: 1.4141 - acc: 0.4965 - val_loss: 1.4534 - val_acc: 0.5301\n","Epoch 6/60\n","3833/3833 [==============================] - 33s 9ms/step - loss: 1.2942 - acc: 0.5445 - val_loss: 1.2786 - val_acc: 0.5432\n","Epoch 7/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 1.2289 - acc: 0.5643 - val_loss: 1.2863 - val_acc: 0.5173\n","Epoch 8/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 1.2185 - acc: 0.5591 - val_loss: 1.1499 - val_acc: 0.6160\n","Epoch 9/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 1.1643 - acc: 0.5823 - val_loss: 1.1428 - val_acc: 0.5766\n","Epoch 10/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 1.1332 - acc: 0.5826 - val_loss: 1.2074 - val_acc: 0.5398\n","Epoch 11/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 1.1173 - acc: 0.6066 - val_loss: 1.1487 - val_acc: 0.5792\n","Epoch 12/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 1.0814 - acc: 0.6165 - val_loss: 1.1356 - val_acc: 0.6147\n","Epoch 13/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 1.0492 - acc: 0.6334 - val_loss: 1.0987 - val_acc: 0.6238\n","Epoch 14/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 1.0455 - acc: 0.6332 - val_loss: 1.3453 - val_acc: 0.5244\n","Epoch 15/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 1.0444 - acc: 0.6241 - val_loss: 1.0380 - val_acc: 0.6355\n","Epoch 16/60\n","3833/3833 [==============================] - 33s 9ms/step - loss: 1.0137 - acc: 0.6507 - val_loss: 1.1575 - val_acc: 0.5523\n","Epoch 17/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.9977 - acc: 0.6486 - val_loss: 1.0927 - val_acc: 0.5534\n","Epoch 18/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.9888 - acc: 0.6444 - val_loss: 1.0937 - val_acc: 0.5580\n","Epoch 19/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.9827 - acc: 0.6577 - val_loss: 1.0694 - val_acc: 0.6063\n","Epoch 20/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.9694 - acc: 0.6569 - val_loss: 1.0448 - val_acc: 0.6217\n","Epoch 21/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.9497 - acc: 0.6668 - val_loss: 1.0150 - val_acc: 0.6327\n","Epoch 22/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.9477 - acc: 0.6694 - val_loss: 1.0490 - val_acc: 0.5948\n","Epoch 23/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.9265 - acc: 0.6796 - val_loss: 0.9758 - val_acc: 0.6541\n","Epoch 24/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.9332 - acc: 0.6770 - val_loss: 0.8931 - val_acc: 0.7010\n","Epoch 25/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.9065 - acc: 0.6841 - val_loss: 0.9100 - val_acc: 0.6937\n","Epoch 26/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.9137 - acc: 0.6723 - val_loss: 0.9163 - val_acc: 0.6624\n","Epoch 27/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.8984 - acc: 0.6880 - val_loss: 0.9600 - val_acc: 0.6499\n","Epoch 28/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.8885 - acc: 0.6828 - val_loss: 0.9476 - val_acc: 0.6567\n","Epoch 29/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.8757 - acc: 0.6979 - val_loss: 0.9195 - val_acc: 0.6882\n","Epoch 30/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.8662 - acc: 0.6948 - val_loss: 0.9469 - val_acc: 0.6361\n","Epoch 31/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.8666 - acc: 0.6911 - val_loss: 0.9511 - val_acc: 0.6491\n","Epoch 32/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.8616 - acc: 0.6961 - val_loss: 0.9029 - val_acc: 0.6770\n","Epoch 33/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.8597 - acc: 0.6971 - val_loss: 0.8789 - val_acc: 0.6809\n","Epoch 34/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.8513 - acc: 0.6950 - val_loss: 0.8791 - val_acc: 0.6851\n","Epoch 35/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.8333 - acc: 0.6995 - val_loss: 0.9370 - val_acc: 0.6368\n","Epoch 36/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.8317 - acc: 0.7138 - val_loss: 0.8163 - val_acc: 0.7219\n","Epoch 37/60\n","3833/3833 [==============================] - 33s 9ms/step - loss: 0.8257 - acc: 0.7068 - val_loss: 0.8433 - val_acc: 0.6872\n","Epoch 38/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.8151 - acc: 0.7167 - val_loss: 0.8598 - val_acc: 0.6807\n","Epoch 39/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.8124 - acc: 0.7154 - val_loss: 0.9317 - val_acc: 0.6825\n","Epoch 40/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.8157 - acc: 0.7109 - val_loss: 0.8367 - val_acc: 0.7073\n","Epoch 41/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.8021 - acc: 0.7133 - val_loss: 0.7964 - val_acc: 0.7154\n","Epoch 42/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.8091 - acc: 0.7167 - val_loss: 0.8093 - val_acc: 0.7104\n","Epoch 43/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.7942 - acc: 0.7203 - val_loss: 0.8341 - val_acc: 0.6976\n","Epoch 44/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.7886 - acc: 0.7250 - val_loss: 0.7987 - val_acc: 0.7253\n","Epoch 45/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.7734 - acc: 0.7378 - val_loss: 0.7795 - val_acc: 0.7146\n","Epoch 46/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.7763 - acc: 0.7331 - val_loss: 0.8013 - val_acc: 0.7159\n","Epoch 47/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.7669 - acc: 0.7342 - val_loss: 0.8636 - val_acc: 0.6916\n","Epoch 48/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.7747 - acc: 0.7250 - val_loss: 0.8950 - val_acc: 0.6585\n","Epoch 49/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.7626 - acc: 0.7352 - val_loss: 0.7845 - val_acc: 0.7248\n","Epoch 50/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.7619 - acc: 0.7326 - val_loss: 0.7818 - val_acc: 0.7143\n","Epoch 51/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.7492 - acc: 0.7386 - val_loss: 0.7838 - val_acc: 0.7195\n","Epoch 52/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.7465 - acc: 0.7373 - val_loss: 0.7261 - val_acc: 0.7446\n","Epoch 53/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.7361 - acc: 0.7404 - val_loss: 0.7471 - val_acc: 0.7185\n","Epoch 54/60\n","3833/3833 [==============================] - 33s 8ms/step - loss: 0.7384 - acc: 0.7430 - val_loss: 0.7872 - val_acc: 0.7276\n","Epoch 55/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.7282 - acc: 0.7495 - val_loss: 0.7425 - val_acc: 0.7420\n","Epoch 56/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.7312 - acc: 0.7451 - val_loss: 0.8664 - val_acc: 0.6971\n","Epoch 57/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.7246 - acc: 0.7391 - val_loss: 0.7720 - val_acc: 0.7057\n","Epoch 58/60\n","3833/3833 [==============================] - 32s 8ms/step - loss: 0.7174 - acc: 0.7498 - val_loss: 0.7314 - val_acc: 0.7495\n","Epoch 59/60\n","3833/3833 [==============================] - 33s 8ms/step - loss: 0.7068 - acc: 0.7535 - val_loss: 0.7549 - val_acc: 0.7308\n","Epoch 60/60\n","3833/3833 [==============================] - 33s 8ms/step - loss: 0.7191 - acc: 0.7605 - val_loss: 0.7889 - val_acc: 0.7198\n","Accuracy[0.5000] Recall[0.0714] F1[0.0952] at fold[14]\n","______________________________________________________\n","Start Training\n","Train on 3837 samples, validate on 3837 samples\n","Epoch 1/60\n","3837/3837 [==============================] - 38s 10ms/step - loss: 2.2790 - acc: 0.2520 - val_loss: 1.9902 - val_acc: 0.3693\n","Epoch 2/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 1.7738 - acc: 0.4058 - val_loss: 1.6317 - val_acc: 0.3896\n","Epoch 3/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 1.5151 - acc: 0.4741 - val_loss: 1.4022 - val_acc: 0.5165\n","Epoch 4/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 1.3899 - acc: 0.5030 - val_loss: 1.3468 - val_acc: 0.5124\n","Epoch 5/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 1.2815 - acc: 0.5382 - val_loss: 1.3243 - val_acc: 0.5202\n","Epoch 6/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 1.2233 - acc: 0.5541 - val_loss: 1.2363 - val_acc: 0.5437\n","Epoch 7/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 1.1928 - acc: 0.5658 - val_loss: 1.4311 - val_acc: 0.4975\n","Epoch 8/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 1.1330 - acc: 0.6065 - val_loss: 1.1325 - val_acc: 0.5966\n","Epoch 9/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 1.1100 - acc: 0.6065 - val_loss: 1.0789 - val_acc: 0.6450\n","Epoch 10/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 1.0658 - acc: 0.6320 - val_loss: 1.0740 - val_acc: 0.5973\n","Epoch 11/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 1.0560 - acc: 0.6244 - val_loss: 1.1039 - val_acc: 0.5971\n","Epoch 12/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 1.0208 - acc: 0.6432 - val_loss: 1.0465 - val_acc: 0.6213\n","Epoch 13/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 1.0121 - acc: 0.6482 - val_loss: 0.9690 - val_acc: 0.6513\n","Epoch 14/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 0.9829 - acc: 0.6588 - val_loss: 1.1118 - val_acc: 0.5804\n","Epoch 15/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 0.9758 - acc: 0.6607 - val_loss: 1.0095 - val_acc: 0.6260\n","Epoch 16/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 0.9546 - acc: 0.6706 - val_loss: 0.9728 - val_acc: 0.6573\n","Epoch 17/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 0.9412 - acc: 0.6667 - val_loss: 0.9565 - val_acc: 0.6633\n","Epoch 18/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 0.9337 - acc: 0.6742 - val_loss: 0.9290 - val_acc: 0.6615\n","Epoch 19/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 0.9169 - acc: 0.6873 - val_loss: 0.9671 - val_acc: 0.6729\n","Epoch 20/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.8935 - acc: 0.6935 - val_loss: 0.8902 - val_acc: 0.7068\n","Epoch 21/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.8917 - acc: 0.6951 - val_loss: 0.9327 - val_acc: 0.6763\n","Epoch 22/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.8818 - acc: 0.6906 - val_loss: 1.1609 - val_acc: 0.5489\n","Epoch 23/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.8712 - acc: 0.7102 - val_loss: 0.8842 - val_acc: 0.6909\n","Epoch 24/60\n","3837/3837 [==============================] - 36s 9ms/step - loss: 0.8587 - acc: 0.7063 - val_loss: 0.9037 - val_acc: 0.6698\n","Epoch 25/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.8593 - acc: 0.7024 - val_loss: 0.8654 - val_acc: 0.6935\n","Epoch 26/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.8334 - acc: 0.7120 - val_loss: 0.8782 - val_acc: 0.6925\n","Epoch 27/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.8404 - acc: 0.7084 - val_loss: 0.8076 - val_acc: 0.7352\n","Epoch 28/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.8339 - acc: 0.7154 - val_loss: 0.8353 - val_acc: 0.6930\n","Epoch 29/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.8110 - acc: 0.7180 - val_loss: 0.8573 - val_acc: 0.7021\n","Epoch 30/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.8008 - acc: 0.7331 - val_loss: 0.8092 - val_acc: 0.7224\n","Epoch 31/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.8030 - acc: 0.7321 - val_loss: 0.8020 - val_acc: 0.7206\n","Epoch 32/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.7917 - acc: 0.7284 - val_loss: 0.8253 - val_acc: 0.7060\n","Epoch 33/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.7907 - acc: 0.7297 - val_loss: 0.7788 - val_acc: 0.7284\n","Epoch 34/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.7803 - acc: 0.7394 - val_loss: 0.8528 - val_acc: 0.6755\n","Epoch 35/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.7809 - acc: 0.7277 - val_loss: 0.7681 - val_acc: 0.7482\n","Epoch 36/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.7670 - acc: 0.7360 - val_loss: 0.8012 - val_acc: 0.7204\n","Epoch 37/60\n","3837/3837 [==============================] - 36s 9ms/step - loss: 0.7608 - acc: 0.7456 - val_loss: 0.7984 - val_acc: 0.7063\n","Epoch 38/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.7538 - acc: 0.7443 - val_loss: 0.8487 - val_acc: 0.6977\n","Epoch 39/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.7525 - acc: 0.7459 - val_loss: 0.7722 - val_acc: 0.7253\n","Epoch 40/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.7437 - acc: 0.7451 - val_loss: 0.8910 - val_acc: 0.6701\n","Epoch 41/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.7412 - acc: 0.7490 - val_loss: 0.8117 - val_acc: 0.7290\n","Epoch 42/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.7305 - acc: 0.7542 - val_loss: 0.8435 - val_acc: 0.6904\n","Epoch 43/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.7256 - acc: 0.7535 - val_loss: 0.7065 - val_acc: 0.7579\n","Epoch 44/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.7198 - acc: 0.7568 - val_loss: 0.7987 - val_acc: 0.7076\n","Epoch 45/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.7279 - acc: 0.7506 - val_loss: 0.7201 - val_acc: 0.7535\n","Epoch 46/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.7089 - acc: 0.7579 - val_loss: 0.7572 - val_acc: 0.7318\n","Epoch 47/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 0.7131 - acc: 0.7618 - val_loss: 0.7131 - val_acc: 0.7602\n","Epoch 48/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 0.6988 - acc: 0.7634 - val_loss: 0.7949 - val_acc: 0.7128\n","Epoch 49/60\n","3837/3837 [==============================] - 33s 8ms/step - loss: 0.6997 - acc: 0.7553 - val_loss: 0.7237 - val_acc: 0.7396\n","Epoch 50/60\n","3837/3837 [==============================] - 33s 8ms/step - loss: 0.6893 - acc: 0.7636 - val_loss: 0.7007 - val_acc: 0.7621\n","Epoch 51/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 0.6873 - acc: 0.7675 - val_loss: 0.6582 - val_acc: 0.7834\n","Epoch 52/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.6834 - acc: 0.7675 - val_loss: 0.7134 - val_acc: 0.7490\n","Epoch 53/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.6752 - acc: 0.7714 - val_loss: 0.7195 - val_acc: 0.7456\n","Epoch 54/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.6823 - acc: 0.7683 - val_loss: 0.6721 - val_acc: 0.7639\n","Epoch 55/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.6777 - acc: 0.7688 - val_loss: 0.6835 - val_acc: 0.7644\n","Epoch 56/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.6674 - acc: 0.7803 - val_loss: 0.7233 - val_acc: 0.7305\n","Epoch 57/60\n","3837/3837 [==============================] - 33s 8ms/step - loss: 0.6705 - acc: 0.7772 - val_loss: 0.6570 - val_acc: 0.7746\n","Epoch 58/60\n","3837/3837 [==============================] - 33s 8ms/step - loss: 0.6544 - acc: 0.7785 - val_loss: 0.6787 - val_acc: 0.7712\n","Epoch 59/60\n","3837/3837 [==============================] - 32s 8ms/step - loss: 0.6534 - acc: 0.7787 - val_loss: 0.6497 - val_acc: 0.7816\n","Epoch 60/60\n","3837/3837 [==============================] - 33s 9ms/step - loss: 0.6474 - acc: 0.7787 - val_loss: 0.6651 - val_acc: 0.7696\n","Accuracy[0.7647] Recall[0.1912] F1[0.2167] at fold[15]\n","______________________________________________________\n","Mean Accuracy[0.5913] IC [0.5089, 0.6738]\n","Mean Recall[0.3811] IC [0.3073, 0.4550]\n","Mean F1[0.3706] IC [0.3024, 0.4387]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"du_uR3jI7pcP","colab_type":"code","outputId":"24da7ab0-61db-4f24-d973-70b91deaa1a1","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1586113145604,"user_tz":-120,"elapsed":4795120,"user":{"displayName":"Rana mostafa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpLWLhJYcXKOOp7sprSKwnxN-x9hYM61yh__9kww=s64","userId":"07598775866819373078"}}},"source":["RunWHARF('data/LOTO/WHARF.npz')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["12\n","(3871, 1, 250, 29)\n","(3871, 12)\n","(3472, 1, 250, 29)\n","(399, 1, 250, 29)\n","[11, 19, 27]\n","Start Training\n","Train on 3472 samples, validate on 3472 samples\n","Epoch 1/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 2.2045 - acc: 0.2952 - val_loss: 1.9852 - val_acc: 0.3978\n","Epoch 2/60\n","3472/3472 [==============================] - 37s 11ms/step - loss: 1.8985 - acc: 0.4035 - val_loss: 1.7021 - val_acc: 0.4490\n","Epoch 3/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 1.6498 - acc: 0.4519 - val_loss: 1.9356 - val_acc: 0.3534\n","Epoch 4/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 1.5155 - acc: 0.4821 - val_loss: 1.4276 - val_acc: 0.5009\n","Epoch 5/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 1.3928 - acc: 0.5072 - val_loss: 1.3415 - val_acc: 0.5058\n","Epoch 6/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 1.3012 - acc: 0.5432 - val_loss: 1.2932 - val_acc: 0.5225\n","Epoch 7/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 1.2671 - acc: 0.5504 - val_loss: 1.2912 - val_acc: 0.5490\n","Epoch 8/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 1.2179 - acc: 0.5657 - val_loss: 1.1970 - val_acc: 0.5783\n","Epoch 9/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 1.1846 - acc: 0.5844 - val_loss: 1.1631 - val_acc: 0.5994\n","Epoch 10/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 1.1524 - acc: 0.5783 - val_loss: 1.1876 - val_acc: 0.5749\n","Epoch 11/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 1.1413 - acc: 0.6014 - val_loss: 1.0935 - val_acc: 0.6040\n","Epoch 12/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 1.0887 - acc: 0.6155 - val_loss: 1.0816 - val_acc: 0.6308\n","Epoch 13/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 1.0888 - acc: 0.6123 - val_loss: 1.0450 - val_acc: 0.6382\n","Epoch 14/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 1.0559 - acc: 0.6313 - val_loss: 1.0418 - val_acc: 0.6345\n","Epoch 15/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 1.0397 - acc: 0.6276 - val_loss: 1.0075 - val_acc: 0.6599\n","Epoch 16/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 1.0233 - acc: 0.6449 - val_loss: 1.0122 - val_acc: 0.6285\n","Epoch 17/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 1.0065 - acc: 0.6535 - val_loss: 0.9840 - val_acc: 0.6780\n","Epoch 18/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 0.9890 - acc: 0.6578 - val_loss: 0.9809 - val_acc: 0.6671\n","Epoch 19/60\n","3472/3472 [==============================] - 36s 10ms/step - loss: 0.9858 - acc: 0.6573 - val_loss: 0.9911 - val_acc: 0.6662\n","Epoch 20/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 0.9617 - acc: 0.6696 - val_loss: 0.9452 - val_acc: 0.6884\n","Epoch 21/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 0.9585 - acc: 0.6639 - val_loss: 0.9381 - val_acc: 0.6702\n","Epoch 22/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.9417 - acc: 0.6728 - val_loss: 1.0403 - val_acc: 0.6178\n","Epoch 23/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 0.9389 - acc: 0.6705 - val_loss: 0.9345 - val_acc: 0.6768\n","Epoch 24/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 0.9118 - acc: 0.6858 - val_loss: 0.9135 - val_acc: 0.6976\n","Epoch 25/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.9146 - acc: 0.6806 - val_loss: 0.8924 - val_acc: 0.7056\n","Epoch 26/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.9206 - acc: 0.6737 - val_loss: 0.9467 - val_acc: 0.6728\n","Epoch 27/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.9005 - acc: 0.6881 - val_loss: 0.9151 - val_acc: 0.6869\n","Epoch 28/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.8860 - acc: 0.6901 - val_loss: 0.8756 - val_acc: 0.6881\n","Epoch 29/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 0.8832 - acc: 0.6898 - val_loss: 0.8501 - val_acc: 0.7126\n","Epoch 30/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 0.8674 - acc: 0.6984 - val_loss: 0.8709 - val_acc: 0.6826\n","Epoch 31/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.8554 - acc: 0.7059 - val_loss: 0.8519 - val_acc: 0.6982\n","Epoch 32/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 0.8551 - acc: 0.7059 - val_loss: 0.8496 - val_acc: 0.7160\n","Epoch 33/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 0.8495 - acc: 0.7010 - val_loss: 0.8072 - val_acc: 0.7278\n","Epoch 34/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 0.8322 - acc: 0.7085 - val_loss: 0.8191 - val_acc: 0.7111\n","Epoch 35/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 0.8359 - acc: 0.7146 - val_loss: 0.8125 - val_acc: 0.7131\n","Epoch 36/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.8195 - acc: 0.7215 - val_loss: 0.8981 - val_acc: 0.6714\n","Epoch 37/60\n","3472/3472 [==============================] - 37s 11ms/step - loss: 0.8206 - acc: 0.7146 - val_loss: 0.8022 - val_acc: 0.7247\n","Epoch 38/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.8052 - acc: 0.7209 - val_loss: 0.8406 - val_acc: 0.6938\n","Epoch 39/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.7977 - acc: 0.7203 - val_loss: 0.7893 - val_acc: 0.7189\n","Epoch 40/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.7922 - acc: 0.7247 - val_loss: 0.7860 - val_acc: 0.7321\n","Epoch 41/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.7960 - acc: 0.7221 - val_loss: 0.7719 - val_acc: 0.7368\n","Epoch 42/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.7848 - acc: 0.7281 - val_loss: 0.7877 - val_acc: 0.7175\n","Epoch 43/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.7775 - acc: 0.7301 - val_loss: 0.7591 - val_acc: 0.7293\n","Epoch 44/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.7755 - acc: 0.7298 - val_loss: 0.8148 - val_acc: 0.6872\n","Epoch 45/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.7686 - acc: 0.7264 - val_loss: 0.7452 - val_acc: 0.7422\n","Epoch 46/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.7713 - acc: 0.7281 - val_loss: 0.7328 - val_acc: 0.7457\n","Epoch 47/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.7531 - acc: 0.7350 - val_loss: 0.7787 - val_acc: 0.7252\n","Epoch 48/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.7573 - acc: 0.7313 - val_loss: 0.7283 - val_acc: 0.7529\n","Epoch 49/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.7424 - acc: 0.7382 - val_loss: 0.8521 - val_acc: 0.7065\n","Epoch 50/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.7449 - acc: 0.7408 - val_loss: 0.7945 - val_acc: 0.7100\n","Epoch 51/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.7430 - acc: 0.7460 - val_loss: 0.7131 - val_acc: 0.7503\n","Epoch 52/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.7274 - acc: 0.7468 - val_loss: 0.7186 - val_acc: 0.7396\n","Epoch 53/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 0.7275 - acc: 0.7457 - val_loss: 0.7691 - val_acc: 0.7327\n","Epoch 54/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.7243 - acc: 0.7428 - val_loss: 0.7113 - val_acc: 0.7440\n","Epoch 55/60\n","3472/3472 [==============================] - 39s 11ms/step - loss: 0.7112 - acc: 0.7425 - val_loss: 0.8075 - val_acc: 0.7151\n","Epoch 56/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.7100 - acc: 0.7546 - val_loss: 0.6906 - val_acc: 0.7641\n","Epoch 57/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.6956 - acc: 0.7604 - val_loss: 0.6808 - val_acc: 0.7615\n","Epoch 58/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.6936 - acc: 0.7584 - val_loss: 0.6861 - val_acc: 0.7535\n","Epoch 59/60\n","3472/3472 [==============================] - 34s 10ms/step - loss: 0.7053 - acc: 0.7483 - val_loss: 0.7067 - val_acc: 0.7480\n","Epoch 60/60\n","3472/3472 [==============================] - 35s 10ms/step - loss: 0.6932 - acc: 0.7589 - val_loss: 0.7010 - val_acc: 0.7632\n","Accuracy[0.6617] Recall[0.6020] F1[0.5849] at fold[0]\n","______________________________________________________\n","Start Training\n","Train on 3456 samples, validate on 3456 samples\n","Epoch 1/60\n","3456/3456 [==============================] - 35s 10ms/step - loss: 2.6276 - acc: 0.1962 - val_loss: 2.1436 - val_acc: 0.3464\n","Epoch 2/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 2.0624 - acc: 0.3206 - val_loss: 2.0377 - val_acc: 0.2882\n","Epoch 3/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 1.7170 - acc: 0.4106 - val_loss: 1.6336 - val_acc: 0.4693\n","Epoch 4/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 1.5169 - acc: 0.4748 - val_loss: 1.4312 - val_acc: 0.4742\n","Epoch 5/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 1.3948 - acc: 0.5124 - val_loss: 1.3460 - val_acc: 0.5038\n","Epoch 6/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 1.3088 - acc: 0.5203 - val_loss: 1.2786 - val_acc: 0.5370\n","Epoch 7/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 1.2509 - acc: 0.5518 - val_loss: 1.2291 - val_acc: 0.5720\n","Epoch 8/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 1.2078 - acc: 0.5654 - val_loss: 1.2804 - val_acc: 0.4899\n","Epoch 9/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 1.1757 - acc: 0.5723 - val_loss: 1.1610 - val_acc: 0.5639\n","Epoch 10/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 1.1584 - acc: 0.5830 - val_loss: 1.1166 - val_acc: 0.6178\n","Epoch 11/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 1.1105 - acc: 0.5952 - val_loss: 1.1670 - val_acc: 0.5917\n","Epoch 12/60\n","3456/3456 [==============================] - 37s 11ms/step - loss: 1.1155 - acc: 0.5920 - val_loss: 1.1307 - val_acc: 0.5992\n","Epoch 13/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 1.0651 - acc: 0.6128 - val_loss: 1.1473 - val_acc: 0.5995\n","Epoch 14/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 1.0328 - acc: 0.6331 - val_loss: 1.1373 - val_acc: 0.6042\n","Epoch 15/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 1.0580 - acc: 0.6143 - val_loss: 1.0924 - val_acc: 0.6123\n","Epoch 16/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 1.0324 - acc: 0.6270 - val_loss: 0.9915 - val_acc: 0.6473\n","Epoch 17/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.9961 - acc: 0.6438 - val_loss: 1.0306 - val_acc: 0.6088\n","Epoch 18/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.9997 - acc: 0.6473 - val_loss: 1.0402 - val_acc: 0.6247\n","Epoch 19/60\n","3456/3456 [==============================] - 35s 10ms/step - loss: 0.9714 - acc: 0.6510 - val_loss: 0.9826 - val_acc: 0.6522\n","Epoch 20/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.9852 - acc: 0.6464 - val_loss: 0.9719 - val_acc: 0.6406\n","Epoch 21/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.9700 - acc: 0.6473 - val_loss: 0.9211 - val_acc: 0.6782\n","Epoch 22/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.9588 - acc: 0.6534 - val_loss: 1.0785 - val_acc: 0.6001\n","Epoch 23/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.9420 - acc: 0.6649 - val_loss: 0.9272 - val_acc: 0.6617\n","Epoch 24/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.9265 - acc: 0.6733 - val_loss: 0.9751 - val_acc: 0.6314\n","Epoch 25/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.9357 - acc: 0.6687 - val_loss: 0.9029 - val_acc: 0.6782\n","Epoch 26/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.9204 - acc: 0.6693 - val_loss: 0.9104 - val_acc: 0.6910\n","Epoch 27/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.9077 - acc: 0.6762 - val_loss: 0.9510 - val_acc: 0.6615\n","Epoch 28/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.9121 - acc: 0.6736 - val_loss: 0.8655 - val_acc: 0.7086\n","Epoch 29/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.9068 - acc: 0.6759 - val_loss: 0.9573 - val_acc: 0.6496\n","Epoch 30/60\n","3456/3456 [==============================] - 37s 11ms/step - loss: 0.8911 - acc: 0.6829 - val_loss: 0.8832 - val_acc: 0.6768\n","Epoch 31/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.8891 - acc: 0.6832 - val_loss: 0.8847 - val_acc: 0.6675\n","Epoch 32/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.8691 - acc: 0.6999 - val_loss: 0.9200 - val_acc: 0.6597\n","Epoch 33/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.8702 - acc: 0.6950 - val_loss: 0.8639 - val_acc: 0.6806\n","Epoch 34/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.8713 - acc: 0.6858 - val_loss: 0.8580 - val_acc: 0.6843\n","Epoch 35/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.8496 - acc: 0.7095 - val_loss: 0.8844 - val_acc: 0.6817\n","Epoch 36/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.8626 - acc: 0.6907 - val_loss: 0.8127 - val_acc: 0.7251\n","Epoch 37/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.8449 - acc: 0.7011 - val_loss: 0.8226 - val_acc: 0.7054\n","Epoch 38/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.8420 - acc: 0.7052 - val_loss: 0.8053 - val_acc: 0.7277\n","Epoch 39/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.8288 - acc: 0.7072 - val_loss: 0.8222 - val_acc: 0.7083\n","Epoch 40/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.8313 - acc: 0.6962 - val_loss: 0.8934 - val_acc: 0.6609\n","Epoch 41/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.8434 - acc: 0.6985 - val_loss: 0.8253 - val_acc: 0.7034\n","Epoch 42/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.8070 - acc: 0.7164 - val_loss: 0.8197 - val_acc: 0.6962\n","Epoch 43/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.8168 - acc: 0.7101 - val_loss: 0.9557 - val_acc: 0.6481\n","Epoch 44/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.8236 - acc: 0.7037 - val_loss: 0.8163 - val_acc: 0.7002\n","Epoch 45/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.7937 - acc: 0.7283 - val_loss: 0.8297 - val_acc: 0.7028\n","Epoch 46/60\n","3456/3456 [==============================] - 35s 10ms/step - loss: 0.8056 - acc: 0.7133 - val_loss: 0.8377 - val_acc: 0.7147\n","Epoch 47/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.7895 - acc: 0.7214 - val_loss: 0.7967 - val_acc: 0.7130\n","Epoch 48/60\n","3456/3456 [==============================] - 37s 11ms/step - loss: 0.7913 - acc: 0.7266 - val_loss: 0.7829 - val_acc: 0.7179\n","Epoch 49/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.7762 - acc: 0.7297 - val_loss: 0.7688 - val_acc: 0.7370\n","Epoch 50/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.7869 - acc: 0.7173 - val_loss: 0.7617 - val_acc: 0.7274\n","Epoch 51/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.7628 - acc: 0.7321 - val_loss: 0.8007 - val_acc: 0.6982\n","Epoch 52/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.7900 - acc: 0.7153 - val_loss: 0.8430 - val_acc: 0.7083\n","Epoch 53/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.7647 - acc: 0.7323 - val_loss: 0.7322 - val_acc: 0.7503\n","Epoch 54/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.7548 - acc: 0.7378 - val_loss: 0.7359 - val_acc: 0.7486\n","Epoch 55/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.7455 - acc: 0.7367 - val_loss: 0.8623 - val_acc: 0.6994\n","Epoch 56/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.7508 - acc: 0.7378 - val_loss: 0.7375 - val_acc: 0.7335\n","Epoch 57/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.7460 - acc: 0.7387 - val_loss: 0.8316 - val_acc: 0.6965\n","Epoch 58/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.7462 - acc: 0.7350 - val_loss: 0.7653 - val_acc: 0.7176\n","Epoch 59/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.7353 - acc: 0.7436 - val_loss: 0.7893 - val_acc: 0.7109\n","Epoch 60/60\n","3456/3456 [==============================] - 34s 10ms/step - loss: 0.7419 - acc: 0.7332 - val_loss: 0.7527 - val_acc: 0.7318\n","Accuracy[0.6578] Recall[0.5515] F1[0.5408] at fold[1]\n","______________________________________________________\n","Start Training\n","Train on 3450 samples, validate on 3450 samples\n","Epoch 1/60\n","3450/3450 [==============================] - 36s 10ms/step - loss: 2.5287 - acc: 0.1751 - val_loss: 2.2437 - val_acc: 0.3145\n","Epoch 2/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 2.0880 - acc: 0.3441 - val_loss: 1.9330 - val_acc: 0.4029\n","Epoch 3/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 1.7441 - acc: 0.4197 - val_loss: 1.7367 - val_acc: 0.4128\n","Epoch 4/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 1.5407 - acc: 0.4614 - val_loss: 1.4086 - val_acc: 0.5194\n","Epoch 5/60\n","3450/3450 [==============================] - 37s 11ms/step - loss: 1.4385 - acc: 0.4872 - val_loss: 1.4244 - val_acc: 0.4406\n","Epoch 6/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 1.3422 - acc: 0.5212 - val_loss: 1.3482 - val_acc: 0.5612\n","Epoch 7/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 1.2925 - acc: 0.5290 - val_loss: 1.2595 - val_acc: 0.5229\n","Epoch 8/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 1.2326 - acc: 0.5536 - val_loss: 1.2593 - val_acc: 0.5386\n","Epoch 9/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 1.1834 - acc: 0.5826 - val_loss: 1.1463 - val_acc: 0.5930\n","Epoch 10/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 1.1832 - acc: 0.5748 - val_loss: 1.1027 - val_acc: 0.6513\n","Epoch 11/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 1.1311 - acc: 0.5948 - val_loss: 1.2142 - val_acc: 0.5742\n","Epoch 12/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 1.1223 - acc: 0.5887 - val_loss: 1.1540 - val_acc: 0.5672\n","Epoch 13/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 1.0791 - acc: 0.6200 - val_loss: 1.0355 - val_acc: 0.6368\n","Epoch 14/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 1.0571 - acc: 0.6296 - val_loss: 1.0400 - val_acc: 0.6197\n","Epoch 15/60\n","3450/3450 [==============================] - 35s 10ms/step - loss: 1.0419 - acc: 0.6391 - val_loss: 1.0322 - val_acc: 0.6452\n","Epoch 16/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 1.0092 - acc: 0.6507 - val_loss: 0.9838 - val_acc: 0.6568\n","Epoch 17/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 1.0112 - acc: 0.6449 - val_loss: 1.0163 - val_acc: 0.6293\n","Epoch 18/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.9825 - acc: 0.6603 - val_loss: 0.9947 - val_acc: 0.6446\n","Epoch 19/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.9784 - acc: 0.6690 - val_loss: 0.9869 - val_acc: 0.6319\n","Epoch 20/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.9643 - acc: 0.6678 - val_loss: 0.9505 - val_acc: 0.6516\n","Epoch 21/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.9573 - acc: 0.6675 - val_loss: 0.9755 - val_acc: 0.6417\n","Epoch 22/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.9464 - acc: 0.6751 - val_loss: 0.9937 - val_acc: 0.6261\n","Epoch 23/60\n","3450/3450 [==============================] - 37s 11ms/step - loss: 0.9392 - acc: 0.6713 - val_loss: 0.9395 - val_acc: 0.6635\n","Epoch 24/60\n","3450/3450 [==============================] - 35s 10ms/step - loss: 0.9204 - acc: 0.6791 - val_loss: 0.9732 - val_acc: 0.6600\n","Epoch 25/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.9205 - acc: 0.6762 - val_loss: 0.9312 - val_acc: 0.6629\n","Epoch 26/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.9202 - acc: 0.6826 - val_loss: 0.8897 - val_acc: 0.7055\n","Epoch 27/60\n","3450/3450 [==============================] - 35s 10ms/step - loss: 0.9083 - acc: 0.6855 - val_loss: 0.8904 - val_acc: 0.6974\n","Epoch 28/60\n","3450/3450 [==============================] - 35s 10ms/step - loss: 0.8879 - acc: 0.7038 - val_loss: 0.9329 - val_acc: 0.6757\n","Epoch 29/60\n","3450/3450 [==============================] - 35s 10ms/step - loss: 0.8812 - acc: 0.6971 - val_loss: 0.8987 - val_acc: 0.6658\n","Epoch 30/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.8773 - acc: 0.6986 - val_loss: 0.9163 - val_acc: 0.6820\n","Epoch 31/60\n","3450/3450 [==============================] - 35s 10ms/step - loss: 0.8745 - acc: 0.6965 - val_loss: 0.9592 - val_acc: 0.6603\n","Epoch 32/60\n","3450/3450 [==============================] - 35s 10ms/step - loss: 0.8682 - acc: 0.7090 - val_loss: 0.8866 - val_acc: 0.6812\n","Epoch 33/60\n","3450/3450 [==============================] - 35s 10ms/step - loss: 0.8466 - acc: 0.7186 - val_loss: 0.9005 - val_acc: 0.6632\n","Epoch 34/60\n","3450/3450 [==============================] - 35s 10ms/step - loss: 0.8597 - acc: 0.7043 - val_loss: 0.8720 - val_acc: 0.6690\n","Epoch 35/60\n","3450/3450 [==============================] - 35s 10ms/step - loss: 0.8542 - acc: 0.7058 - val_loss: 0.8410 - val_acc: 0.7214\n","Epoch 36/60\n","3450/3450 [==============================] - 35s 10ms/step - loss: 0.8423 - acc: 0.7078 - val_loss: 0.8277 - val_acc: 0.7148\n","Epoch 37/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.8326 - acc: 0.7145 - val_loss: 0.8591 - val_acc: 0.7064\n","Epoch 38/60\n","3450/3450 [==============================] - 35s 10ms/step - loss: 0.8287 - acc: 0.7096 - val_loss: 0.8008 - val_acc: 0.7304\n","Epoch 39/60\n","3450/3450 [==============================] - 35s 10ms/step - loss: 0.8247 - acc: 0.7174 - val_loss: 0.8320 - val_acc: 0.7032\n","Epoch 40/60\n","3450/3450 [==============================] - 39s 11ms/step - loss: 0.8249 - acc: 0.7206 - val_loss: 0.8273 - val_acc: 0.6922\n","Epoch 41/60\n","3450/3450 [==============================] - 35s 10ms/step - loss: 0.8135 - acc: 0.7209 - val_loss: 0.7974 - val_acc: 0.7293\n","Epoch 42/60\n","3450/3450 [==============================] - 35s 10ms/step - loss: 0.8019 - acc: 0.7258 - val_loss: 0.8138 - val_acc: 0.7093\n","Epoch 43/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.8062 - acc: 0.7304 - val_loss: 0.8003 - val_acc: 0.7235\n","Epoch 44/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.7976 - acc: 0.7310 - val_loss: 0.7816 - val_acc: 0.7313\n","Epoch 45/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.7972 - acc: 0.7322 - val_loss: 0.7759 - val_acc: 0.7417\n","Epoch 46/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.7872 - acc: 0.7435 - val_loss: 0.8056 - val_acc: 0.7183\n","Epoch 47/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.7870 - acc: 0.7333 - val_loss: 0.9108 - val_acc: 0.6672\n","Epoch 48/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.7846 - acc: 0.7409 - val_loss: 0.7684 - val_acc: 0.7420\n","Epoch 49/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.7710 - acc: 0.7394 - val_loss: 0.7707 - val_acc: 0.7368\n","Epoch 50/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.7706 - acc: 0.7365 - val_loss: 0.8056 - val_acc: 0.7232\n","Epoch 51/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.7703 - acc: 0.7345 - val_loss: 0.7973 - val_acc: 0.7139\n","Epoch 52/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.7552 - acc: 0.7426 - val_loss: 0.7805 - val_acc: 0.7414\n","Epoch 53/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.7619 - acc: 0.7403 - val_loss: 0.7485 - val_acc: 0.7484\n","Epoch 54/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.7553 - acc: 0.7449 - val_loss: 0.7756 - val_acc: 0.7449\n","Epoch 55/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.7511 - acc: 0.7528 - val_loss: 0.7346 - val_acc: 0.7530\n","Epoch 56/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.7422 - acc: 0.7472 - val_loss: 0.7861 - val_acc: 0.7307\n","Epoch 57/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.7436 - acc: 0.7525 - val_loss: 0.7181 - val_acc: 0.7612\n","Epoch 58/60\n","3450/3450 [==============================] - 37s 11ms/step - loss: 0.7410 - acc: 0.7507 - val_loss: 0.7234 - val_acc: 0.7617\n","Epoch 59/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.7385 - acc: 0.7464 - val_loss: 0.7304 - val_acc: 0.7603\n","Epoch 60/60\n","3450/3450 [==============================] - 34s 10ms/step - loss: 0.7280 - acc: 0.7574 - val_loss: 0.7472 - val_acc: 0.7493\n","Accuracy[0.6413] Recall[0.6025] F1[0.5719] at fold[2]\n","______________________________________________________\n","Start Training\n","Train on 3476 samples, validate on 3476 samples\n","Epoch 1/60\n","3476/3476 [==============================] - 36s 10ms/step - loss: 2.2279 - acc: 0.2768 - val_loss: 2.0168 - val_acc: 0.3685\n","Epoch 2/60\n","3476/3476 [==============================] - 34s 10ms/step - loss: 1.8286 - acc: 0.4071 - val_loss: 1.8006 - val_acc: 0.3550\n","Epoch 3/60\n","3476/3476 [==============================] - 34s 10ms/step - loss: 1.5505 - acc: 0.4606 - val_loss: 1.4071 - val_acc: 0.4960\n","Epoch 4/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 1.4180 - acc: 0.4865 - val_loss: 1.3843 - val_acc: 0.4954\n","Epoch 5/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 1.3170 - acc: 0.5199 - val_loss: 1.2507 - val_acc: 0.5526\n","Epoch 6/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 1.2579 - acc: 0.5397 - val_loss: 1.1906 - val_acc: 0.5803\n","Epoch 7/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 1.2243 - acc: 0.5498 - val_loss: 1.2421 - val_acc: 0.5423\n","Epoch 8/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 1.1829 - acc: 0.5713 - val_loss: 1.1222 - val_acc: 0.6047\n","Epoch 9/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 1.1513 - acc: 0.5765 - val_loss: 1.1149 - val_acc: 0.6036\n","Epoch 10/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 1.1106 - acc: 0.6067 - val_loss: 1.0887 - val_acc: 0.5852\n","Epoch 11/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 1.1054 - acc: 0.6047 - val_loss: 1.0737 - val_acc: 0.6159\n","Epoch 12/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 1.0608 - acc: 0.6257 - val_loss: 1.0268 - val_acc: 0.6479\n","Epoch 13/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 1.0575 - acc: 0.6220 - val_loss: 1.0314 - val_acc: 0.6194\n","Epoch 14/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 1.0312 - acc: 0.6372 - val_loss: 1.1129 - val_acc: 0.5944\n","Epoch 15/60\n","3476/3476 [==============================] - 37s 11ms/step - loss: 1.0071 - acc: 0.6542 - val_loss: 0.9836 - val_acc: 0.6545\n","Epoch 16/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.9996 - acc: 0.6456 - val_loss: 0.9971 - val_acc: 0.6628\n","Epoch 17/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.9927 - acc: 0.6551 - val_loss: 0.9607 - val_acc: 0.6951\n","Epoch 18/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.9729 - acc: 0.6677 - val_loss: 0.9573 - val_acc: 0.6640\n","Epoch 19/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.9572 - acc: 0.6669 - val_loss: 0.9561 - val_acc: 0.6709\n","Epoch 20/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.9455 - acc: 0.6720 - val_loss: 0.9677 - val_acc: 0.6692\n","Epoch 21/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.9328 - acc: 0.6818 - val_loss: 0.9241 - val_acc: 0.7074\n","Epoch 22/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.9321 - acc: 0.6812 - val_loss: 0.9205 - val_acc: 0.6907\n","Epoch 23/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.9138 - acc: 0.6827 - val_loss: 0.8883 - val_acc: 0.7060\n","Epoch 24/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.9071 - acc: 0.6884 - val_loss: 0.9034 - val_acc: 0.7022\n","Epoch 25/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.8921 - acc: 0.6982 - val_loss: 0.8719 - val_acc: 0.6956\n","Epoch 26/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.8833 - acc: 0.7068 - val_loss: 0.8943 - val_acc: 0.7040\n","Epoch 27/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.8720 - acc: 0.7146 - val_loss: 0.8576 - val_acc: 0.7080\n","Epoch 28/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.8601 - acc: 0.7054 - val_loss: 0.8514 - val_acc: 0.7152\n","Epoch 29/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.8562 - acc: 0.7034 - val_loss: 0.8302 - val_acc: 0.7184\n","Epoch 30/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.8436 - acc: 0.7230 - val_loss: 0.8958 - val_acc: 0.6755\n","Epoch 31/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.8459 - acc: 0.7068 - val_loss: 0.8245 - val_acc: 0.7230\n","Epoch 32/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.8289 - acc: 0.7195 - val_loss: 0.8186 - val_acc: 0.7155\n","Epoch 33/60\n","3476/3476 [==============================] - 37s 11ms/step - loss: 0.8269 - acc: 0.7235 - val_loss: 0.8247 - val_acc: 0.7089\n","Epoch 34/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.8139 - acc: 0.7204 - val_loss: 0.8031 - val_acc: 0.7264\n","Epoch 35/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.8059 - acc: 0.7273 - val_loss: 0.8048 - val_acc: 0.7126\n","Epoch 36/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.7980 - acc: 0.7379 - val_loss: 0.7876 - val_acc: 0.7362\n","Epoch 37/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.7903 - acc: 0.7287 - val_loss: 0.8512 - val_acc: 0.6942\n","Epoch 38/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.7748 - acc: 0.7428 - val_loss: 0.7738 - val_acc: 0.7371\n","Epoch 39/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.7676 - acc: 0.7394 - val_loss: 0.7368 - val_acc: 0.7612\n","Epoch 40/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.7743 - acc: 0.7348 - val_loss: 0.7637 - val_acc: 0.7460\n","Epoch 41/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.7677 - acc: 0.7399 - val_loss: 0.7908 - val_acc: 0.7224\n","Epoch 42/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.7567 - acc: 0.7491 - val_loss: 0.7427 - val_acc: 0.7566\n","Epoch 43/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.7540 - acc: 0.7477 - val_loss: 0.7607 - val_acc: 0.7396\n","Epoch 44/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.7370 - acc: 0.7560 - val_loss: 0.7356 - val_acc: 0.7569\n","Epoch 45/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.7378 - acc: 0.7523 - val_loss: 0.7419 - val_acc: 0.7474\n","Epoch 46/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.7330 - acc: 0.7532 - val_loss: 0.7665 - val_acc: 0.7394\n","Epoch 47/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.7305 - acc: 0.7586 - val_loss: 0.7186 - val_acc: 0.7673\n","Epoch 48/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.7134 - acc: 0.7606 - val_loss: 0.6943 - val_acc: 0.7759\n","Epoch 49/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.7085 - acc: 0.7655 - val_loss: 0.7305 - val_acc: 0.7569\n","Epoch 50/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.7086 - acc: 0.7615 - val_loss: 0.7000 - val_acc: 0.7555\n","Epoch 51/60\n","3476/3476 [==============================] - 37s 11ms/step - loss: 0.6990 - acc: 0.7635 - val_loss: 0.6998 - val_acc: 0.7638\n","Epoch 52/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.7012 - acc: 0.7601 - val_loss: 0.6678 - val_acc: 0.7883\n","Epoch 53/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.6931 - acc: 0.7675 - val_loss: 0.6745 - val_acc: 0.7894\n","Epoch 54/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.6951 - acc: 0.7681 - val_loss: 0.6805 - val_acc: 0.7733\n","Epoch 55/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.6839 - acc: 0.7722 - val_loss: 0.7039 - val_acc: 0.7632\n","Epoch 56/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.6792 - acc: 0.7739 - val_loss: 0.6584 - val_acc: 0.7776\n","Epoch 57/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.6722 - acc: 0.7733 - val_loss: 0.7070 - val_acc: 0.7445\n","Epoch 58/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.6751 - acc: 0.7719 - val_loss: 0.6828 - val_acc: 0.7793\n","Epoch 59/60\n","3476/3476 [==============================] - 35s 10ms/step - loss: 0.6622 - acc: 0.7819 - val_loss: 0.6438 - val_acc: 0.7822\n","Epoch 60/60\n","3476/3476 [==============================] - 34s 10ms/step - loss: 0.6632 - acc: 0.7788 - val_loss: 0.6733 - val_acc: 0.7609\n","Accuracy[0.7114] Recall[0.6681] F1[0.6596] at fold[3]\n","______________________________________________________\n","Start Training\n","Train on 3460 samples, validate on 3460 samples\n","Epoch 1/60\n","3460/3460 [==============================] - 36s 10ms/step - loss: 2.2454 - acc: 0.2624 - val_loss: 2.0616 - val_acc: 0.3436\n","Epoch 2/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 1.9227 - acc: 0.3801 - val_loss: 1.7577 - val_acc: 0.3991\n","Epoch 3/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 1.6386 - acc: 0.4419 - val_loss: 1.6418 - val_acc: 0.4006\n","Epoch 4/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 1.4713 - acc: 0.4844 - val_loss: 1.4669 - val_acc: 0.4454\n","Epoch 5/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 1.3809 - acc: 0.5026 - val_loss: 1.3411 - val_acc: 0.5020\n","Epoch 6/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 1.2965 - acc: 0.5387 - val_loss: 1.2412 - val_acc: 0.5688\n","Epoch 7/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 1.2645 - acc: 0.5462 - val_loss: 1.2438 - val_acc: 0.5627\n","Epoch 8/60\n","3460/3460 [==============================] - 37s 11ms/step - loss: 1.2285 - acc: 0.5584 - val_loss: 1.1746 - val_acc: 0.5844\n","Epoch 9/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 1.1915 - acc: 0.5711 - val_loss: 1.1659 - val_acc: 0.5685\n","Epoch 10/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 1.1836 - acc: 0.5694 - val_loss: 1.1200 - val_acc: 0.6098\n","Epoch 11/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 1.1342 - acc: 0.5954 - val_loss: 1.1236 - val_acc: 0.6003\n","Epoch 12/60\n","3460/3460 [==============================] - 35s 10ms/step - loss: 1.1203 - acc: 0.6009 - val_loss: 1.0878 - val_acc: 0.6197\n","Epoch 13/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 1.1055 - acc: 0.5997 - val_loss: 1.0921 - val_acc: 0.6399\n","Epoch 14/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 1.0882 - acc: 0.6145 - val_loss: 1.0748 - val_acc: 0.6095\n","Epoch 15/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 1.0723 - acc: 0.6205 - val_loss: 1.0657 - val_acc: 0.6237\n","Epoch 16/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 1.0564 - acc: 0.6327 - val_loss: 1.0736 - val_acc: 0.6350\n","Epoch 17/60\n","3460/3460 [==============================] - 35s 10ms/step - loss: 1.0382 - acc: 0.6260 - val_loss: 1.0968 - val_acc: 0.5934\n","Epoch 18/60\n","3460/3460 [==============================] - 35s 10ms/step - loss: 1.0312 - acc: 0.6457 - val_loss: 1.0078 - val_acc: 0.6552\n","Epoch 19/60\n","3460/3460 [==============================] - 35s 10ms/step - loss: 1.0076 - acc: 0.6477 - val_loss: 1.0183 - val_acc: 0.6321\n","Epoch 20/60\n","3460/3460 [==============================] - 35s 10ms/step - loss: 1.0052 - acc: 0.6468 - val_loss: 0.9837 - val_acc: 0.6645\n","Epoch 21/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.9794 - acc: 0.6662 - val_loss: 0.9691 - val_acc: 0.6434\n","Epoch 22/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.9727 - acc: 0.6613 - val_loss: 0.9788 - val_acc: 0.6335\n","Epoch 23/60\n","3460/3460 [==============================] - 35s 10ms/step - loss: 0.9572 - acc: 0.6653 - val_loss: 0.9917 - val_acc: 0.6312\n","Epoch 24/60\n","3460/3460 [==============================] - 35s 10ms/step - loss: 0.9566 - acc: 0.6616 - val_loss: 0.9485 - val_acc: 0.6682\n","Epoch 25/60\n","3460/3460 [==============================] - 35s 10ms/step - loss: 0.9543 - acc: 0.6717 - val_loss: 0.9707 - val_acc: 0.6905\n","Epoch 26/60\n","3460/3460 [==============================] - 39s 11ms/step - loss: 0.9387 - acc: 0.6769 - val_loss: 0.9788 - val_acc: 0.6720\n","Epoch 27/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.9208 - acc: 0.6887 - val_loss: 0.9429 - val_acc: 0.6523\n","Epoch 28/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.9223 - acc: 0.6803 - val_loss: 0.9061 - val_acc: 0.6853\n","Epoch 29/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.9057 - acc: 0.6873 - val_loss: 0.8772 - val_acc: 0.6997\n","Epoch 30/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.9054 - acc: 0.6899 - val_loss: 0.8936 - val_acc: 0.6740\n","Epoch 31/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.9067 - acc: 0.6766 - val_loss: 0.8722 - val_acc: 0.6954\n","Epoch 32/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.8851 - acc: 0.6893 - val_loss: 0.9912 - val_acc: 0.6491\n","Epoch 33/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.8807 - acc: 0.6922 - val_loss: 0.9068 - val_acc: 0.6899\n","Epoch 34/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.8729 - acc: 0.7038 - val_loss: 0.8859 - val_acc: 0.6688\n","Epoch 35/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.8678 - acc: 0.7040 - val_loss: 0.8877 - val_acc: 0.6939\n","Epoch 36/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.8591 - acc: 0.7029 - val_loss: 0.8419 - val_acc: 0.7107\n","Epoch 37/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.8527 - acc: 0.7064 - val_loss: 0.8787 - val_acc: 0.6931\n","Epoch 38/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.8486 - acc: 0.7043 - val_loss: 0.8381 - val_acc: 0.7092\n","Epoch 39/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.8356 - acc: 0.7133 - val_loss: 0.8415 - val_acc: 0.6942\n","Epoch 40/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.8311 - acc: 0.7066 - val_loss: 0.8308 - val_acc: 0.7275\n","Epoch 41/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.8313 - acc: 0.7078 - val_loss: 0.9664 - val_acc: 0.6373\n","Epoch 42/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.8334 - acc: 0.7116 - val_loss: 0.8515 - val_acc: 0.6884\n","Epoch 43/60\n","3460/3460 [==============================] - 36s 10ms/step - loss: 0.8101 - acc: 0.7211 - val_loss: 0.8105 - val_acc: 0.7078\n","Epoch 44/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.8137 - acc: 0.7139 - val_loss: 0.8251 - val_acc: 0.7014\n","Epoch 45/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.7978 - acc: 0.7197 - val_loss: 0.8151 - val_acc: 0.7130\n","Epoch 46/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.7997 - acc: 0.7145 - val_loss: 0.8347 - val_acc: 0.7171\n","Epoch 47/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.8031 - acc: 0.7171 - val_loss: 0.8062 - val_acc: 0.7153\n","Epoch 48/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.7979 - acc: 0.7237 - val_loss: 0.7679 - val_acc: 0.7410\n","Epoch 49/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.7922 - acc: 0.7202 - val_loss: 0.7869 - val_acc: 0.7277\n","Epoch 50/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.7819 - acc: 0.7254 - val_loss: 0.8216 - val_acc: 0.7118\n","Epoch 51/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.7782 - acc: 0.7286 - val_loss: 0.7439 - val_acc: 0.7474\n","Epoch 52/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.7710 - acc: 0.7315 - val_loss: 0.7630 - val_acc: 0.7439\n","Epoch 53/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.7684 - acc: 0.7376 - val_loss: 0.7768 - val_acc: 0.7263\n","Epoch 54/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.7612 - acc: 0.7327 - val_loss: 0.7290 - val_acc: 0.7460\n","Epoch 55/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.7616 - acc: 0.7324 - val_loss: 0.7790 - val_acc: 0.7309\n","Epoch 56/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.7488 - acc: 0.7431 - val_loss: 0.7358 - val_acc: 0.7451\n","Epoch 57/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.7486 - acc: 0.7382 - val_loss: 0.7232 - val_acc: 0.7526\n","Epoch 58/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.7492 - acc: 0.7408 - val_loss: 0.7673 - val_acc: 0.7249\n","Epoch 59/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.7372 - acc: 0.7468 - val_loss: 0.7142 - val_acc: 0.7590\n","Epoch 60/60\n","3460/3460 [==============================] - 34s 10ms/step - loss: 0.7384 - acc: 0.7439 - val_loss: 0.7918 - val_acc: 0.7113\n","Accuracy[0.7080] Recall[0.6425] F1[0.6139] at fold[4]\n","______________________________________________________\n","Start Training\n","Train on 3511 samples, validate on 3511 samples\n","Epoch 1/60\n","3511/3511 [==============================] - 38s 11ms/step - loss: 2.2149 - acc: 0.3048 - val_loss: 1.9832 - val_acc: 0.3982\n","Epoch 2/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 1.8379 - acc: 0.4198 - val_loss: 1.7331 - val_acc: 0.4295\n","Epoch 3/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 1.6484 - acc: 0.4685 - val_loss: 1.5612 - val_acc: 0.4981\n","Epoch 4/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 1.5069 - acc: 0.5098 - val_loss: 1.5242 - val_acc: 0.4597\n","Epoch 5/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 1.4022 - acc: 0.5386 - val_loss: 1.4669 - val_acc: 0.4893\n","Epoch 6/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 1.3246 - acc: 0.5423 - val_loss: 1.4846 - val_acc: 0.4739\n","Epoch 7/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 1.2497 - acc: 0.5625 - val_loss: 1.3021 - val_acc: 0.5423\n","Epoch 8/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 1.2102 - acc: 0.5708 - val_loss: 1.3746 - val_acc: 0.4776\n","Epoch 9/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 1.1745 - acc: 0.5779 - val_loss: 1.2760 - val_acc: 0.5403\n","Epoch 10/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 1.1184 - acc: 0.6118 - val_loss: 1.2651 - val_acc: 0.5449\n","Epoch 11/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 1.1166 - acc: 0.5998 - val_loss: 1.2331 - val_acc: 0.5440\n","Epoch 12/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 1.0662 - acc: 0.6229 - val_loss: 1.2268 - val_acc: 0.5907\n","Epoch 13/60\n","3511/3511 [==============================] - 34s 10ms/step - loss: 1.0530 - acc: 0.6240 - val_loss: 1.1645 - val_acc: 0.5366\n","Epoch 14/60\n","3511/3511 [==============================] - 34s 10ms/step - loss: 1.0417 - acc: 0.6346 - val_loss: 1.1248 - val_acc: 0.5113\n","Epoch 15/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 1.0184 - acc: 0.6360 - val_loss: 1.2853 - val_acc: 0.5013\n","Epoch 16/60\n","3511/3511 [==============================] - 34s 10ms/step - loss: 1.0070 - acc: 0.6431 - val_loss: 1.1420 - val_acc: 0.5565\n","Epoch 17/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.9899 - acc: 0.6514 - val_loss: 1.1346 - val_acc: 0.5671\n","Epoch 18/60\n","3511/3511 [==============================] - 34s 10ms/step - loss: 0.9695 - acc: 0.6605 - val_loss: 1.2027 - val_acc: 0.4927\n","Epoch 19/60\n","3511/3511 [==============================] - 37s 10ms/step - loss: 0.9610 - acc: 0.6659 - val_loss: 1.0856 - val_acc: 0.6095\n","Epoch 20/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.9510 - acc: 0.6699 - val_loss: 0.9625 - val_acc: 0.6426\n","Epoch 21/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.9350 - acc: 0.6696 - val_loss: 1.0487 - val_acc: 0.6104\n","Epoch 22/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.9280 - acc: 0.6861 - val_loss: 1.0342 - val_acc: 0.6024\n","Epoch 23/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.9230 - acc: 0.6764 - val_loss: 0.9353 - val_acc: 0.6642\n","Epoch 24/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.9057 - acc: 0.6839 - val_loss: 1.0315 - val_acc: 0.6232\n","Epoch 25/60\n","3511/3511 [==============================] - 34s 10ms/step - loss: 0.9011 - acc: 0.6898 - val_loss: 0.9487 - val_acc: 0.6585\n","Epoch 26/60\n","3511/3511 [==============================] - 34s 10ms/step - loss: 0.8903 - acc: 0.6924 - val_loss: 1.1463 - val_acc: 0.5708\n","Epoch 27/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.8878 - acc: 0.6904 - val_loss: 0.9698 - val_acc: 0.6434\n","Epoch 28/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.8747 - acc: 0.6930 - val_loss: 0.9378 - val_acc: 0.6371\n","Epoch 29/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.8676 - acc: 0.6941 - val_loss: 0.9114 - val_acc: 0.6710\n","Epoch 30/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.8617 - acc: 0.6975 - val_loss: 0.9277 - val_acc: 0.6685\n","Epoch 31/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.8582 - acc: 0.6950 - val_loss: 0.9015 - val_acc: 0.6764\n","Epoch 32/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.8433 - acc: 0.7072 - val_loss: 0.9007 - val_acc: 0.6676\n","Epoch 33/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.8427 - acc: 0.6992 - val_loss: 0.8886 - val_acc: 0.6502\n","Epoch 34/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.8380 - acc: 0.7058 - val_loss: 0.9348 - val_acc: 0.6585\n","Epoch 35/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.8210 - acc: 0.7163 - val_loss: 0.8286 - val_acc: 0.7101\n","Epoch 36/60\n","3511/3511 [==============================] - 37s 10ms/step - loss: 0.8271 - acc: 0.7129 - val_loss: 0.8390 - val_acc: 0.6870\n","Epoch 37/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.8157 - acc: 0.7123 - val_loss: 0.8780 - val_acc: 0.6767\n","Epoch 38/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.8090 - acc: 0.7223 - val_loss: 0.8137 - val_acc: 0.7135\n","Epoch 39/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.8064 - acc: 0.7152 - val_loss: 0.8724 - val_acc: 0.6673\n","Epoch 40/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.8012 - acc: 0.7223 - val_loss: 0.9054 - val_acc: 0.6784\n","Epoch 41/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7958 - acc: 0.7186 - val_loss: 0.8527 - val_acc: 0.6668\n","Epoch 42/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7799 - acc: 0.7274 - val_loss: 0.8335 - val_acc: 0.6941\n","Epoch 43/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7859 - acc: 0.7220 - val_loss: 1.0793 - val_acc: 0.6118\n","Epoch 44/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7798 - acc: 0.7314 - val_loss: 0.8175 - val_acc: 0.7152\n","Epoch 45/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7731 - acc: 0.7263 - val_loss: 0.9121 - val_acc: 0.6656\n","Epoch 46/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7577 - acc: 0.7365 - val_loss: 0.7755 - val_acc: 0.7232\n","Epoch 47/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7593 - acc: 0.7354 - val_loss: 0.7728 - val_acc: 0.7274\n","Epoch 48/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7549 - acc: 0.7380 - val_loss: 0.9190 - val_acc: 0.6366\n","Epoch 49/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7593 - acc: 0.7308 - val_loss: 0.7743 - val_acc: 0.7152\n","Epoch 50/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7451 - acc: 0.7402 - val_loss: 0.8227 - val_acc: 0.7021\n","Epoch 51/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7353 - acc: 0.7505 - val_loss: 0.7808 - val_acc: 0.7095\n","Epoch 52/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7283 - acc: 0.7548 - val_loss: 0.7965 - val_acc: 0.7066\n","Epoch 53/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7247 - acc: 0.7553 - val_loss: 0.7655 - val_acc: 0.7135\n","Epoch 54/60\n","3511/3511 [==============================] - 37s 10ms/step - loss: 0.7309 - acc: 0.7431 - val_loss: 0.7788 - val_acc: 0.7197\n","Epoch 55/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7213 - acc: 0.7471 - val_loss: 0.7938 - val_acc: 0.7069\n","Epoch 56/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7215 - acc: 0.7522 - val_loss: 0.7330 - val_acc: 0.7459\n","Epoch 57/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7178 - acc: 0.7531 - val_loss: 0.7769 - val_acc: 0.7303\n","Epoch 58/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7051 - acc: 0.7533 - val_loss: 0.8167 - val_acc: 0.6921\n","Epoch 59/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.6970 - acc: 0.7608 - val_loss: 0.8129 - val_acc: 0.6927\n","Epoch 60/60\n","3511/3511 [==============================] - 35s 10ms/step - loss: 0.7138 - acc: 0.7519 - val_loss: 0.7390 - val_acc: 0.7402\n","Accuracy[0.7306] Recall[0.6609] F1[0.6833] at fold[5]\n","______________________________________________________\n","Start Training\n","Train on 3504 samples, validate on 3504 samples\n","Epoch 1/60\n","3504/3504 [==============================] - 36s 10ms/step - loss: 2.3583 - acc: 0.2594 - val_loss: 2.4123 - val_acc: 0.0939\n","Epoch 2/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 2.1093 - acc: 0.3545 - val_loss: 2.0617 - val_acc: 0.3613\n","Epoch 3/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 1.7694 - acc: 0.4332 - val_loss: 1.8316 - val_acc: 0.3559\n","Epoch 4/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 1.5104 - acc: 0.4703 - val_loss: 3.3278 - val_acc: 0.2979\n","Epoch 5/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 1.4030 - acc: 0.5188 - val_loss: 2.3846 - val_acc: 0.2737\n","Epoch 6/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 1.3033 - acc: 0.5428 - val_loss: 1.4613 - val_acc: 0.5031\n","Epoch 7/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 1.2310 - acc: 0.5648 - val_loss: 1.2657 - val_acc: 0.5571\n","Epoch 8/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 1.2012 - acc: 0.5788 - val_loss: 1.5002 - val_acc: 0.4138\n","Epoch 9/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 1.1728 - acc: 0.5830 - val_loss: 1.4298 - val_acc: 0.3596\n","Epoch 10/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 1.1330 - acc: 0.5965 - val_loss: 1.4094 - val_acc: 0.5251\n","Epoch 11/60\n","3504/3504 [==============================] - 40s 11ms/step - loss: 1.1168 - acc: 0.6050 - val_loss: 1.2994 - val_acc: 0.5459\n","Epoch 12/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 1.0974 - acc: 0.6170 - val_loss: 2.0756 - val_acc: 0.3933\n","Epoch 13/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 1.1088 - acc: 0.6087 - val_loss: 1.2529 - val_acc: 0.5420\n","Epoch 14/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 1.0661 - acc: 0.6236 - val_loss: 1.1605 - val_acc: 0.5494\n","Epoch 15/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 1.0505 - acc: 0.6313 - val_loss: 1.6551 - val_acc: 0.4064\n","Epoch 16/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 1.0580 - acc: 0.6270 - val_loss: 1.3314 - val_acc: 0.5414\n","Epoch 17/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 1.0306 - acc: 0.6373 - val_loss: 1.1855 - val_acc: 0.5822\n","Epoch 18/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 1.0279 - acc: 0.6464 - val_loss: 1.0754 - val_acc: 0.6170\n","Epoch 19/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 1.0134 - acc: 0.6401 - val_loss: 1.2850 - val_acc: 0.5362\n","Epoch 20/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 1.0192 - acc: 0.6484 - val_loss: 1.2385 - val_acc: 0.5551\n","Epoch 21/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 1.0019 - acc: 0.6473 - val_loss: 1.0795 - val_acc: 0.5959\n","Epoch 22/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 0.9983 - acc: 0.6504 - val_loss: 1.3675 - val_acc: 0.4872\n","Epoch 23/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 0.9928 - acc: 0.6604 - val_loss: 1.4834 - val_acc: 0.4917\n","Epoch 24/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 0.9890 - acc: 0.6570 - val_loss: 1.1620 - val_acc: 0.5919\n","Epoch 25/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 0.9676 - acc: 0.6701 - val_loss: 1.1772 - val_acc: 0.5925\n","Epoch 26/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 0.9631 - acc: 0.6630 - val_loss: 1.4286 - val_acc: 0.4775\n","Epoch 27/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 0.9741 - acc: 0.6612 - val_loss: 1.1942 - val_acc: 0.5285\n","Epoch 28/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 0.9567 - acc: 0.6672 - val_loss: 1.0303 - val_acc: 0.6170\n","Epoch 29/60\n","3504/3504 [==============================] - 36s 10ms/step - loss: 0.9480 - acc: 0.6792 - val_loss: 1.0341 - val_acc: 0.6284\n","Epoch 30/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.9462 - acc: 0.6772 - val_loss: 1.0033 - val_acc: 0.6187\n","Epoch 31/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.9453 - acc: 0.6735 - val_loss: 1.1831 - val_acc: 0.5428\n","Epoch 32/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.9426 - acc: 0.6801 - val_loss: 1.1065 - val_acc: 0.5876\n","Epoch 33/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 0.9347 - acc: 0.6767 - val_loss: 1.0074 - val_acc: 0.6621\n","Epoch 34/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.9259 - acc: 0.6844 - val_loss: 1.1644 - val_acc: 0.5565\n","Epoch 35/60\n","3504/3504 [==============================] - 34s 10ms/step - loss: 0.9245 - acc: 0.6787 - val_loss: 1.0190 - val_acc: 0.6027\n","Epoch 36/60\n","3504/3504 [==============================] - 40s 11ms/step - loss: 0.9191 - acc: 0.6858 - val_loss: 1.0914 - val_acc: 0.6124\n","Epoch 37/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.9195 - acc: 0.6881 - val_loss: 0.9925 - val_acc: 0.6453\n","Epoch 38/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.9115 - acc: 0.6884 - val_loss: 1.0212 - val_acc: 0.6079\n","Epoch 39/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.9088 - acc: 0.6938 - val_loss: 0.9740 - val_acc: 0.6598\n","Epoch 40/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.9078 - acc: 0.6906 - val_loss: 1.2865 - val_acc: 0.5000\n","Epoch 41/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.9041 - acc: 0.6878 - val_loss: 1.0552 - val_acc: 0.5956\n","Epoch 42/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.9035 - acc: 0.6886 - val_loss: 1.0255 - val_acc: 0.6279\n","Epoch 43/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8900 - acc: 0.6938 - val_loss: 0.9387 - val_acc: 0.6704\n","Epoch 44/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8928 - acc: 0.6906 - val_loss: 1.1834 - val_acc: 0.5859\n","Epoch 45/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8859 - acc: 0.6998 - val_loss: 1.1379 - val_acc: 0.5922\n","Epoch 46/60\n","3504/3504 [==============================] - 37s 11ms/step - loss: 0.8885 - acc: 0.6978 - val_loss: 1.2047 - val_acc: 0.5602\n","Epoch 47/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8886 - acc: 0.7012 - val_loss: 1.0169 - val_acc: 0.6381\n","Epoch 48/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8795 - acc: 0.6966 - val_loss: 1.2005 - val_acc: 0.5645\n","Epoch 49/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8770 - acc: 0.7041 - val_loss: 0.9646 - val_acc: 0.6655\n","Epoch 50/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8585 - acc: 0.7018 - val_loss: 0.9189 - val_acc: 0.6644\n","Epoch 51/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8588 - acc: 0.7012 - val_loss: 1.0039 - val_acc: 0.6299\n","Epoch 52/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8617 - acc: 0.7086 - val_loss: 0.8500 - val_acc: 0.7061\n","Epoch 53/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8546 - acc: 0.7078 - val_loss: 1.1206 - val_acc: 0.6233\n","Epoch 54/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8606 - acc: 0.6998 - val_loss: 1.2080 - val_acc: 0.5534\n","Epoch 55/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8565 - acc: 0.7035 - val_loss: 0.9676 - val_acc: 0.6284\n","Epoch 56/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8497 - acc: 0.7123 - val_loss: 1.2494 - val_acc: 0.5377\n","Epoch 57/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8480 - acc: 0.7083 - val_loss: 1.0216 - val_acc: 0.6127\n","Epoch 58/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8430 - acc: 0.7086 - val_loss: 0.9702 - val_acc: 0.6704\n","Epoch 59/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8442 - acc: 0.7160 - val_loss: 0.9140 - val_acc: 0.6544\n","Epoch 60/60\n","3504/3504 [==============================] - 35s 10ms/step - loss: 0.8275 - acc: 0.7166 - val_loss: 1.1038 - val_acc: 0.5956\n","Accuracy[0.5368] Recall[0.3867] F1[0.3871] at fold[6]\n","______________________________________________________\n","Start Training\n","Train on 3506 samples, validate on 3506 samples\n","Epoch 1/60\n","3506/3506 [==============================] - 36s 10ms/step - loss: 2.4177 - acc: 0.2268 - val_loss: 2.3520 - val_acc: 0.0944\n","Epoch 2/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 2.1797 - acc: 0.3052 - val_loss: 2.1213 - val_acc: 0.3531\n","Epoch 3/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.8591 - acc: 0.3967 - val_loss: 1.7983 - val_acc: 0.4013\n","Epoch 4/60\n","3506/3506 [==============================] - 37s 10ms/step - loss: 1.5491 - acc: 0.4683 - val_loss: 1.6596 - val_acc: 0.4207\n","Epoch 5/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.4188 - acc: 0.5071 - val_loss: 2.4226 - val_acc: 0.3377\n","Epoch 6/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.3347 - acc: 0.5322 - val_loss: 1.4098 - val_acc: 0.4991\n","Epoch 7/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.2594 - acc: 0.5579 - val_loss: 2.4984 - val_acc: 0.2076\n","Epoch 8/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.2611 - acc: 0.5602 - val_loss: 1.3556 - val_acc: 0.4957\n","Epoch 9/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.1886 - acc: 0.5830 - val_loss: 2.4521 - val_acc: 0.2670\n","Epoch 10/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.1794 - acc: 0.5981 - val_loss: 1.8383 - val_acc: 0.4007\n","Epoch 11/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.1445 - acc: 0.6112 - val_loss: 1.4128 - val_acc: 0.4929\n","Epoch 12/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.1057 - acc: 0.6226 - val_loss: 1.2538 - val_acc: 0.5590\n","Epoch 13/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.0954 - acc: 0.6232 - val_loss: 1.3463 - val_acc: 0.5180\n","Epoch 14/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.0715 - acc: 0.6335 - val_loss: 1.3606 - val_acc: 0.4524\n","Epoch 15/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.0585 - acc: 0.6383 - val_loss: 1.4796 - val_acc: 0.3776\n","Epoch 16/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.0519 - acc: 0.6423 - val_loss: 1.2708 - val_acc: 0.4504\n","Epoch 17/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.0449 - acc: 0.6443 - val_loss: 1.2149 - val_acc: 0.5913\n","Epoch 18/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.0282 - acc: 0.6517 - val_loss: 1.1381 - val_acc: 0.5944\n","Epoch 19/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.0167 - acc: 0.6480 - val_loss: 1.2405 - val_acc: 0.5499\n","Epoch 20/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 1.0013 - acc: 0.6557 - val_loss: 1.0826 - val_acc: 0.5990\n","Epoch 21/60\n","3506/3506 [==============================] - 37s 10ms/step - loss: 1.0013 - acc: 0.6560 - val_loss: 1.1284 - val_acc: 0.5958\n","Epoch 22/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.9863 - acc: 0.6686 - val_loss: 1.1505 - val_acc: 0.5742\n","Epoch 23/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.9821 - acc: 0.6683 - val_loss: 1.2218 - val_acc: 0.5071\n","Epoch 24/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.9780 - acc: 0.6700 - val_loss: 1.0527 - val_acc: 0.6363\n","Epoch 25/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.9614 - acc: 0.6803 - val_loss: 1.1595 - val_acc: 0.5824\n","Epoch 26/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.9622 - acc: 0.6686 - val_loss: 1.2292 - val_acc: 0.5493\n","Epoch 27/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.9493 - acc: 0.6794 - val_loss: 0.9721 - val_acc: 0.6572\n","Epoch 28/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.9442 - acc: 0.6766 - val_loss: 1.1220 - val_acc: 0.6246\n","Epoch 29/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.9322 - acc: 0.6860 - val_loss: 1.1433 - val_acc: 0.6135\n","Epoch 30/60\n","3506/3506 [==============================] - 36s 10ms/step - loss: 0.9273 - acc: 0.6854 - val_loss: 1.0717 - val_acc: 0.6272\n","Epoch 31/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.9314 - acc: 0.6877 - val_loss: 1.1183 - val_acc: 0.5993\n","Epoch 32/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.9151 - acc: 0.6954 - val_loss: 1.0300 - val_acc: 0.6312\n","Epoch 33/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.9097 - acc: 0.6945 - val_loss: 1.0642 - val_acc: 0.5876\n","Epoch 34/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.9055 - acc: 0.6880 - val_loss: 0.9809 - val_acc: 0.6597\n","Epoch 35/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8998 - acc: 0.6951 - val_loss: 1.3663 - val_acc: 0.5071\n","Epoch 36/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.9072 - acc: 0.6914 - val_loss: 1.1038 - val_acc: 0.5987\n","Epoch 37/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8896 - acc: 0.7002 - val_loss: 0.9451 - val_acc: 0.6649\n","Epoch 38/60\n","3506/3506 [==============================] - 37s 10ms/step - loss: 0.8807 - acc: 0.6974 - val_loss: 1.0736 - val_acc: 0.6007\n","Epoch 39/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8916 - acc: 0.6925 - val_loss: 0.9115 - val_acc: 0.6843\n","Epoch 40/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8666 - acc: 0.7065 - val_loss: 1.0522 - val_acc: 0.6115\n","Epoch 41/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8728 - acc: 0.7062 - val_loss: 1.1849 - val_acc: 0.5251\n","Epoch 42/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8729 - acc: 0.7048 - val_loss: 1.1183 - val_acc: 0.5764\n","Epoch 43/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8592 - acc: 0.7054 - val_loss: 0.9143 - val_acc: 0.6865\n","Epoch 44/60\n","3506/3506 [==============================] - 40s 11ms/step - loss: 0.8477 - acc: 0.7094 - val_loss: 1.0401 - val_acc: 0.6204\n","Epoch 45/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8515 - acc: 0.7119 - val_loss: 1.5709 - val_acc: 0.4746\n","Epoch 46/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8510 - acc: 0.7065 - val_loss: 0.8958 - val_acc: 0.6891\n","Epoch 47/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8413 - acc: 0.7068 - val_loss: 0.8927 - val_acc: 0.6940\n","Epoch 48/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8386 - acc: 0.7119 - val_loss: 0.9266 - val_acc: 0.6669\n","Epoch 49/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8241 - acc: 0.7179 - val_loss: 1.0747 - val_acc: 0.5759\n","Epoch 50/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8351 - acc: 0.7171 - val_loss: 0.9202 - val_acc: 0.6426\n","Epoch 51/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8276 - acc: 0.7156 - val_loss: 0.9732 - val_acc: 0.6506\n","Epoch 52/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8305 - acc: 0.7065 - val_loss: 0.8986 - val_acc: 0.6720\n","Epoch 53/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8175 - acc: 0.7213 - val_loss: 0.9378 - val_acc: 0.6520\n","Epoch 54/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8160 - acc: 0.7199 - val_loss: 1.1144 - val_acc: 0.5750\n","Epoch 55/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8254 - acc: 0.7122 - val_loss: 1.0039 - val_acc: 0.6440\n","Epoch 56/60\n","3506/3506 [==============================] - 38s 11ms/step - loss: 0.8062 - acc: 0.7259 - val_loss: 1.0778 - val_acc: 0.5961\n","Epoch 57/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8083 - acc: 0.7210 - val_loss: 0.8789 - val_acc: 0.7065\n","Epoch 58/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.7942 - acc: 0.7282 - val_loss: 0.9404 - val_acc: 0.6529\n","Epoch 59/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.7893 - acc: 0.7353 - val_loss: 1.2451 - val_acc: 0.5505\n","Epoch 60/60\n","3506/3506 [==============================] - 35s 10ms/step - loss: 0.8025 - acc: 0.7179 - val_loss: 0.8676 - val_acc: 0.6860\n","Accuracy[0.6767] Recall[0.5175] F1[0.5126] at fold[7]\n","______________________________________________________\n","Start Training\n","Train on 3501 samples, validate on 3501 samples\n","Epoch 1/60\n","3501/3501 [==============================] - 36s 10ms/step - loss: 2.3919 - acc: 0.2411 - val_loss: 2.6349 - val_acc: 0.1245\n","Epoch 2/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.9908 - acc: 0.3887 - val_loss: 2.3990 - val_acc: 0.2622\n","Epoch 3/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.7228 - acc: 0.4484 - val_loss: 1.8450 - val_acc: 0.3319\n","Epoch 4/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.5591 - acc: 0.4684 - val_loss: 1.6573 - val_acc: 0.4230\n","Epoch 5/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.4340 - acc: 0.5076 - val_loss: 2.7538 - val_acc: 0.3705\n","Epoch 6/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.3941 - acc: 0.5196 - val_loss: 1.3650 - val_acc: 0.5496\n","Epoch 7/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.2994 - acc: 0.5453 - val_loss: 1.4033 - val_acc: 0.5164\n","Epoch 8/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.2784 - acc: 0.5536 - val_loss: 1.8274 - val_acc: 0.3685\n","Epoch 9/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.2539 - acc: 0.5598 - val_loss: 1.4618 - val_acc: 0.3633\n","Epoch 10/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.2199 - acc: 0.5698 - val_loss: 1.4448 - val_acc: 0.5293\n","Epoch 11/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.2025 - acc: 0.5918 - val_loss: 1.6247 - val_acc: 0.4607\n","Epoch 12/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.1887 - acc: 0.5901 - val_loss: 1.3214 - val_acc: 0.5613\n","Epoch 13/60\n","3501/3501 [==============================] - 37s 10ms/step - loss: 1.1645 - acc: 0.5921 - val_loss: 1.3656 - val_acc: 0.5027\n","Epoch 14/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.1580 - acc: 0.6018 - val_loss: 1.1954 - val_acc: 0.5741\n","Epoch 15/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.1404 - acc: 0.6064 - val_loss: 1.1324 - val_acc: 0.6033\n","Epoch 16/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.1323 - acc: 0.6041 - val_loss: 1.1716 - val_acc: 0.6207\n","Epoch 17/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.1248 - acc: 0.6130 - val_loss: 1.3895 - val_acc: 0.4287\n","Epoch 18/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.1234 - acc: 0.6121 - val_loss: 1.0950 - val_acc: 0.6164\n","Epoch 19/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.1169 - acc: 0.6121 - val_loss: 1.8327 - val_acc: 0.5301\n","Epoch 20/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.1251 - acc: 0.6224 - val_loss: 1.6820 - val_acc: 0.4113\n","Epoch 21/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.1156 - acc: 0.6144 - val_loss: 1.2859 - val_acc: 0.5327\n","Epoch 22/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0848 - acc: 0.6281 - val_loss: 1.2575 - val_acc: 0.5407\n","Epoch 23/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0781 - acc: 0.6267 - val_loss: 1.1439 - val_acc: 0.5827\n","Epoch 24/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0677 - acc: 0.6270 - val_loss: 1.1162 - val_acc: 0.6310\n","Epoch 25/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0701 - acc: 0.6290 - val_loss: 1.0589 - val_acc: 0.6250\n","Epoch 26/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0568 - acc: 0.6327 - val_loss: 1.1541 - val_acc: 0.6047\n","Epoch 27/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0619 - acc: 0.6278 - val_loss: 1.4609 - val_acc: 0.5216\n","Epoch 28/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0642 - acc: 0.6255 - val_loss: 1.4477 - val_acc: 0.5618\n","Epoch 29/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0558 - acc: 0.6324 - val_loss: 1.0332 - val_acc: 0.6324\n","Epoch 30/60\n","3501/3501 [==============================] - 37s 11ms/step - loss: 1.0375 - acc: 0.6401 - val_loss: 1.9651 - val_acc: 0.3859\n","Epoch 31/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0478 - acc: 0.6450 - val_loss: 1.1784 - val_acc: 0.5601\n","Epoch 32/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0284 - acc: 0.6395 - val_loss: 1.1121 - val_acc: 0.6090\n","Epoch 33/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0181 - acc: 0.6450 - val_loss: 1.1741 - val_acc: 0.5838\n","Epoch 34/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0140 - acc: 0.6518 - val_loss: 1.0711 - val_acc: 0.6141\n","Epoch 35/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0053 - acc: 0.6521 - val_loss: 1.0616 - val_acc: 0.6538\n","Epoch 36/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0031 - acc: 0.6524 - val_loss: 1.0990 - val_acc: 0.6261\n","Epoch 37/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0001 - acc: 0.6552 - val_loss: 1.1818 - val_acc: 0.5650\n","Epoch 38/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0001 - acc: 0.6507 - val_loss: 1.2474 - val_acc: 0.5650\n","Epoch 39/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9997 - acc: 0.6518 - val_loss: 1.7927 - val_acc: 0.4722\n","Epoch 40/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 1.0170 - acc: 0.6555 - val_loss: 1.0356 - val_acc: 0.6358\n","Epoch 41/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9812 - acc: 0.6624 - val_loss: 1.0230 - val_acc: 0.6367\n","Epoch 42/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9729 - acc: 0.6678 - val_loss: 1.1583 - val_acc: 0.5853\n","Epoch 43/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9790 - acc: 0.6581 - val_loss: 1.1996 - val_acc: 0.5724\n","Epoch 44/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9753 - acc: 0.6592 - val_loss: 1.2492 - val_acc: 0.5864\n","Epoch 45/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9713 - acc: 0.6627 - val_loss: 1.0237 - val_acc: 0.6630\n","Epoch 46/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9610 - acc: 0.6721 - val_loss: 0.9653 - val_acc: 0.6564\n","Epoch 47/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9580 - acc: 0.6738 - val_loss: 1.4460 - val_acc: 0.4519\n","Epoch 48/60\n","3501/3501 [==============================] - 39s 11ms/step - loss: 0.9680 - acc: 0.6638 - val_loss: 1.0636 - val_acc: 0.6201\n","Epoch 49/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9575 - acc: 0.6710 - val_loss: 1.3617 - val_acc: 0.5510\n","Epoch 50/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9595 - acc: 0.6667 - val_loss: 1.0648 - val_acc: 0.5998\n","Epoch 51/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9525 - acc: 0.6747 - val_loss: 1.0986 - val_acc: 0.5953\n","Epoch 52/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9462 - acc: 0.6704 - val_loss: 0.9358 - val_acc: 0.6718\n","Epoch 53/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9320 - acc: 0.6809 - val_loss: 1.4727 - val_acc: 0.5110\n","Epoch 54/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9501 - acc: 0.6741 - val_loss: 1.0997 - val_acc: 0.6161\n","Epoch 55/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9300 - acc: 0.6812 - val_loss: 0.9976 - val_acc: 0.6644\n","Epoch 56/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9246 - acc: 0.6895 - val_loss: 1.0108 - val_acc: 0.6381\n","Epoch 57/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9273 - acc: 0.6804 - val_loss: 1.0819 - val_acc: 0.6284\n","Epoch 58/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9278 - acc: 0.6835 - val_loss: 1.6479 - val_acc: 0.4979\n","Epoch 59/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9350 - acc: 0.6818 - val_loss: 0.9491 - val_acc: 0.6664\n","Epoch 60/60\n","3501/3501 [==============================] - 35s 10ms/step - loss: 0.9118 - acc: 0.6889 - val_loss: 1.0052 - val_acc: 0.6153\n","Accuracy[0.5919] Recall[0.4906] F1[0.4631] at fold[8]\n","______________________________________________________\n","Start Training\n","Train on 3503 samples, validate on 3503 samples\n","Epoch 1/60\n","3503/3503 [==============================] - 36s 10ms/step - loss: 2.3243 - acc: 0.2267 - val_loss: 2.2722 - val_acc: 0.3391\n","Epoch 2/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 2.0434 - acc: 0.3603 - val_loss: 2.2289 - val_acc: 0.1950\n","Epoch 3/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.7938 - acc: 0.3954 - val_loss: 1.8082 - val_acc: 0.3123\n","Epoch 4/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.6133 - acc: 0.4408 - val_loss: 1.6797 - val_acc: 0.4028\n","Epoch 5/60\n","3503/3503 [==============================] - 36s 10ms/step - loss: 1.5026 - acc: 0.4713 - val_loss: 1.4507 - val_acc: 0.4887\n","Epoch 6/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.4109 - acc: 0.5050 - val_loss: 2.9867 - val_acc: 0.3703\n","Epoch 7/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.3777 - acc: 0.5204 - val_loss: 1.6594 - val_acc: 0.4348\n","Epoch 8/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.2935 - acc: 0.5413 - val_loss: 1.4134 - val_acc: 0.4907\n","Epoch 9/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.2612 - acc: 0.5572 - val_loss: 2.4798 - val_acc: 0.1961\n","Epoch 10/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.2647 - acc: 0.5624 - val_loss: 1.3839 - val_acc: 0.4879\n","Epoch 11/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.2155 - acc: 0.5812 - val_loss: 1.3345 - val_acc: 0.4904\n","Epoch 12/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.1888 - acc: 0.5923 - val_loss: 1.2709 - val_acc: 0.5350\n","Epoch 13/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.1745 - acc: 0.5898 - val_loss: 1.2470 - val_acc: 0.5792\n","Epoch 14/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.1549 - acc: 0.6069 - val_loss: 1.3624 - val_acc: 0.4896\n","Epoch 15/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.1482 - acc: 0.6001 - val_loss: 1.1590 - val_acc: 0.5701\n","Epoch 16/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.1381 - acc: 0.6035 - val_loss: 1.6017 - val_acc: 0.4125\n","Epoch 17/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.1289 - acc: 0.6043 - val_loss: 1.2432 - val_acc: 0.5432\n","Epoch 18/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.1103 - acc: 0.6178 - val_loss: 1.8558 - val_acc: 0.4333\n","Epoch 19/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.1098 - acc: 0.6212 - val_loss: 1.1816 - val_acc: 0.5530\n","Epoch 20/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.0860 - acc: 0.6303 - val_loss: 1.2136 - val_acc: 0.5467\n","Epoch 21/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.0766 - acc: 0.6409 - val_loss: 1.2537 - val_acc: 0.4556\n","Epoch 22/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.0696 - acc: 0.6297 - val_loss: 1.1989 - val_acc: 0.5327\n","Epoch 23/60\n","3503/3503 [==============================] - 36s 10ms/step - loss: 1.0633 - acc: 0.6375 - val_loss: 1.2299 - val_acc: 0.5561\n","Epoch 24/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.0539 - acc: 0.6403 - val_loss: 1.3103 - val_acc: 0.4804\n","Epoch 25/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.0533 - acc: 0.6452 - val_loss: 1.1297 - val_acc: 0.5912\n","Epoch 26/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.0338 - acc: 0.6514 - val_loss: 1.1780 - val_acc: 0.5815\n","Epoch 27/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.0252 - acc: 0.6494 - val_loss: 1.0971 - val_acc: 0.6263\n","Epoch 28/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.0178 - acc: 0.6503 - val_loss: 1.0999 - val_acc: 0.5806\n","Epoch 29/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.0184 - acc: 0.6514 - val_loss: 1.5540 - val_acc: 0.4194\n","Epoch 30/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.0201 - acc: 0.6611 - val_loss: 1.0933 - val_acc: 0.5929\n","Epoch 31/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.0026 - acc: 0.6574 - val_loss: 1.0465 - val_acc: 0.6195\n","Epoch 32/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 1.0019 - acc: 0.6591 - val_loss: 1.1599 - val_acc: 0.5678\n","Epoch 33/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9958 - acc: 0.6626 - val_loss: 1.4471 - val_acc: 0.4371\n","Epoch 34/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9934 - acc: 0.6594 - val_loss: 1.1076 - val_acc: 0.5935\n","Epoch 35/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9765 - acc: 0.6766 - val_loss: 1.1486 - val_acc: 0.5198\n","Epoch 36/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9712 - acc: 0.6700 - val_loss: 1.1307 - val_acc: 0.5729\n","Epoch 37/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9731 - acc: 0.6697 - val_loss: 1.0784 - val_acc: 0.6295\n","Epoch 38/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9646 - acc: 0.6634 - val_loss: 1.1238 - val_acc: 0.6112\n","Epoch 39/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9657 - acc: 0.6700 - val_loss: 1.1738 - val_acc: 0.5698\n","Epoch 40/60\n","3503/3503 [==============================] - 37s 10ms/step - loss: 0.9560 - acc: 0.6737 - val_loss: 1.1716 - val_acc: 0.6120\n","Epoch 41/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9560 - acc: 0.6723 - val_loss: 1.0499 - val_acc: 0.6100\n","Epoch 42/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9484 - acc: 0.6754 - val_loss: 1.2818 - val_acc: 0.5059\n","Epoch 43/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9410 - acc: 0.6803 - val_loss: 1.1100 - val_acc: 0.5889\n","Epoch 44/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9367 - acc: 0.6737 - val_loss: 1.0123 - val_acc: 0.6434\n","Epoch 45/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9269 - acc: 0.6806 - val_loss: 1.2393 - val_acc: 0.5315\n","Epoch 46/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9260 - acc: 0.6780 - val_loss: 0.9875 - val_acc: 0.6554\n","Epoch 47/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9180 - acc: 0.6854 - val_loss: 1.1318 - val_acc: 0.5181\n","Epoch 48/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9144 - acc: 0.6911 - val_loss: 1.4075 - val_acc: 0.4722\n","Epoch 49/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9166 - acc: 0.6868 - val_loss: 1.2873 - val_acc: 0.5047\n","Epoch 50/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.9027 - acc: 0.6871 - val_loss: 0.9348 - val_acc: 0.6520\n","Epoch 51/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.8932 - acc: 0.6945 - val_loss: 1.3155 - val_acc: 0.4862\n","Epoch 52/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.8943 - acc: 0.6868 - val_loss: 1.2146 - val_acc: 0.5393\n","Epoch 53/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.8945 - acc: 0.6914 - val_loss: 1.1213 - val_acc: 0.6103\n","Epoch 54/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.8894 - acc: 0.6928 - val_loss: 1.3025 - val_acc: 0.4690\n","Epoch 55/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.8893 - acc: 0.6908 - val_loss: 1.0502 - val_acc: 0.5755\n","Epoch 56/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.8743 - acc: 0.6925 - val_loss: 1.0588 - val_acc: 0.6155\n","Epoch 57/60\n","3503/3503 [==============================] - 37s 10ms/step - loss: 0.8815 - acc: 0.6957 - val_loss: 1.0310 - val_acc: 0.6295\n","Epoch 58/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.8672 - acc: 0.6983 - val_loss: 1.0384 - val_acc: 0.6406\n","Epoch 59/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.8685 - acc: 0.7011 - val_loss: 1.8235 - val_acc: 0.4510\n","Epoch 60/60\n","3503/3503 [==============================] - 35s 10ms/step - loss: 0.8770 - acc: 0.6997 - val_loss: 1.1058 - val_acc: 0.5258\n","Accuracy[0.5516] Recall[0.4993] F1[0.5048] at fold[9]\n","______________________________________________________\n","Mean Accuracy[0.6468] IC [0.6080, 0.6856]\n","Mean Recall[0.5622] IC [0.5101, 0.6142]\n","Mean F1[0.5522] IC [0.5000, 0.6045]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3WCA-5Zd7weR","colab_type":"code","outputId":"8df14ce3-5b48-4fbb-feaa-26ebd189ee70","executionInfo":{"status":"error","timestamp":1585999651675,"user_tz":-120,"elapsed":12085,"user":{"displayName":"Rana mostafa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpLWLhJYcXKOOp7sprSKwnxN-x9hYM61yh__9kww=s64","userId":"07598775866819373078"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["RunWHARF('data/FNOW/WHARF.npz')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["12\n","(2146, 1, 250, 29)\n","(2146, 12)\n","(1926, 1, 250, 29)\n","(220, 1, 250, 29)\n","[11, 19, 27]\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","Start Training\n","Train on 1926 samples, validate on 1926 samples\n","Epoch 1/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 2.4667 - acc: 0.1490 - val_loss: 2.2209 - val_acc: 0.2799\n","Epoch 2/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 2.1380 - acc: 0.3489 - val_loss: 2.0353 - val_acc: 0.3884\n","Epoch 3/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.9735 - acc: 0.3645 - val_loss: 1.8350 - val_acc: 0.4117\n","Epoch 4/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.8422 - acc: 0.3951 - val_loss: 2.0836 - val_acc: 0.3193\n","Epoch 5/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.7300 - acc: 0.4237 - val_loss: 1.7249 - val_acc: 0.3775\n","Epoch 6/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.6229 - acc: 0.4341 - val_loss: 1.6928 - val_acc: 0.3531\n","Epoch 7/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.4987 - acc: 0.4673 - val_loss: 1.4280 - val_acc: 0.5130\n","Epoch 8/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.4079 - acc: 0.5078 - val_loss: 1.5966 - val_acc: 0.3816\n","Epoch 9/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.3861 - acc: 0.5161 - val_loss: 1.4758 - val_acc: 0.4948\n","Epoch 10/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.3303 - acc: 0.5327 - val_loss: 1.4004 - val_acc: 0.4943\n","Epoch 11/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.2814 - acc: 0.5478 - val_loss: 1.3669 - val_acc: 0.4792\n","Epoch 12/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.2597 - acc: 0.5535 - val_loss: 1.3429 - val_acc: 0.4938\n","Epoch 13/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.2358 - acc: 0.5602 - val_loss: 1.3158 - val_acc: 0.5265\n","Epoch 14/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.2101 - acc: 0.5862 - val_loss: 1.2022 - val_acc: 0.5836\n","Epoch 15/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.2138 - acc: 0.5701 - val_loss: 1.2811 - val_acc: 0.5109\n","Epoch 16/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.1680 - acc: 0.5929 - val_loss: 1.1759 - val_acc: 0.5831\n","Epoch 17/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.1496 - acc: 0.5997 - val_loss: 1.1428 - val_acc: 0.6194\n","Epoch 18/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.1249 - acc: 0.6205 - val_loss: 1.1910 - val_acc: 0.5794\n","Epoch 19/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.1177 - acc: 0.6038 - val_loss: 1.3006 - val_acc: 0.5218\n","Epoch 20/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.0999 - acc: 0.6205 - val_loss: 1.2322 - val_acc: 0.5301\n","Epoch 21/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.1081 - acc: 0.6168 - val_loss: 1.1461 - val_acc: 0.5794\n","Epoch 22/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.0853 - acc: 0.6225 - val_loss: 1.1047 - val_acc: 0.5914\n","Epoch 23/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.0493 - acc: 0.6433 - val_loss: 1.0653 - val_acc: 0.6173\n","Epoch 24/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.0586 - acc: 0.6308 - val_loss: 1.0417 - val_acc: 0.6272\n","Epoch 25/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.0373 - acc: 0.6402 - val_loss: 1.0144 - val_acc: 0.6464\n","Epoch 26/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.0262 - acc: 0.6459 - val_loss: 1.1270 - val_acc: 0.5862\n","Epoch 27/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.0254 - acc: 0.6423 - val_loss: 1.1716 - val_acc: 0.5763\n","Epoch 28/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 1.0081 - acc: 0.6443 - val_loss: 1.0218 - val_acc: 0.6220\n","Epoch 29/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.9916 - acc: 0.6630 - val_loss: 1.0137 - val_acc: 0.6371\n","Epoch 30/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.9864 - acc: 0.6542 - val_loss: 0.9931 - val_acc: 0.6516\n","Epoch 31/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.9683 - acc: 0.6620 - val_loss: 1.1134 - val_acc: 0.5727\n","Epoch 32/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.9811 - acc: 0.6641 - val_loss: 1.0081 - val_acc: 0.6423\n","Epoch 33/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.9667 - acc: 0.6641 - val_loss: 1.1869 - val_acc: 0.6002\n","Epoch 34/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.9739 - acc: 0.6630 - val_loss: 1.1368 - val_acc: 0.5810\n","Epoch 35/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.9669 - acc: 0.6641 - val_loss: 0.9965 - val_acc: 0.6391\n","Epoch 36/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.9466 - acc: 0.6687 - val_loss: 1.0133 - val_acc: 0.6552\n","Epoch 37/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.9418 - acc: 0.6698 - val_loss: 1.2480 - val_acc: 0.5488\n","Epoch 38/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.9641 - acc: 0.6604 - val_loss: 0.9316 - val_acc: 0.6786\n","Epoch 39/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.9245 - acc: 0.6745 - val_loss: 0.9664 - val_acc: 0.6521\n","Epoch 40/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.9249 - acc: 0.6765 - val_loss: 0.9612 - val_acc: 0.6516\n","Epoch 41/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.9087 - acc: 0.6838 - val_loss: 0.9724 - val_acc: 0.6449\n","Epoch 42/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.9069 - acc: 0.6874 - val_loss: 0.8995 - val_acc: 0.6807\n","Epoch 43/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.8997 - acc: 0.6895 - val_loss: 0.9472 - val_acc: 0.6765\n","Epoch 44/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.9071 - acc: 0.6880 - val_loss: 0.9891 - val_acc: 0.6449\n","Epoch 45/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.9025 - acc: 0.6869 - val_loss: 0.9673 - val_acc: 0.6594\n","Epoch 46/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.8885 - acc: 0.6952 - val_loss: 0.9258 - val_acc: 0.6521\n","Epoch 47/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.8859 - acc: 0.6859 - val_loss: 0.9242 - val_acc: 0.6620\n","Epoch 48/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.8728 - acc: 0.6916 - val_loss: 0.8756 - val_acc: 0.6947\n","Epoch 49/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.8734 - acc: 0.6973 - val_loss: 0.8531 - val_acc: 0.7087\n","Epoch 50/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.8553 - acc: 0.7051 - val_loss: 0.8632 - val_acc: 0.6822\n","Epoch 51/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.8492 - acc: 0.7061 - val_loss: 0.8877 - val_acc: 0.6765\n","Epoch 52/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.8732 - acc: 0.6885 - val_loss: 0.9947 - val_acc: 0.6210\n","Epoch 53/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.8633 - acc: 0.7061 - val_loss: 0.8836 - val_acc: 0.6843\n","Epoch 54/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.8427 - acc: 0.7150 - val_loss: 0.8640 - val_acc: 0.6812\n","Epoch 55/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.8385 - acc: 0.7015 - val_loss: 0.9435 - val_acc: 0.6719\n","Epoch 56/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.8370 - acc: 0.7150 - val_loss: 0.8818 - val_acc: 0.6931\n","Epoch 57/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.8429 - acc: 0.7118 - val_loss: 0.8925 - val_acc: 0.6563\n","Epoch 58/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.8394 - acc: 0.7082 - val_loss: 0.7940 - val_acc: 0.7227\n","Epoch 59/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.8271 - acc: 0.7129 - val_loss: 0.8284 - val_acc: 0.7175\n","Epoch 60/60\n","1926/1926 [==============================] - 16s 8ms/step - loss: 0.8157 - acc: 0.7144 - val_loss: 0.8345 - val_acc: 0.6926\n","Accuracy[0.6182] Recall[0.5524] F1[0.5508] at fold[0]\n","______________________________________________________\n","Start Training\n","Train on 1927 samples, validate on 1927 samples\n","Epoch 1/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 2.9019 - acc: 0.1401 - val_loss: 2.3911 - val_acc: 0.1484\n","Epoch 2/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 2.2693 - acc: 0.2460 - val_loss: 2.2320 - val_acc: 0.2994\n","Epoch 3/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 2.1529 - acc: 0.3342 - val_loss: 2.2369 - val_acc: 0.1889\n","Epoch 4/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 2.0253 - acc: 0.3700 - val_loss: 1.9242 - val_acc: 0.3856\n","Epoch 5/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.8506 - acc: 0.4100 - val_loss: 2.2184 - val_acc: 0.2621\n","Epoch 6/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.7445 - acc: 0.4224 - val_loss: 1.6024 - val_acc: 0.4494\n","Epoch 7/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.5736 - acc: 0.4603 - val_loss: 1.6933 - val_acc: 0.4338\n","Epoch 8/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.5285 - acc: 0.4676 - val_loss: 1.5031 - val_acc: 0.4561\n","Epoch 9/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.4144 - acc: 0.4862 - val_loss: 1.4259 - val_acc: 0.4722\n","Epoch 10/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.3679 - acc: 0.4961 - val_loss: 1.3714 - val_acc: 0.4816\n","Epoch 11/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.3059 - acc: 0.5288 - val_loss: 1.4350 - val_acc: 0.4645\n","Epoch 12/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.2752 - acc: 0.5444 - val_loss: 1.4066 - val_acc: 0.4629\n","Epoch 13/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.3230 - acc: 0.5210 - val_loss: 1.2492 - val_acc: 0.5620\n","Epoch 14/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.2265 - acc: 0.5589 - val_loss: 1.3382 - val_acc: 0.5117\n","Epoch 15/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.2136 - acc: 0.5625 - val_loss: 1.4125 - val_acc: 0.4894\n","Epoch 16/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.2441 - acc: 0.5542 - val_loss: 1.1779 - val_acc: 0.5828\n","Epoch 17/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.1858 - acc: 0.5765 - val_loss: 1.1990 - val_acc: 0.5547\n","Epoch 18/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.1789 - acc: 0.5719 - val_loss: 1.2551 - val_acc: 0.5241\n","Epoch 19/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.1531 - acc: 0.5843 - val_loss: 1.1601 - val_acc: 0.5833\n","Epoch 20/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.1501 - acc: 0.5776 - val_loss: 1.1358 - val_acc: 0.6066\n","Epoch 21/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.1170 - acc: 0.6009 - val_loss: 1.3169 - val_acc: 0.4152\n","Epoch 22/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.1259 - acc: 0.5885 - val_loss: 1.3081 - val_acc: 0.5439\n","Epoch 23/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.1191 - acc: 0.6025 - val_loss: 1.2438 - val_acc: 0.5008\n","Epoch 24/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0969 - acc: 0.6061 - val_loss: 1.1371 - val_acc: 0.6087\n","Epoch 25/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0926 - acc: 0.5989 - val_loss: 1.1266 - val_acc: 0.5755\n","Epoch 26/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0688 - acc: 0.6072 - val_loss: 1.1599 - val_acc: 0.5760\n","Epoch 27/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0729 - acc: 0.6118 - val_loss: 1.1700 - val_acc: 0.5885\n","Epoch 28/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0694 - acc: 0.6129 - val_loss: 1.3910 - val_acc: 0.4120\n","Epoch 29/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0750 - acc: 0.5952 - val_loss: 1.2766 - val_acc: 0.5122\n","Epoch 30/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0391 - acc: 0.6305 - val_loss: 1.0117 - val_acc: 0.6492\n","Epoch 31/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0374 - acc: 0.6212 - val_loss: 1.1166 - val_acc: 0.5978\n","Epoch 32/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0148 - acc: 0.6414 - val_loss: 1.0409 - val_acc: 0.6513\n","Epoch 33/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0258 - acc: 0.6471 - val_loss: 0.9872 - val_acc: 0.6471\n","Epoch 34/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9992 - acc: 0.6393 - val_loss: 1.0781 - val_acc: 0.5745\n","Epoch 35/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0077 - acc: 0.6414 - val_loss: 1.2425 - val_acc: 0.5573\n","Epoch 36/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0287 - acc: 0.6310 - val_loss: 1.0168 - val_acc: 0.6321\n","Epoch 37/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9851 - acc: 0.6533 - val_loss: 1.1627 - val_acc: 0.5485\n","Epoch 38/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9777 - acc: 0.6508 - val_loss: 1.1167 - val_acc: 0.5682\n","Epoch 39/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9900 - acc: 0.6518 - val_loss: 0.9745 - val_acc: 0.6642\n","Epoch 40/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9622 - acc: 0.6668 - val_loss: 0.9921 - val_acc: 0.6393\n","Epoch 41/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9585 - acc: 0.6679 - val_loss: 1.0798 - val_acc: 0.5667\n","Epoch 42/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9687 - acc: 0.6482 - val_loss: 0.9842 - val_acc: 0.6347\n","Epoch 43/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9729 - acc: 0.6559 - val_loss: 1.0093 - val_acc: 0.6347\n","Epoch 44/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9293 - acc: 0.6694 - val_loss: 1.1187 - val_acc: 0.5475\n","Epoch 45/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9411 - acc: 0.6591 - val_loss: 1.0262 - val_acc: 0.6212\n","Epoch 46/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9586 - acc: 0.6518 - val_loss: 1.0750 - val_acc: 0.5926\n","Epoch 47/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9255 - acc: 0.6767 - val_loss: 1.0187 - val_acc: 0.6471\n","Epoch 48/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9365 - acc: 0.6523 - val_loss: 1.1147 - val_acc: 0.6051\n","Epoch 49/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9277 - acc: 0.6746 - val_loss: 1.0209 - val_acc: 0.6020\n","Epoch 50/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9123 - acc: 0.6772 - val_loss: 0.9372 - val_acc: 0.6824\n","Epoch 51/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9163 - acc: 0.6720 - val_loss: 0.9438 - val_acc: 0.6772\n","Epoch 52/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9212 - acc: 0.6658 - val_loss: 0.9051 - val_acc: 0.6668\n","Epoch 53/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9020 - acc: 0.6757 - val_loss: 0.9159 - val_acc: 0.6881\n","Epoch 54/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8835 - acc: 0.6912 - val_loss: 0.8726 - val_acc: 0.6803\n","Epoch 55/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8728 - acc: 0.6881 - val_loss: 1.0666 - val_acc: 0.5989\n","Epoch 56/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8860 - acc: 0.6767 - val_loss: 0.9271 - val_acc: 0.6668\n","Epoch 57/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8622 - acc: 0.6871 - val_loss: 0.8874 - val_acc: 0.6855\n","Epoch 58/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8677 - acc: 0.6912 - val_loss: 0.9219 - val_acc: 0.6414\n","Epoch 59/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8914 - acc: 0.6824 - val_loss: 0.8492 - val_acc: 0.6902\n","Epoch 60/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8583 - acc: 0.7016 - val_loss: 0.8842 - val_acc: 0.6689\n","Accuracy[0.6119] Recall[0.5655] F1[0.6055] at fold[1]\n","______________________________________________________\n","Start Training\n","Train on 1927 samples, validate on 1927 samples\n","Epoch 1/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 2.4219 - acc: 0.1982 - val_loss: 2.3272 - val_acc: 0.1282\n","Epoch 2/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 2.2580 - acc: 0.2704 - val_loss: 2.2479 - val_acc: 0.2346\n","Epoch 3/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 2.1541 - acc: 0.3394 - val_loss: 2.0435 - val_acc: 0.4110\n","Epoch 4/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 2.0175 - acc: 0.3576 - val_loss: 2.0521 - val_acc: 0.2600\n","Epoch 5/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.8663 - acc: 0.4115 - val_loss: 1.8286 - val_acc: 0.2927\n","Epoch 6/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.7308 - acc: 0.4297 - val_loss: 1.8310 - val_acc: 0.3358\n","Epoch 7/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.6162 - acc: 0.4515 - val_loss: 1.5363 - val_acc: 0.4790\n","Epoch 8/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.5398 - acc: 0.4598 - val_loss: 1.4750 - val_acc: 0.4670\n","Epoch 9/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.4702 - acc: 0.4831 - val_loss: 1.4700 - val_acc: 0.4390\n","Epoch 10/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.4243 - acc: 0.4940 - val_loss: 1.4825 - val_acc: 0.4862\n","Epoch 11/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.3970 - acc: 0.5106 - val_loss: 1.5398 - val_acc: 0.4063\n","Epoch 12/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.3622 - acc: 0.5221 - val_loss: 1.4027 - val_acc: 0.4909\n","Epoch 13/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.3186 - acc: 0.5324 - val_loss: 1.2780 - val_acc: 0.5423\n","Epoch 14/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.2697 - acc: 0.5511 - val_loss: 1.3005 - val_acc: 0.5205\n","Epoch 15/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.2659 - acc: 0.5480 - val_loss: 1.3449 - val_acc: 0.4702\n","Epoch 16/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.2273 - acc: 0.5563 - val_loss: 1.2571 - val_acc: 0.5195\n","Epoch 17/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.2161 - acc: 0.5708 - val_loss: 1.2371 - val_acc: 0.5298\n","Epoch 18/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.1891 - acc: 0.5724 - val_loss: 1.4700 - val_acc: 0.4821\n","Epoch 19/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.2153 - acc: 0.5698 - val_loss: 1.1717 - val_acc: 0.5698\n","Epoch 20/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.1496 - acc: 0.5926 - val_loss: 1.2991 - val_acc: 0.5755\n","Epoch 21/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.1495 - acc: 0.5947 - val_loss: 1.1145 - val_acc: 0.6212\n","Epoch 22/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.1278 - acc: 0.6015 - val_loss: 1.1983 - val_acc: 0.5906\n","Epoch 23/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.1170 - acc: 0.6066 - val_loss: 1.1738 - val_acc: 0.5890\n","Epoch 24/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0896 - acc: 0.5947 - val_loss: 1.1969 - val_acc: 0.6051\n","Epoch 25/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0834 - acc: 0.6222 - val_loss: 1.0890 - val_acc: 0.6207\n","Epoch 26/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0649 - acc: 0.6284 - val_loss: 1.0477 - val_acc: 0.6341\n","Epoch 27/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0685 - acc: 0.6217 - val_loss: 1.0980 - val_acc: 0.5947\n","Epoch 28/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0239 - acc: 0.6461 - val_loss: 1.0989 - val_acc: 0.6191\n","Epoch 29/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0432 - acc: 0.6419 - val_loss: 1.2393 - val_acc: 0.5039\n","Epoch 30/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0301 - acc: 0.6456 - val_loss: 1.0800 - val_acc: 0.5760\n","Epoch 31/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 1.0063 - acc: 0.6476 - val_loss: 1.0053 - val_acc: 0.6497\n","Epoch 32/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9869 - acc: 0.6559 - val_loss: 1.0485 - val_acc: 0.6170\n","Epoch 33/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9937 - acc: 0.6518 - val_loss: 0.9718 - val_acc: 0.6575\n","Epoch 34/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9712 - acc: 0.6674 - val_loss: 1.3527 - val_acc: 0.4961\n","Epoch 35/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9799 - acc: 0.6663 - val_loss: 0.9628 - val_acc: 0.6720\n","Epoch 36/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9479 - acc: 0.6788 - val_loss: 1.0709 - val_acc: 0.6092\n","Epoch 37/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9728 - acc: 0.6559 - val_loss: 0.9661 - val_acc: 0.6575\n","Epoch 38/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9289 - acc: 0.6881 - val_loss: 0.9262 - val_acc: 0.7109\n","Epoch 39/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9358 - acc: 0.6809 - val_loss: 1.1192 - val_acc: 0.5989\n","Epoch 40/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9482 - acc: 0.6689 - val_loss: 0.9356 - val_acc: 0.6793\n","Epoch 41/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9080 - acc: 0.6938 - val_loss: 0.9262 - val_acc: 0.6803\n","Epoch 42/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9128 - acc: 0.6845 - val_loss: 0.9516 - val_acc: 0.6648\n","Epoch 43/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9209 - acc: 0.6840 - val_loss: 0.9333 - val_acc: 0.6684\n","Epoch 44/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.9060 - acc: 0.6814 - val_loss: 0.8712 - val_acc: 0.7250\n","Epoch 45/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8890 - acc: 0.7037 - val_loss: 1.1037 - val_acc: 0.5418\n","Epoch 46/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8926 - acc: 0.6928 - val_loss: 0.8922 - val_acc: 0.7141\n","Epoch 47/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8720 - acc: 0.7094 - val_loss: 0.9203 - val_acc: 0.6715\n","Epoch 48/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8867 - acc: 0.6928 - val_loss: 0.8946 - val_acc: 0.6850\n","Epoch 49/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8689 - acc: 0.7104 - val_loss: 1.0061 - val_acc: 0.6617\n","Epoch 50/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8681 - acc: 0.7146 - val_loss: 0.9170 - val_acc: 0.6751\n","Epoch 51/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8722 - acc: 0.6995 - val_loss: 1.0344 - val_acc: 0.6144\n","Epoch 52/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8592 - acc: 0.7047 - val_loss: 0.8686 - val_acc: 0.7104\n","Epoch 53/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8569 - acc: 0.7130 - val_loss: 0.8525 - val_acc: 0.7042\n","Epoch 54/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8553 - acc: 0.7073 - val_loss: 0.8215 - val_acc: 0.7255\n","Epoch 55/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8544 - acc: 0.7058 - val_loss: 0.8723 - val_acc: 0.6881\n","Epoch 56/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8326 - acc: 0.7234 - val_loss: 0.8502 - val_acc: 0.7089\n","Epoch 57/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8242 - acc: 0.7234 - val_loss: 0.9199 - val_acc: 0.6824\n","Epoch 58/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8311 - acc: 0.7167 - val_loss: 0.8198 - val_acc: 0.7084\n","Epoch 59/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8421 - acc: 0.7042 - val_loss: 0.8732 - val_acc: 0.7052\n","Epoch 60/60\n","1927/1927 [==============================] - 16s 8ms/step - loss: 0.8281 - acc: 0.7084 - val_loss: 0.8779 - val_acc: 0.6793\n","Accuracy[0.6210] Recall[0.5047] F1[0.5071] at fold[2]\n","______________________________________________________\n","Start Training\n","Train on 1929 samples, validate on 1929 samples\n","Epoch 1/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 2.3793 - acc: 0.1218 - val_loss: 2.3185 - val_acc: 0.2561\n","Epoch 2/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 2.2750 - acc: 0.2328 - val_loss: 2.2788 - val_acc: 0.2504\n","Epoch 3/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 2.1984 - acc: 0.2732 - val_loss: 2.1475 - val_acc: 0.2639\n","Epoch 4/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 2.1157 - acc: 0.3043 - val_loss: 2.0697 - val_acc: 0.2856\n","Epoch 5/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 2.0133 - acc: 0.3354 - val_loss: 1.8684 - val_acc: 0.3888\n","Epoch 6/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.8530 - acc: 0.3898 - val_loss: 1.7312 - val_acc: 0.3696\n","Epoch 7/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.7141 - acc: 0.4287 - val_loss: 1.6796 - val_acc: 0.3790\n","Epoch 8/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.5573 - acc: 0.4562 - val_loss: 1.6085 - val_acc: 0.3940\n","Epoch 9/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.5079 - acc: 0.4671 - val_loss: 1.5558 - val_acc: 0.4572\n","Epoch 10/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.4279 - acc: 0.4997 - val_loss: 1.6200 - val_acc: 0.4292\n","Epoch 11/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.3972 - acc: 0.5241 - val_loss: 1.3144 - val_acc: 0.5485\n","Epoch 12/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.3590 - acc: 0.5189 - val_loss: 1.3241 - val_acc: 0.5241\n","Epoch 13/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.3308 - acc: 0.5324 - val_loss: 1.3046 - val_acc: 0.5215\n","Epoch 14/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.2879 - acc: 0.5469 - val_loss: 1.3858 - val_acc: 0.4645\n","Epoch 15/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.2465 - acc: 0.5687 - val_loss: 1.4726 - val_acc: 0.4847\n","Epoch 16/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.2562 - acc: 0.5765 - val_loss: 1.1772 - val_acc: 0.6179\n","Epoch 17/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.2183 - acc: 0.5925 - val_loss: 1.2439 - val_acc: 0.5832\n","Epoch 18/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.2158 - acc: 0.5894 - val_loss: 1.2294 - val_acc: 0.5272\n","Epoch 19/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.2099 - acc: 0.5842 - val_loss: 1.4761 - val_acc: 0.4640\n","Epoch 20/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.1655 - acc: 0.6019 - val_loss: 1.1950 - val_acc: 0.5734\n","Epoch 21/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.1631 - acc: 0.5910 - val_loss: 1.2530 - val_acc: 0.5785\n","Epoch 22/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.1434 - acc: 0.6133 - val_loss: 1.1648 - val_acc: 0.5879\n","Epoch 23/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.1312 - acc: 0.6107 - val_loss: 1.2271 - val_acc: 0.5822\n","Epoch 24/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.1197 - acc: 0.6096 - val_loss: 1.1379 - val_acc: 0.6340\n","Epoch 25/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.1117 - acc: 0.6356 - val_loss: 1.0833 - val_acc: 0.6247\n","Epoch 26/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0828 - acc: 0.6356 - val_loss: 1.0721 - val_acc: 0.6413\n","Epoch 27/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0892 - acc: 0.6387 - val_loss: 1.1320 - val_acc: 0.6071\n","Epoch 28/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0835 - acc: 0.6278 - val_loss: 1.1831 - val_acc: 0.5635\n","Epoch 29/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0694 - acc: 0.6314 - val_loss: 1.1391 - val_acc: 0.5884\n","Epoch 30/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0570 - acc: 0.6464 - val_loss: 1.1321 - val_acc: 0.5951\n","Epoch 31/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0414 - acc: 0.6490 - val_loss: 1.1627 - val_acc: 0.5562\n","Epoch 32/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0490 - acc: 0.6516 - val_loss: 1.0945 - val_acc: 0.6418\n","Epoch 33/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0323 - acc: 0.6522 - val_loss: 1.0309 - val_acc: 0.6558\n","Epoch 34/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0273 - acc: 0.6563 - val_loss: 1.0435 - val_acc: 0.6464\n","Epoch 35/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0233 - acc: 0.6532 - val_loss: 1.0016 - val_acc: 0.6615\n","Epoch 36/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0018 - acc: 0.6573 - val_loss: 1.0345 - val_acc: 0.6527\n","Epoch 37/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9978 - acc: 0.6620 - val_loss: 1.0161 - val_acc: 0.6584\n","Epoch 38/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9994 - acc: 0.6646 - val_loss: 0.9995 - val_acc: 0.6553\n","Epoch 39/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0018 - acc: 0.6568 - val_loss: 1.0769 - val_acc: 0.6117\n","Epoch 40/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9984 - acc: 0.6599 - val_loss: 1.0338 - val_acc: 0.6501\n","Epoch 41/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9854 - acc: 0.6682 - val_loss: 1.0504 - val_acc: 0.6200\n","Epoch 42/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9747 - acc: 0.6693 - val_loss: 1.0009 - val_acc: 0.6516\n","Epoch 43/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9811 - acc: 0.6755 - val_loss: 1.0225 - val_acc: 0.6366\n","Epoch 44/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9628 - acc: 0.6853 - val_loss: 0.9689 - val_acc: 0.6630\n","Epoch 45/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9560 - acc: 0.6744 - val_loss: 0.9963 - val_acc: 0.6439\n","Epoch 46/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9405 - acc: 0.6765 - val_loss: 0.9949 - val_acc: 0.6739\n","Epoch 47/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9511 - acc: 0.6708 - val_loss: 0.9614 - val_acc: 0.6843\n","Epoch 48/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9416 - acc: 0.6853 - val_loss: 1.0424 - val_acc: 0.6257\n","Epoch 49/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9432 - acc: 0.6630 - val_loss: 0.9433 - val_acc: 0.6719\n","Epoch 50/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9279 - acc: 0.6776 - val_loss: 0.9663 - val_acc: 0.6459\n","Epoch 51/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9332 - acc: 0.6724 - val_loss: 0.9234 - val_acc: 0.6884\n","Epoch 52/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9167 - acc: 0.6947 - val_loss: 0.8984 - val_acc: 0.6895\n","Epoch 53/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9106 - acc: 0.6884 - val_loss: 0.9027 - val_acc: 0.6869\n","Epoch 54/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9063 - acc: 0.6952 - val_loss: 0.9280 - val_acc: 0.6890\n","Epoch 55/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9001 - acc: 0.6993 - val_loss: 0.9110 - val_acc: 0.6827\n","Epoch 56/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.8907 - acc: 0.6967 - val_loss: 0.9023 - val_acc: 0.6833\n","Epoch 57/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.8895 - acc: 0.6941 - val_loss: 0.9400 - val_acc: 0.6584\n","Epoch 58/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.8789 - acc: 0.7040 - val_loss: 0.9042 - val_acc: 0.6739\n","Epoch 59/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.8769 - acc: 0.7014 - val_loss: 0.9536 - val_acc: 0.6444\n","Epoch 60/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.8811 - acc: 0.7055 - val_loss: 0.8600 - val_acc: 0.7206\n","Accuracy[0.6221] Recall[0.5673] F1[0.5560] at fold[3]\n","______________________________________________________\n","Start Training\n","Train on 1929 samples, validate on 1929 samples\n","Epoch 1/60\n","1929/1929 [==============================] - 16s 9ms/step - loss: 2.4501 - acc: 0.1664 - val_loss: 2.3060 - val_acc: 0.2882\n","Epoch 2/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 2.2303 - acc: 0.3142 - val_loss: 2.0875 - val_acc: 0.3790\n","Epoch 3/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.9682 - acc: 0.3857 - val_loss: 1.8163 - val_acc: 0.4194\n","Epoch 4/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.7959 - acc: 0.3987 - val_loss: 1.7115 - val_acc: 0.3976\n","Epoch 5/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.6343 - acc: 0.4391 - val_loss: 1.6455 - val_acc: 0.4432\n","Epoch 6/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.5438 - acc: 0.4624 - val_loss: 1.5440 - val_acc: 0.4438\n","Epoch 7/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.4410 - acc: 0.4961 - val_loss: 1.4985 - val_acc: 0.4593\n","Epoch 8/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.3965 - acc: 0.5148 - val_loss: 1.3451 - val_acc: 0.4977\n","Epoch 9/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.3253 - acc: 0.5226 - val_loss: 1.2820 - val_acc: 0.5422\n","Epoch 10/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.2576 - acc: 0.5651 - val_loss: 1.4081 - val_acc: 0.4666\n","Epoch 11/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.2358 - acc: 0.5775 - val_loss: 1.2199 - val_acc: 0.5474\n","Epoch 12/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.2231 - acc: 0.5702 - val_loss: 1.1532 - val_acc: 0.6003\n","Epoch 13/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.1741 - acc: 0.5946 - val_loss: 1.2428 - val_acc: 0.5215\n","Epoch 14/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.1646 - acc: 0.5894 - val_loss: 1.1703 - val_acc: 0.5858\n","Epoch 15/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.1351 - acc: 0.5910 - val_loss: 1.1326 - val_acc: 0.6112\n","Epoch 16/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.1208 - acc: 0.6081 - val_loss: 1.0970 - val_acc: 0.6008\n","Epoch 17/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0968 - acc: 0.6076 - val_loss: 1.2045 - val_acc: 0.5635\n","Epoch 18/60\n","1929/1929 [==============================] - 16s 9ms/step - loss: 1.0958 - acc: 0.6107 - val_loss: 1.3141 - val_acc: 0.5314\n","Epoch 19/60\n","1929/1929 [==============================] - 17s 9ms/step - loss: 1.0734 - acc: 0.6179 - val_loss: 1.1531 - val_acc: 0.5723\n","Epoch 20/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0518 - acc: 0.6304 - val_loss: 1.1340 - val_acc: 0.6008\n","Epoch 21/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0409 - acc: 0.6444 - val_loss: 1.1269 - val_acc: 0.5635\n","Epoch 22/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0363 - acc: 0.6356 - val_loss: 1.0508 - val_acc: 0.6485\n","Epoch 23/60\n","1929/1929 [==============================] - 17s 9ms/step - loss: 1.0129 - acc: 0.6382 - val_loss: 1.0288 - val_acc: 0.6501\n","Epoch 24/60\n","1929/1929 [==============================] - 16s 9ms/step - loss: 0.9856 - acc: 0.6413 - val_loss: 1.0664 - val_acc: 0.6019\n","Epoch 25/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 1.0063 - acc: 0.6485 - val_loss: 0.9475 - val_acc: 0.6594\n","Epoch 26/60\n","1929/1929 [==============================] - 16s 8ms/step - loss: 0.9647 - acc: 0.6786 - val_loss: 1.0015 - val_acc: 0.6319\n","Epoch 27/60\n","1929/1929 [==============================] - 16s 9ms/step - loss: 0.9518 - acc: 0.6719 - val_loss: 1.0409 - val_acc: 0.6076\n","Epoch 28/60\n","1900/1929 [============================>.] - ETA: 0s - loss: 0.9468 - acc: 0.6742"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hq-nPwpH7ydi","colab_type":"code","outputId":"bbf7346e-186b-4c0a-a3e2-eb4edf1d2c1c","executionInfo":{"status":"ok","timestamp":1586108355482,"user_tz":-120,"elapsed":23802,"user":{"displayName":"Rana mostafa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpLWLhJYcXKOOp7sprSKwnxN-x9hYM61yh__9kww=s64","userId":"07598775866819373078"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["RunWHARF('data/SNOW/WHARF.npz')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["12\n","(3880, 1, 250, 29)\n","(3880, 12)\n","(3485, 1, 250, 29)\n","(395, 1, 250, 29)\n","[11, 19, 27]\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","Start Training\n","Train on 3485 samples, validate on 3485 samples\n","Epoch 1/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 2.3026 - acc: 0.2617 - val_loss: 2.0333 - val_acc: 0.3948\n","Epoch 2/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 1.9298 - acc: 0.3963 - val_loss: 1.8302 - val_acc: 0.4080\n","Epoch 3/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 1.6876 - acc: 0.4456 - val_loss: 1.7391 - val_acc: 0.4172\n","Epoch 4/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 1.5078 - acc: 0.4783 - val_loss: 1.4072 - val_acc: 0.5128\n","Epoch 5/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 1.3747 - acc: 0.5188 - val_loss: 1.3048 - val_acc: 0.5354\n","Epoch 6/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 1.3077 - acc: 0.5366 - val_loss: 1.2372 - val_acc: 0.5656\n","Epoch 7/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 1.2587 - acc: 0.5469 - val_loss: 1.2106 - val_acc: 0.5980\n","Epoch 8/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 1.2065 - acc: 0.5727 - val_loss: 1.1500 - val_acc: 0.6405\n","Epoch 9/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 1.1667 - acc: 0.5980 - val_loss: 1.1673 - val_acc: 0.5782\n","Epoch 10/60\n","3485/3485 [==============================] - 37s 11ms/step - loss: 1.1765 - acc: 0.5799 - val_loss: 1.1271 - val_acc: 0.5874\n","Epoch 11/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 1.1150 - acc: 0.6198 - val_loss: 1.1293 - val_acc: 0.5595\n","Epoch 12/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 1.0961 - acc: 0.6204 - val_loss: 1.1005 - val_acc: 0.5791\n","Epoch 13/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 1.0840 - acc: 0.6235 - val_loss: 1.0327 - val_acc: 0.6554\n","Epoch 14/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 1.0583 - acc: 0.6393 - val_loss: 1.0641 - val_acc: 0.6353\n","Epoch 15/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 1.0712 - acc: 0.6201 - val_loss: 1.0002 - val_acc: 0.6646\n","Epoch 16/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 1.0286 - acc: 0.6488 - val_loss: 0.9919 - val_acc: 0.6824\n","Epoch 17/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 1.0074 - acc: 0.6603 - val_loss: 0.9806 - val_acc: 0.6703\n","Epoch 18/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.9983 - acc: 0.6680 - val_loss: 1.0462 - val_acc: 0.6341\n","Epoch 19/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.9856 - acc: 0.6634 - val_loss: 0.9586 - val_acc: 0.6780\n","Epoch 20/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.9655 - acc: 0.6760 - val_loss: 0.9525 - val_acc: 0.6961\n","Epoch 21/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.9700 - acc: 0.6763 - val_loss: 0.9598 - val_acc: 0.6582\n","Epoch 22/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.9525 - acc: 0.6766 - val_loss: 0.9739 - val_acc: 0.6640\n","Epoch 23/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.9516 - acc: 0.6809 - val_loss: 0.9141 - val_acc: 0.6956\n","Epoch 24/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.9381 - acc: 0.6809 - val_loss: 0.9413 - val_acc: 0.6723\n","Epoch 25/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.9339 - acc: 0.6824 - val_loss: 0.9068 - val_acc: 0.7033\n","Epoch 26/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.9166 - acc: 0.6970 - val_loss: 0.9353 - val_acc: 0.6895\n","Epoch 27/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.9090 - acc: 0.6930 - val_loss: 0.9622 - val_acc: 0.6571\n","Epoch 28/60\n","3485/3485 [==============================] - 37s 11ms/step - loss: 0.9010 - acc: 0.6907 - val_loss: 0.8890 - val_acc: 0.7013\n","Epoch 29/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.8954 - acc: 0.6933 - val_loss: 0.9073 - val_acc: 0.6743\n","Epoch 30/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.8924 - acc: 0.7027 - val_loss: 0.8600 - val_acc: 0.7125\n","Epoch 31/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.8843 - acc: 0.7010 - val_loss: 0.8768 - val_acc: 0.7105\n","Epoch 32/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.8770 - acc: 0.6999 - val_loss: 0.8606 - val_acc: 0.7079\n","Epoch 33/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.8728 - acc: 0.7024 - val_loss: 0.8738 - val_acc: 0.6999\n","Epoch 34/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.8606 - acc: 0.7019 - val_loss: 0.8754 - val_acc: 0.6901\n","Epoch 35/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.8671 - acc: 0.7007 - val_loss: 0.8308 - val_acc: 0.7222\n","Epoch 36/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.8473 - acc: 0.7065 - val_loss: 0.8404 - val_acc: 0.7096\n","Epoch 37/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.8431 - acc: 0.7116 - val_loss: 0.8211 - val_acc: 0.7254\n","Epoch 38/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.8537 - acc: 0.7062 - val_loss: 0.8363 - val_acc: 0.7076\n","Epoch 39/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.8299 - acc: 0.7154 - val_loss: 0.7950 - val_acc: 0.7374\n","Epoch 40/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.8210 - acc: 0.7165 - val_loss: 0.8444 - val_acc: 0.7125\n","Epoch 41/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.8171 - acc: 0.7185 - val_loss: 0.8412 - val_acc: 0.7088\n","Epoch 42/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.8114 - acc: 0.7182 - val_loss: 0.8131 - val_acc: 0.7225\n","Epoch 43/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.8074 - acc: 0.7199 - val_loss: 0.7797 - val_acc: 0.7311\n","Epoch 44/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.7985 - acc: 0.7199 - val_loss: 0.7939 - val_acc: 0.7274\n","Epoch 45/60\n","3485/3485 [==============================] - 37s 11ms/step - loss: 0.8060 - acc: 0.7240 - val_loss: 0.7863 - val_acc: 0.7277\n","Epoch 46/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.7919 - acc: 0.7268 - val_loss: 0.7778 - val_acc: 0.7308\n","Epoch 47/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.8002 - acc: 0.7251 - val_loss: 0.7607 - val_acc: 0.7443\n","Epoch 48/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.7842 - acc: 0.7294 - val_loss: 0.8033 - val_acc: 0.7240\n","Epoch 49/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.7736 - acc: 0.7392 - val_loss: 0.8110 - val_acc: 0.7016\n","Epoch 50/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.7704 - acc: 0.7329 - val_loss: 0.7555 - val_acc: 0.7461\n","Epoch 51/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.7681 - acc: 0.7320 - val_loss: 0.7422 - val_acc: 0.7415\n","Epoch 52/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.7724 - acc: 0.7260 - val_loss: 0.7691 - val_acc: 0.7291\n","Epoch 53/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.7605 - acc: 0.7377 - val_loss: 0.7341 - val_acc: 0.7515\n","Epoch 54/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.7544 - acc: 0.7406 - val_loss: 0.7435 - val_acc: 0.7423\n","Epoch 55/60\n","3485/3485 [==============================] - 35s 10ms/step - loss: 0.7555 - acc: 0.7455 - val_loss: 0.7963 - val_acc: 0.7136\n","Epoch 56/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.7515 - acc: 0.7374 - val_loss: 0.7607 - val_acc: 0.7420\n","Epoch 57/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.7516 - acc: 0.7320 - val_loss: 0.7343 - val_acc: 0.7412\n","Epoch 58/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.7447 - acc: 0.7452 - val_loss: 0.7172 - val_acc: 0.7475\n","Epoch 59/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.7471 - acc: 0.7429 - val_loss: 0.7569 - val_acc: 0.7300\n","Epoch 60/60\n","3485/3485 [==============================] - 34s 10ms/step - loss: 0.7281 - acc: 0.7484 - val_loss: 0.7660 - val_acc: 0.7248\n","Accuracy[0.6785] Recall[0.5865] F1[0.6039] at fold[0]\n","______________________________________________________\n","Start Training\n","Train on 3489 samples, validate on 3489 samples\n","Epoch 1/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 2.3833 - acc: 0.2253 - val_loss: 2.2045 - val_acc: 0.3554\n","Epoch 2/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 2.0037 - acc: 0.3669 - val_loss: 1.6917 - val_acc: 0.4248\n","Epoch 3/60\n","3489/3489 [==============================] - 37s 11ms/step - loss: 1.6210 - acc: 0.4537 - val_loss: 1.4453 - val_acc: 0.5311\n","Epoch 4/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 1.4330 - acc: 0.4979 - val_loss: 1.3167 - val_acc: 0.5437\n","Epoch 5/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 1.3086 - acc: 0.5251 - val_loss: 1.3101 - val_acc: 0.5638\n","Epoch 6/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.2343 - acc: 0.5578 - val_loss: 1.2043 - val_acc: 0.5598\n","Epoch 7/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 1.1817 - acc: 0.5727 - val_loss: 1.1210 - val_acc: 0.6022\n","Epoch 8/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.1504 - acc: 0.5810 - val_loss: 1.0839 - val_acc: 0.6068\n","Epoch 9/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.1373 - acc: 0.5850 - val_loss: 1.1220 - val_acc: 0.5830\n","Epoch 10/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 1.0993 - acc: 0.6059 - val_loss: 1.0775 - val_acc: 0.6171\n","Epoch 11/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 1.0687 - acc: 0.6240 - val_loss: 1.1165 - val_acc: 0.5896\n","Epoch 12/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 1.0388 - acc: 0.6303 - val_loss: 1.0130 - val_acc: 0.6263\n","Epoch 13/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 1.0324 - acc: 0.6303 - val_loss: 1.0051 - val_acc: 0.6819\n","Epoch 14/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.0065 - acc: 0.6449 - val_loss: 0.9679 - val_acc: 0.6629\n","Epoch 15/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.9806 - acc: 0.6598 - val_loss: 0.9690 - val_acc: 0.6457\n","Epoch 16/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.9719 - acc: 0.6621 - val_loss: 1.0106 - val_acc: 0.6351\n","Epoch 17/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.9593 - acc: 0.6658 - val_loss: 1.0059 - val_acc: 0.6343\n","Epoch 18/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.9496 - acc: 0.6764 - val_loss: 0.9749 - val_acc: 0.6581\n","Epoch 19/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.9490 - acc: 0.6715 - val_loss: 0.9087 - val_acc: 0.6942\n","Epoch 20/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.9265 - acc: 0.6756 - val_loss: 0.9238 - val_acc: 0.6681\n","Epoch 21/60\n","3489/3489 [==============================] - 38s 11ms/step - loss: 0.9160 - acc: 0.6758 - val_loss: 0.9340 - val_acc: 0.6638\n","Epoch 22/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.9155 - acc: 0.6733 - val_loss: 0.9085 - val_acc: 0.6839\n","Epoch 23/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.8996 - acc: 0.6864 - val_loss: 0.8722 - val_acc: 0.7151\n","Epoch 24/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.8956 - acc: 0.6867 - val_loss: 0.8962 - val_acc: 0.6793\n","Epoch 25/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8791 - acc: 0.6996 - val_loss: 0.8584 - val_acc: 0.7071\n","Epoch 26/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.8667 - acc: 0.7016 - val_loss: 0.8644 - val_acc: 0.7019\n","Epoch 27/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.8744 - acc: 0.6993 - val_loss: 0.8487 - val_acc: 0.7191\n","Epoch 28/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.8521 - acc: 0.7091 - val_loss: 0.8575 - val_acc: 0.7082\n","Epoch 29/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.8482 - acc: 0.7111 - val_loss: 0.8715 - val_acc: 0.6979\n","Epoch 30/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.8466 - acc: 0.7056 - val_loss: 0.8677 - val_acc: 0.6790\n","Epoch 31/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8384 - acc: 0.7117 - val_loss: 0.8242 - val_acc: 0.7185\n","Epoch 32/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.8288 - acc: 0.7214 - val_loss: 0.8236 - val_acc: 0.7240\n","Epoch 33/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.8201 - acc: 0.7185 - val_loss: 0.8133 - val_acc: 0.7220\n","Epoch 34/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8256 - acc: 0.7114 - val_loss: 0.8311 - val_acc: 0.7231\n","Epoch 35/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8207 - acc: 0.7194 - val_loss: 0.8038 - val_acc: 0.7355\n","Epoch 36/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.8039 - acc: 0.7291 - val_loss: 0.7861 - val_acc: 0.7420\n","Epoch 37/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8051 - acc: 0.7300 - val_loss: 0.7737 - val_acc: 0.7463\n","Epoch 38/60\n","3489/3489 [==============================] - 37s 11ms/step - loss: 0.7943 - acc: 0.7323 - val_loss: 0.7749 - val_acc: 0.7435\n","Epoch 39/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.7915 - acc: 0.7254 - val_loss: 0.7877 - val_acc: 0.7352\n","Epoch 40/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7808 - acc: 0.7349 - val_loss: 0.7638 - val_acc: 0.7463\n","Epoch 41/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7837 - acc: 0.7277 - val_loss: 0.7594 - val_acc: 0.7395\n","Epoch 42/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7752 - acc: 0.7398 - val_loss: 0.7672 - val_acc: 0.7334\n","Epoch 43/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7690 - acc: 0.7398 - val_loss: 0.7781 - val_acc: 0.7263\n","Epoch 44/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7697 - acc: 0.7357 - val_loss: 0.7478 - val_acc: 0.7432\n","Epoch 45/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7597 - acc: 0.7412 - val_loss: 0.7530 - val_acc: 0.7521\n","Epoch 46/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7519 - acc: 0.7461 - val_loss: 0.7777 - val_acc: 0.7188\n","Epoch 47/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7504 - acc: 0.7449 - val_loss: 0.7414 - val_acc: 0.7506\n","Epoch 48/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7370 - acc: 0.7472 - val_loss: 0.7453 - val_acc: 0.7380\n","Epoch 49/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7375 - acc: 0.7466 - val_loss: 0.7223 - val_acc: 0.7501\n","Epoch 50/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.7315 - acc: 0.7575 - val_loss: 0.7193 - val_acc: 0.7575\n","Epoch 51/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7282 - acc: 0.7552 - val_loss: 0.7170 - val_acc: 0.7584\n","Epoch 52/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7202 - acc: 0.7549 - val_loss: 0.7126 - val_acc: 0.7584\n","Epoch 53/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7137 - acc: 0.7561 - val_loss: 0.6996 - val_acc: 0.7713\n","Epoch 54/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.7151 - acc: 0.7581 - val_loss: 0.7070 - val_acc: 0.7624\n","Epoch 55/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.7108 - acc: 0.7570 - val_loss: 0.6831 - val_acc: 0.7750\n","Epoch 56/60\n","3489/3489 [==============================] - 37s 11ms/step - loss: 0.7064 - acc: 0.7627 - val_loss: 0.6956 - val_acc: 0.7630\n","Epoch 57/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.7030 - acc: 0.7624 - val_loss: 0.6987 - val_acc: 0.7633\n","Epoch 58/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.6907 - acc: 0.7693 - val_loss: 0.6746 - val_acc: 0.7784\n","Epoch 59/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.6917 - acc: 0.7678 - val_loss: 0.6709 - val_acc: 0.7690\n","Epoch 60/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.6975 - acc: 0.7676 - val_loss: 0.6983 - val_acc: 0.7541\n","Accuracy[0.6777] Recall[0.5870] F1[0.6060] at fold[1]\n","______________________________________________________\n","Start Training\n","Train on 3489 samples, validate on 3489 samples\n","Epoch 1/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 2.2554 - acc: 0.2582 - val_loss: 2.0522 - val_acc: 0.2752\n","Epoch 2/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.8529 - acc: 0.4018 - val_loss: 1.6779 - val_acc: 0.4076\n","Epoch 3/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.6303 - acc: 0.4371 - val_loss: 1.6059 - val_acc: 0.4649\n","Epoch 4/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.4360 - acc: 0.4904 - val_loss: 1.3426 - val_acc: 0.5056\n","Epoch 5/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.3275 - acc: 0.5259 - val_loss: 1.3267 - val_acc: 0.4878\n","Epoch 6/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 1.2807 - acc: 0.5385 - val_loss: 1.2236 - val_acc: 0.5767\n","Epoch 7/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.2337 - acc: 0.5535 - val_loss: 1.1636 - val_acc: 0.5867\n","Epoch 8/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.2054 - acc: 0.5681 - val_loss: 1.1545 - val_acc: 0.5901\n","Epoch 9/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 1.1562 - acc: 0.5933 - val_loss: 1.1361 - val_acc: 0.5982\n","Epoch 10/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.1302 - acc: 0.5999 - val_loss: 1.1317 - val_acc: 0.6337\n","Epoch 11/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.1043 - acc: 0.6099 - val_loss: 1.0652 - val_acc: 0.6601\n","Epoch 12/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.0858 - acc: 0.6188 - val_loss: 1.0697 - val_acc: 0.6254\n","Epoch 13/60\n","3489/3489 [==============================] - 39s 11ms/step - loss: 1.0679 - acc: 0.6240 - val_loss: 1.0263 - val_acc: 0.6452\n","Epoch 14/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.0588 - acc: 0.6260 - val_loss: 1.0320 - val_acc: 0.6285\n","Epoch 15/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.0342 - acc: 0.6369 - val_loss: 1.0346 - val_acc: 0.6449\n","Epoch 16/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.0184 - acc: 0.6475 - val_loss: 1.0007 - val_acc: 0.6303\n","Epoch 17/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.0164 - acc: 0.6426 - val_loss: 0.9924 - val_acc: 0.6555\n","Epoch 18/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 1.0006 - acc: 0.6443 - val_loss: 0.9746 - val_acc: 0.6601\n","Epoch 19/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.9827 - acc: 0.6598 - val_loss: 0.9693 - val_acc: 0.6629\n","Epoch 20/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.9767 - acc: 0.6624 - val_loss: 0.9534 - val_acc: 0.6747\n","Epoch 21/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.9672 - acc: 0.6635 - val_loss: 0.9631 - val_acc: 0.6664\n","Epoch 22/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.9547 - acc: 0.6678 - val_loss: 0.9394 - val_acc: 0.6767\n","Epoch 23/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.9531 - acc: 0.6675 - val_loss: 0.9375 - val_acc: 0.6801\n","Epoch 24/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.9541 - acc: 0.6647 - val_loss: 0.9260 - val_acc: 0.6735\n","Epoch 25/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.9331 - acc: 0.6770 - val_loss: 0.9308 - val_acc: 0.6801\n","Epoch 26/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.9259 - acc: 0.6664 - val_loss: 0.9114 - val_acc: 0.6733\n","Epoch 27/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.9227 - acc: 0.6687 - val_loss: 0.9245 - val_acc: 0.6810\n","Epoch 28/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.9182 - acc: 0.6807 - val_loss: 0.9070 - val_acc: 0.6939\n","Epoch 29/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.9072 - acc: 0.6758 - val_loss: 0.8901 - val_acc: 0.6859\n","Epoch 30/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8955 - acc: 0.6905 - val_loss: 0.9103 - val_acc: 0.6624\n","Epoch 31/60\n","3489/3489 [==============================] - 38s 11ms/step - loss: 0.8907 - acc: 0.6836 - val_loss: 0.8648 - val_acc: 0.7042\n","Epoch 32/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8901 - acc: 0.6876 - val_loss: 0.8610 - val_acc: 0.7077\n","Epoch 33/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8824 - acc: 0.6873 - val_loss: 0.8752 - val_acc: 0.6870\n","Epoch 34/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8775 - acc: 0.6953 - val_loss: 0.9061 - val_acc: 0.6664\n","Epoch 35/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.8726 - acc: 0.6945 - val_loss: 0.8818 - val_acc: 0.6842\n","Epoch 36/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8642 - acc: 0.6939 - val_loss: 0.8498 - val_acc: 0.7011\n","Epoch 37/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8552 - acc: 0.7016 - val_loss: 0.8538 - val_acc: 0.6950\n","Epoch 38/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8460 - acc: 0.7002 - val_loss: 0.8336 - val_acc: 0.7137\n","Epoch 39/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8428 - acc: 0.7059 - val_loss: 0.8285 - val_acc: 0.7200\n","Epoch 40/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8399 - acc: 0.7094 - val_loss: 0.8314 - val_acc: 0.7163\n","Epoch 41/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.8425 - acc: 0.7045 - val_loss: 0.8344 - val_acc: 0.6973\n","Epoch 42/60\n","3489/3489 [==============================] - 34s 10ms/step - loss: 0.8305 - acc: 0.7142 - val_loss: 0.8204 - val_acc: 0.7191\n","Epoch 43/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8296 - acc: 0.7120 - val_loss: 0.8555 - val_acc: 0.7085\n","Epoch 44/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8200 - acc: 0.7220 - val_loss: 0.8011 - val_acc: 0.7183\n","Epoch 45/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8209 - acc: 0.7099 - val_loss: 0.8217 - val_acc: 0.7111\n","Epoch 46/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8042 - acc: 0.7226 - val_loss: 0.8144 - val_acc: 0.7097\n","Epoch 47/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.8048 - acc: 0.7183 - val_loss: 0.8157 - val_acc: 0.7056\n","Epoch 48/60\n","3489/3489 [==============================] - 37s 11ms/step - loss: 0.7981 - acc: 0.7240 - val_loss: 0.7776 - val_acc: 0.7343\n","Epoch 49/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7877 - acc: 0.7271 - val_loss: 0.7679 - val_acc: 0.7309\n","Epoch 50/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7855 - acc: 0.7251 - val_loss: 0.7912 - val_acc: 0.7191\n","Epoch 51/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7853 - acc: 0.7226 - val_loss: 0.8167 - val_acc: 0.7142\n","Epoch 52/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7840 - acc: 0.7300 - val_loss: 0.7742 - val_acc: 0.7283\n","Epoch 53/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7758 - acc: 0.7332 - val_loss: 0.8109 - val_acc: 0.7074\n","Epoch 54/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7720 - acc: 0.7254 - val_loss: 0.7768 - val_acc: 0.7243\n","Epoch 55/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7665 - acc: 0.7363 - val_loss: 0.7924 - val_acc: 0.7059\n","Epoch 56/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7599 - acc: 0.7369 - val_loss: 0.7706 - val_acc: 0.7389\n","Epoch 57/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7609 - acc: 0.7366 - val_loss: 0.7266 - val_acc: 0.7495\n","Epoch 58/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7618 - acc: 0.7332 - val_loss: 0.7271 - val_acc: 0.7498\n","Epoch 59/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7401 - acc: 0.7449 - val_loss: 0.7451 - val_acc: 0.7469\n","Epoch 60/60\n","3489/3489 [==============================] - 35s 10ms/step - loss: 0.7489 - acc: 0.7409 - val_loss: 0.7947 - val_acc: 0.7140\n","Accuracy[0.6573] Recall[0.6137] F1[0.6075] at fold[2]\n","______________________________________________________\n","Start Training\n","Train on 3491 samples, validate on 3491 samples\n","Epoch 1/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 2.4791 - acc: 0.1756 - val_loss: 2.1871 - val_acc: 0.2991\n","Epoch 2/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 2.1680 - acc: 0.2796 - val_loss: 2.1239 - val_acc: 0.2463\n","Epoch 3/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 2.0048 - acc: 0.3523 - val_loss: 1.9037 - val_acc: 0.4005\n","Epoch 4/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.7498 - acc: 0.4394 - val_loss: 1.7183 - val_acc: 0.3847\n","Epoch 5/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.6006 - acc: 0.4546 - val_loss: 1.5053 - val_acc: 0.4789\n","Epoch 6/60\n","3491/3491 [==============================] - 37s 11ms/step - loss: 1.4650 - acc: 0.4850 - val_loss: 1.3903 - val_acc: 0.4901\n","Epoch 7/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.3702 - acc: 0.5079 - val_loss: 1.3335 - val_acc: 0.5448\n","Epoch 8/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.3309 - acc: 0.5242 - val_loss: 1.2694 - val_acc: 0.5457\n","Epoch 9/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.2765 - acc: 0.5460 - val_loss: 1.3215 - val_acc: 0.4953\n","Epoch 10/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.2295 - acc: 0.5637 - val_loss: 1.2237 - val_acc: 0.5531\n","Epoch 11/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.2329 - acc: 0.5531 - val_loss: 1.1564 - val_acc: 0.6147\n","Epoch 12/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.1938 - acc: 0.5706 - val_loss: 1.1705 - val_acc: 0.6044\n","Epoch 13/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.1539 - acc: 0.5921 - val_loss: 1.1596 - val_acc: 0.6061\n","Epoch 14/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.1370 - acc: 0.5995 - val_loss: 1.0999 - val_acc: 0.6382\n","Epoch 15/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.1178 - acc: 0.6096 - val_loss: 1.1106 - val_acc: 0.5975\n","Epoch 16/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.1224 - acc: 0.5987 - val_loss: 1.1160 - val_acc: 0.5952\n","Epoch 17/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.1014 - acc: 0.6124 - val_loss: 1.0792 - val_acc: 0.6196\n","Epoch 18/60\n","3491/3491 [==============================] - 34s 10ms/step - loss: 1.0919 - acc: 0.6073 - val_loss: 1.0780 - val_acc: 0.5875\n","Epoch 19/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.0845 - acc: 0.6225 - val_loss: 1.0990 - val_acc: 0.5766\n","Epoch 20/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.0586 - acc: 0.6288 - val_loss: 1.0327 - val_acc: 0.6517\n","Epoch 21/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.0602 - acc: 0.6182 - val_loss: 1.0790 - val_acc: 0.6308\n","Epoch 22/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.0439 - acc: 0.6422 - val_loss: 1.0200 - val_acc: 0.6528\n","Epoch 23/60\n","3491/3491 [==============================] - 37s 11ms/step - loss: 1.0359 - acc: 0.6362 - val_loss: 1.0387 - val_acc: 0.6316\n","Epoch 24/60\n","3491/3491 [==============================] - 34s 10ms/step - loss: 1.0360 - acc: 0.6359 - val_loss: 0.9871 - val_acc: 0.6626\n","Epoch 25/60\n","3491/3491 [==============================] - 34s 10ms/step - loss: 1.0157 - acc: 0.6439 - val_loss: 1.0289 - val_acc: 0.6144\n","Epoch 26/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.0107 - acc: 0.6425 - val_loss: 1.0650 - val_acc: 0.5835\n","Epoch 27/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.0012 - acc: 0.6545 - val_loss: 0.9705 - val_acc: 0.6686\n","Epoch 28/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9945 - acc: 0.6494 - val_loss: 0.9575 - val_acc: 0.6743\n","Epoch 29/60\n","3491/3491 [==============================] - 34s 10ms/step - loss: 0.9768 - acc: 0.6588 - val_loss: 0.9790 - val_acc: 0.6594\n","Epoch 30/60\n","3491/3491 [==============================] - 34s 10ms/step - loss: 0.9760 - acc: 0.6600 - val_loss: 0.9728 - val_acc: 0.6646\n","Epoch 31/60\n","3491/3491 [==============================] - 34s 10ms/step - loss: 0.9757 - acc: 0.6522 - val_loss: 0.9464 - val_acc: 0.6712\n","Epoch 32/60\n","3491/3491 [==============================] - 34s 10ms/step - loss: 0.9711 - acc: 0.6560 - val_loss: 0.9257 - val_acc: 0.6886\n","Epoch 33/60\n","3491/3491 [==============================] - 34s 10ms/step - loss: 0.9514 - acc: 0.6666 - val_loss: 0.9178 - val_acc: 0.6797\n","Epoch 34/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9526 - acc: 0.6583 - val_loss: 1.0100 - val_acc: 0.6159\n","Epoch 35/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9337 - acc: 0.6795 - val_loss: 0.9459 - val_acc: 0.6666\n","Epoch 36/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9623 - acc: 0.6554 - val_loss: 0.9244 - val_acc: 0.6989\n","Epoch 37/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9292 - acc: 0.6780 - val_loss: 0.9230 - val_acc: 0.6700\n","Epoch 38/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9184 - acc: 0.6898 - val_loss: 0.9547 - val_acc: 0.6353\n","Epoch 39/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9134 - acc: 0.6849 - val_loss: 0.9644 - val_acc: 0.6574\n","Epoch 40/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9099 - acc: 0.6855 - val_loss: 0.8776 - val_acc: 0.7070\n","Epoch 41/60\n","3491/3491 [==============================] - 37s 11ms/step - loss: 0.9092 - acc: 0.6789 - val_loss: 0.9131 - val_acc: 0.6597\n","Epoch 42/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8978 - acc: 0.6912 - val_loss: 0.9155 - val_acc: 0.6726\n","Epoch 43/60\n","3491/3491 [==============================] - 34s 10ms/step - loss: 0.8936 - acc: 0.6886 - val_loss: 0.8758 - val_acc: 0.7115\n","Epoch 44/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8748 - acc: 0.6981 - val_loss: 0.8669 - val_acc: 0.7018\n","Epoch 45/60\n","3491/3491 [==============================] - 36s 10ms/step - loss: 0.8787 - acc: 0.6929 - val_loss: 0.8913 - val_acc: 0.6863\n","Epoch 46/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8789 - acc: 0.6926 - val_loss: 0.8640 - val_acc: 0.6892\n","Epoch 47/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8688 - acc: 0.6984 - val_loss: 0.8763 - val_acc: 0.6938\n","Epoch 48/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8558 - acc: 0.7101 - val_loss: 0.8333 - val_acc: 0.7239\n","Epoch 49/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8831 - acc: 0.6898 - val_loss: 0.8189 - val_acc: 0.7239\n","Epoch 50/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8491 - acc: 0.7078 - val_loss: 0.8732 - val_acc: 0.6978\n","Epoch 51/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8554 - acc: 0.6969 - val_loss: 0.8306 - val_acc: 0.7147\n","Epoch 52/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8365 - acc: 0.7107 - val_loss: 0.8741 - val_acc: 0.6777\n","Epoch 53/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8588 - acc: 0.6912 - val_loss: 0.8276 - val_acc: 0.7293\n","Epoch 54/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8346 - acc: 0.7027 - val_loss: 0.8341 - val_acc: 0.7041\n","Epoch 55/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8284 - acc: 0.7130 - val_loss: 0.8123 - val_acc: 0.7310\n","Epoch 56/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8204 - acc: 0.7210 - val_loss: 0.8339 - val_acc: 0.7001\n","Epoch 57/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8278 - acc: 0.7158 - val_loss: 0.7747 - val_acc: 0.7462\n","Epoch 58/60\n","3491/3491 [==============================] - 40s 11ms/step - loss: 0.8036 - acc: 0.7216 - val_loss: 0.7924 - val_acc: 0.7270\n","Epoch 59/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.7998 - acc: 0.7267 - val_loss: 0.7767 - val_acc: 0.7342\n","Epoch 60/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8055 - acc: 0.7239 - val_loss: 0.7728 - val_acc: 0.7459\n","Accuracy[0.7249] Recall[0.6287] F1[0.6405] at fold[3]\n","______________________________________________________\n","Start Training\n","Train on 3491 samples, validate on 3491 samples\n","Epoch 1/60\n","3491/3491 [==============================] - 36s 10ms/step - loss: 2.5204 - acc: 0.1882 - val_loss: 2.2935 - val_acc: 0.1825\n","Epoch 2/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 2.2252 - acc: 0.2701 - val_loss: 2.1408 - val_acc: 0.3039\n","Epoch 3/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 2.0893 - acc: 0.3217 - val_loss: 2.0211 - val_acc: 0.3563\n","Epoch 4/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.8745 - acc: 0.3999 - val_loss: 1.7138 - val_acc: 0.4357\n","Epoch 5/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.6756 - acc: 0.4345 - val_loss: 1.5401 - val_acc: 0.5019\n","Epoch 6/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.5224 - acc: 0.4798 - val_loss: 1.4288 - val_acc: 0.5133\n","Epoch 7/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.4212 - acc: 0.5004 - val_loss: 1.3908 - val_acc: 0.5024\n","Epoch 8/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.3747 - acc: 0.5196 - val_loss: 1.3159 - val_acc: 0.5228\n","Epoch 9/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.3324 - acc: 0.5371 - val_loss: 1.3355 - val_acc: 0.5428\n","Epoch 10/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.2894 - acc: 0.5471 - val_loss: 1.3066 - val_acc: 0.5506\n","Epoch 11/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.2490 - acc: 0.5511 - val_loss: 1.2176 - val_acc: 0.5657\n","Epoch 12/60\n","3491/3491 [==============================] - 36s 10ms/step - loss: 1.2078 - acc: 0.5689 - val_loss: 1.2140 - val_acc: 0.5606\n","Epoch 13/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.2016 - acc: 0.5695 - val_loss: 1.1583 - val_acc: 0.5970\n","Epoch 14/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.1864 - acc: 0.5772 - val_loss: 1.1793 - val_acc: 0.5743\n","Epoch 15/60\n","3491/3491 [==============================] - 37s 11ms/step - loss: 1.1510 - acc: 0.5869 - val_loss: 1.0973 - val_acc: 0.6282\n","Epoch 16/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.1093 - acc: 0.6110 - val_loss: 1.0918 - val_acc: 0.6159\n","Epoch 17/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.1091 - acc: 0.6001 - val_loss: 1.0709 - val_acc: 0.6394\n","Epoch 18/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.0952 - acc: 0.6121 - val_loss: 1.0561 - val_acc: 0.6313\n","Epoch 19/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.0810 - acc: 0.6222 - val_loss: 1.0480 - val_acc: 0.6391\n","Epoch 20/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.0790 - acc: 0.6233 - val_loss: 1.0155 - val_acc: 0.6422\n","Epoch 21/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.0459 - acc: 0.6325 - val_loss: 1.0199 - val_acc: 0.6600\n","Epoch 22/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.0334 - acc: 0.6376 - val_loss: 1.0457 - val_acc: 0.6359\n","Epoch 23/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.0402 - acc: 0.6322 - val_loss: 1.0104 - val_acc: 0.6649\n","Epoch 24/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.0142 - acc: 0.6382 - val_loss: 0.9971 - val_acc: 0.6720\n","Epoch 25/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 1.0132 - acc: 0.6425 - val_loss: 0.9788 - val_acc: 0.6502\n","Epoch 26/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9912 - acc: 0.6528 - val_loss: 1.0214 - val_acc: 0.6356\n","Epoch 27/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9978 - acc: 0.6534 - val_loss: 0.9657 - val_acc: 0.6577\n","Epoch 28/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9877 - acc: 0.6588 - val_loss: 0.9667 - val_acc: 0.6737\n","Epoch 29/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9972 - acc: 0.6511 - val_loss: 0.9348 - val_acc: 0.6852\n","Epoch 30/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9636 - acc: 0.6689 - val_loss: 1.0696 - val_acc: 0.5643\n","Epoch 31/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9532 - acc: 0.6654 - val_loss: 0.9364 - val_acc: 0.6717\n","Epoch 32/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9609 - acc: 0.6677 - val_loss: 0.9221 - val_acc: 0.6926\n","Epoch 33/60\n","3491/3491 [==============================] - 38s 11ms/step - loss: 0.9461 - acc: 0.6703 - val_loss: 0.9388 - val_acc: 0.6760\n","Epoch 34/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9338 - acc: 0.6797 - val_loss: 0.9092 - val_acc: 0.6949\n","Epoch 35/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9316 - acc: 0.6903 - val_loss: 0.9152 - val_acc: 0.6838\n","Epoch 36/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9238 - acc: 0.6815 - val_loss: 0.8919 - val_acc: 0.7009\n","Epoch 37/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9231 - acc: 0.6818 - val_loss: 0.9123 - val_acc: 0.6858\n","Epoch 38/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9113 - acc: 0.6881 - val_loss: 0.8899 - val_acc: 0.6886\n","Epoch 39/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.9074 - acc: 0.6898 - val_loss: 0.8792 - val_acc: 0.6978\n","Epoch 40/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8918 - acc: 0.6944 - val_loss: 0.8924 - val_acc: 0.6895\n","Epoch 41/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8996 - acc: 0.6849 - val_loss: 0.8852 - val_acc: 0.6858\n","Epoch 42/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8882 - acc: 0.6944 - val_loss: 0.9007 - val_acc: 0.6803\n","Epoch 43/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8767 - acc: 0.6961 - val_loss: 0.8494 - val_acc: 0.7070\n","Epoch 44/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8802 - acc: 0.6981 - val_loss: 0.8438 - val_acc: 0.7101\n","Epoch 45/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8655 - acc: 0.7021 - val_loss: 0.8959 - val_acc: 0.7098\n","Epoch 46/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8735 - acc: 0.6949 - val_loss: 0.8772 - val_acc: 0.7147\n","Epoch 47/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8596 - acc: 0.7018 - val_loss: 0.9282 - val_acc: 0.6838\n","Epoch 48/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8627 - acc: 0.7084 - val_loss: 0.8493 - val_acc: 0.7118\n","Epoch 49/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8451 - acc: 0.7110 - val_loss: 0.8247 - val_acc: 0.7173\n","Epoch 50/60\n","3491/3491 [==============================] - 38s 11ms/step - loss: 0.8490 - acc: 0.7041 - val_loss: 0.8478 - val_acc: 0.7093\n","Epoch 51/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8426 - acc: 0.7061 - val_loss: 0.8480 - val_acc: 0.7038\n","Epoch 52/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8347 - acc: 0.7113 - val_loss: 0.8044 - val_acc: 0.7233\n","Epoch 53/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8374 - acc: 0.7115 - val_loss: 0.8167 - val_acc: 0.7201\n","Epoch 54/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8179 - acc: 0.7239 - val_loss: 0.8062 - val_acc: 0.7262\n","Epoch 55/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8189 - acc: 0.7181 - val_loss: 0.7885 - val_acc: 0.7319\n","Epoch 56/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8136 - acc: 0.7219 - val_loss: 0.8067 - val_acc: 0.7267\n","Epoch 57/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8042 - acc: 0.7279 - val_loss: 0.8077 - val_acc: 0.7267\n","Epoch 58/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8035 - acc: 0.7221 - val_loss: 0.7798 - val_acc: 0.7339\n","Epoch 59/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.8042 - acc: 0.7253 - val_loss: 0.7628 - val_acc: 0.7453\n","Epoch 60/60\n","3491/3491 [==============================] - 35s 10ms/step - loss: 0.7867 - acc: 0.7256 - val_loss: 0.8024 - val_acc: 0.7339\n","Accuracy[0.7044] Recall[0.6517] F1[0.6684] at fold[4]\n","______________________________________________________\n","Start Training\n","Train on 3493 samples, validate on 3493 samples\n","Epoch 1/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 2.6217 - acc: 0.1849 - val_loss: 2.2723 - val_acc: 0.2534\n","Epoch 2/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 2.1344 - acc: 0.3435 - val_loss: 2.0054 - val_acc: 0.3719\n","Epoch 3/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.8888 - acc: 0.4008 - val_loss: 1.7221 - val_acc: 0.4277\n","Epoch 4/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 1.6261 - acc: 0.4489 - val_loss: 1.5304 - val_acc: 0.4904\n","Epoch 5/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.4698 - acc: 0.4864 - val_loss: 1.4119 - val_acc: 0.5219\n","Epoch 6/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.3562 - acc: 0.5242 - val_loss: 1.2678 - val_acc: 0.5319\n","Epoch 7/60\n","3493/3493 [==============================] - 37s 11ms/step - loss: 1.2872 - acc: 0.5514 - val_loss: 1.2665 - val_acc: 0.5319\n","Epoch 8/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.2582 - acc: 0.5617 - val_loss: 1.2187 - val_acc: 0.5749\n","Epoch 9/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.2085 - acc: 0.5757 - val_loss: 1.2096 - val_acc: 0.5256\n","Epoch 10/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.1760 - acc: 0.5774 - val_loss: 1.1813 - val_acc: 0.5680\n","Epoch 11/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 1.1564 - acc: 0.5783 - val_loss: 1.2518 - val_acc: 0.5459\n","Epoch 12/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.1286 - acc: 0.6006 - val_loss: 1.1013 - val_acc: 0.6313\n","Epoch 13/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 1.0969 - acc: 0.6270 - val_loss: 1.1196 - val_acc: 0.5912\n","Epoch 14/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 1.0906 - acc: 0.6115 - val_loss: 1.0561 - val_acc: 0.6356\n","Epoch 15/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 1.0777 - acc: 0.6172 - val_loss: 1.0726 - val_acc: 0.6192\n","Epoch 16/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.0429 - acc: 0.6281 - val_loss: 1.0350 - val_acc: 0.6413\n","Epoch 17/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.0625 - acc: 0.6270 - val_loss: 1.0389 - val_acc: 0.6232\n","Epoch 18/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.0109 - acc: 0.6419 - val_loss: 1.0135 - val_acc: 0.6533\n","Epoch 19/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 1.0142 - acc: 0.6310 - val_loss: 0.9998 - val_acc: 0.6482\n","Epoch 20/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.0081 - acc: 0.6473 - val_loss: 1.0512 - val_acc: 0.6373\n","Epoch 21/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.9832 - acc: 0.6596 - val_loss: 0.9528 - val_acc: 0.6668\n","Epoch 22/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.9915 - acc: 0.6556 - val_loss: 0.9910 - val_acc: 0.6301\n","Epoch 23/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.9682 - acc: 0.6608 - val_loss: 0.9819 - val_acc: 0.6630\n","Epoch 24/60\n","3493/3493 [==============================] - 38s 11ms/step - loss: 0.9606 - acc: 0.6622 - val_loss: 0.9670 - val_acc: 0.6716\n","Epoch 25/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.9571 - acc: 0.6625 - val_loss: 0.9204 - val_acc: 0.6865\n","Epoch 26/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.9373 - acc: 0.6699 - val_loss: 0.9632 - val_acc: 0.6453\n","Epoch 27/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.9357 - acc: 0.6759 - val_loss: 0.9033 - val_acc: 0.6811\n","Epoch 28/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.9276 - acc: 0.6711 - val_loss: 0.8818 - val_acc: 0.6985\n","Epoch 29/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.9212 - acc: 0.6745 - val_loss: 0.8924 - val_acc: 0.6825\n","Epoch 30/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.9091 - acc: 0.6837 - val_loss: 0.9242 - val_acc: 0.6957\n","Epoch 31/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.8899 - acc: 0.6857 - val_loss: 0.8919 - val_acc: 0.6900\n","Epoch 32/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.9111 - acc: 0.6739 - val_loss: 0.9137 - val_acc: 0.6765\n","Epoch 33/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8917 - acc: 0.6911 - val_loss: 0.8505 - val_acc: 0.7023\n","Epoch 34/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8892 - acc: 0.6848 - val_loss: 0.8842 - val_acc: 0.6920\n","Epoch 35/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.8690 - acc: 0.6908 - val_loss: 0.8787 - val_acc: 0.7028\n","Epoch 36/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8778 - acc: 0.6885 - val_loss: 0.8379 - val_acc: 0.7226\n","Epoch 37/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.8632 - acc: 0.7005 - val_loss: 0.8303 - val_acc: 0.7051\n","Epoch 38/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.8469 - acc: 0.6988 - val_loss: 0.8455 - val_acc: 0.6891\n","Epoch 39/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.8483 - acc: 0.7011 - val_loss: 0.8149 - val_acc: 0.7275\n","Epoch 40/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.8460 - acc: 0.7046 - val_loss: 0.8252 - val_acc: 0.7272\n","Epoch 41/60\n","3493/3493 [==============================] - 38s 11ms/step - loss: 0.8377 - acc: 0.7080 - val_loss: 0.8452 - val_acc: 0.7014\n","Epoch 42/60\n","3493/3493 [==============================] - 39s 11ms/step - loss: 0.8314 - acc: 0.7163 - val_loss: 0.8008 - val_acc: 0.7200\n","Epoch 43/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.8317 - acc: 0.7005 - val_loss: 0.8326 - val_acc: 0.7137\n","Epoch 44/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.8250 - acc: 0.7074 - val_loss: 0.8345 - val_acc: 0.6948\n","Epoch 45/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.8167 - acc: 0.7103 - val_loss: 0.7819 - val_acc: 0.7186\n","Epoch 46/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.8120 - acc: 0.7088 - val_loss: 0.7945 - val_acc: 0.7240\n","Epoch 47/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.8185 - acc: 0.7140 - val_loss: 0.7772 - val_acc: 0.7272\n","Epoch 48/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.8017 - acc: 0.7180 - val_loss: 0.8404 - val_acc: 0.7111\n","Epoch 49/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.7960 - acc: 0.7109 - val_loss: 0.7659 - val_acc: 0.7415\n","Epoch 50/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.8046 - acc: 0.7186 - val_loss: 0.7962 - val_acc: 0.7137\n","Epoch 51/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.8054 - acc: 0.7097 - val_loss: 0.8929 - val_acc: 0.6845\n","Epoch 52/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.7932 - acc: 0.7163 - val_loss: 0.7661 - val_acc: 0.7229\n","Epoch 53/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.7723 - acc: 0.7338 - val_loss: 0.8049 - val_acc: 0.7083\n","Epoch 54/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.7755 - acc: 0.7217 - val_loss: 0.7817 - val_acc: 0.7197\n","Epoch 55/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.7676 - acc: 0.7297 - val_loss: 0.7682 - val_acc: 0.7234\n","Epoch 56/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.7761 - acc: 0.7200 - val_loss: 0.7500 - val_acc: 0.7295\n","Epoch 57/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.7564 - acc: 0.7332 - val_loss: 0.7368 - val_acc: 0.7429\n","Epoch 58/60\n","3493/3493 [==============================] - 38s 11ms/step - loss: 0.7715 - acc: 0.7286 - val_loss: 0.7421 - val_acc: 0.7403\n","Epoch 59/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 0.7549 - acc: 0.7380 - val_loss: 0.7303 - val_acc: 0.7521\n","Epoch 60/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.7487 - acc: 0.7412 - val_loss: 0.7114 - val_acc: 0.7598\n","Accuracy[0.6873] Recall[0.6285] F1[0.6230] at fold[5]\n","______________________________________________________\n","Start Training\n","Train on 3493 samples, validate on 3493 samples\n","Epoch 1/60\n","3493/3493 [==============================] - 36s 10ms/step - loss: 2.3756 - acc: 0.2216 - val_loss: 2.1963 - val_acc: 0.3484\n","Epoch 2/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 2.0890 - acc: 0.3536 - val_loss: 1.9433 - val_acc: 0.4088\n","Epoch 3/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.7930 - acc: 0.4194 - val_loss: 1.6535 - val_acc: 0.4082\n","Epoch 4/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.5585 - acc: 0.4638 - val_loss: 1.5019 - val_acc: 0.4881\n","Epoch 5/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.4406 - acc: 0.4807 - val_loss: 1.3326 - val_acc: 0.5425\n","Epoch 6/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.3633 - acc: 0.4979 - val_loss: 1.3192 - val_acc: 0.5422\n","Epoch 7/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.2902 - acc: 0.5325 - val_loss: 1.2964 - val_acc: 0.5190\n","Epoch 8/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.2242 - acc: 0.5683 - val_loss: 1.1753 - val_acc: 0.5683\n","Epoch 9/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.2029 - acc: 0.5657 - val_loss: 1.1686 - val_acc: 0.5637\n","Epoch 10/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.1725 - acc: 0.5814 - val_loss: 1.1416 - val_acc: 0.5763\n","Epoch 11/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.1471 - acc: 0.5912 - val_loss: 1.0866 - val_acc: 0.6238\n","Epoch 12/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.1065 - acc: 0.6101 - val_loss: 1.1911 - val_acc: 0.5431\n","Epoch 13/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.1035 - acc: 0.6149 - val_loss: 1.0766 - val_acc: 0.6161\n","Epoch 14/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.0886 - acc: 0.6104 - val_loss: 1.0415 - val_acc: 0.6519\n","Epoch 15/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.0549 - acc: 0.6290 - val_loss: 1.0209 - val_acc: 0.6467\n","Epoch 16/60\n","3493/3493 [==============================] - 38s 11ms/step - loss: 1.0492 - acc: 0.6267 - val_loss: 1.0132 - val_acc: 0.6484\n","Epoch 17/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.0346 - acc: 0.6347 - val_loss: 1.0026 - val_acc: 0.6562\n","Epoch 18/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.0126 - acc: 0.6482 - val_loss: 1.0178 - val_acc: 0.6533\n","Epoch 19/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 1.0056 - acc: 0.6496 - val_loss: 0.9682 - val_acc: 0.6762\n","Epoch 20/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.9835 - acc: 0.6613 - val_loss: 0.9823 - val_acc: 0.6459\n","Epoch 21/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.9827 - acc: 0.6608 - val_loss: 0.9472 - val_acc: 0.6857\n","Epoch 22/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.9694 - acc: 0.6630 - val_loss: 0.9467 - val_acc: 0.6971\n","Epoch 23/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.9691 - acc: 0.6688 - val_loss: 0.9555 - val_acc: 0.6648\n","Epoch 24/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.9506 - acc: 0.6791 - val_loss: 0.9253 - val_acc: 0.6994\n","Epoch 25/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.9370 - acc: 0.6805 - val_loss: 0.9177 - val_acc: 0.6848\n","Epoch 26/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.9316 - acc: 0.6802 - val_loss: 0.9157 - val_acc: 0.6848\n","Epoch 27/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.9252 - acc: 0.6794 - val_loss: 0.9008 - val_acc: 0.6877\n","Epoch 28/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.9073 - acc: 0.6940 - val_loss: 0.9214 - val_acc: 0.6842\n","Epoch 29/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.9155 - acc: 0.6788 - val_loss: 0.8829 - val_acc: 0.7057\n","Epoch 30/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8978 - acc: 0.6914 - val_loss: 0.9049 - val_acc: 0.7034\n","Epoch 31/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8811 - acc: 0.7017 - val_loss: 0.9030 - val_acc: 0.6908\n","Epoch 32/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8774 - acc: 0.7023 - val_loss: 0.8599 - val_acc: 0.7054\n","Epoch 33/60\n","3493/3493 [==============================] - 40s 12ms/step - loss: 0.8755 - acc: 0.6991 - val_loss: 0.8813 - val_acc: 0.6965\n","Epoch 34/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8738 - acc: 0.7005 - val_loss: 0.8500 - val_acc: 0.7214\n","Epoch 35/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8571 - acc: 0.7066 - val_loss: 0.8789 - val_acc: 0.6802\n","Epoch 36/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8711 - acc: 0.6928 - val_loss: 0.8497 - val_acc: 0.7129\n","Epoch 37/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8473 - acc: 0.7123 - val_loss: 0.8384 - val_acc: 0.7157\n","Epoch 38/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8506 - acc: 0.7097 - val_loss: 0.8643 - val_acc: 0.6791\n","Epoch 39/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8429 - acc: 0.7071 - val_loss: 0.8275 - val_acc: 0.7315\n","Epoch 40/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8418 - acc: 0.7074 - val_loss: 0.8301 - val_acc: 0.7114\n","Epoch 41/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8241 - acc: 0.7154 - val_loss: 0.8040 - val_acc: 0.7255\n","Epoch 42/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8339 - acc: 0.7129 - val_loss: 0.8355 - val_acc: 0.7212\n","Epoch 43/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8159 - acc: 0.7217 - val_loss: 0.8010 - val_acc: 0.7214\n","Epoch 44/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8131 - acc: 0.7171 - val_loss: 0.7844 - val_acc: 0.7343\n","Epoch 45/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8130 - acc: 0.7157 - val_loss: 0.7887 - val_acc: 0.7286\n","Epoch 46/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.8101 - acc: 0.7200 - val_loss: 0.8090 - val_acc: 0.7137\n","Epoch 47/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.7883 - acc: 0.7280 - val_loss: 0.8047 - val_acc: 0.7106\n","Epoch 48/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.7988 - acc: 0.7266 - val_loss: 0.7765 - val_acc: 0.7415\n","Epoch 49/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.7845 - acc: 0.7349 - val_loss: 0.7629 - val_acc: 0.7443\n","Epoch 50/60\n","3493/3493 [==============================] - 38s 11ms/step - loss: 0.7848 - acc: 0.7283 - val_loss: 0.7744 - val_acc: 0.7326\n","Epoch 51/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.7814 - acc: 0.7289 - val_loss: 0.7586 - val_acc: 0.7409\n","Epoch 52/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.7820 - acc: 0.7326 - val_loss: 0.7554 - val_acc: 0.7495\n","Epoch 53/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.7697 - acc: 0.7406 - val_loss: 0.7862 - val_acc: 0.7083\n","Epoch 54/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.7716 - acc: 0.7340 - val_loss: 0.7738 - val_acc: 0.7246\n","Epoch 55/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.7673 - acc: 0.7315 - val_loss: 0.7514 - val_acc: 0.7358\n","Epoch 56/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.7643 - acc: 0.7317 - val_loss: 0.7241 - val_acc: 0.7541\n","Epoch 57/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.7582 - acc: 0.7389 - val_loss: 0.7607 - val_acc: 0.7369\n","Epoch 58/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.7581 - acc: 0.7306 - val_loss: 0.8401 - val_acc: 0.6871\n","Epoch 59/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.7512 - acc: 0.7332 - val_loss: 0.7482 - val_acc: 0.7403\n","Epoch 60/60\n","3493/3493 [==============================] - 35s 10ms/step - loss: 0.7398 - acc: 0.7466 - val_loss: 0.7424 - val_acc: 0.7266\n","Accuracy[0.6744] Recall[0.5906] F1[0.5941] at fold[6]\n","______________________________________________________\n","Start Training\n","Train on 3495 samples, validate on 3495 samples\n","Epoch 1/60\n","3495/3495 [==============================] - 36s 10ms/step - loss: 2.6171 - acc: 0.1825 - val_loss: 2.2886 - val_acc: 0.3382\n","Epoch 2/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 2.2313 - acc: 0.2950 - val_loss: 2.0755 - val_acc: 0.3422\n","Epoch 3/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 1.9506 - acc: 0.3774 - val_loss: 1.7190 - val_acc: 0.4515\n","Epoch 4/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 1.6835 - acc: 0.4280 - val_loss: 1.5439 - val_acc: 0.4732\n","Epoch 5/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 1.5055 - acc: 0.4773 - val_loss: 1.4122 - val_acc: 0.5139\n","Epoch 6/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 1.4003 - acc: 0.4999 - val_loss: 1.4054 - val_acc: 0.5007\n","Epoch 7/60\n","3495/3495 [==============================] - 37s 11ms/step - loss: 1.3332 - acc: 0.5293 - val_loss: 1.2848 - val_acc: 0.5239\n","Epoch 8/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 1.2750 - acc: 0.5462 - val_loss: 1.2259 - val_acc: 0.5863\n","Epoch 9/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 1.2516 - acc: 0.5645 - val_loss: 1.1679 - val_acc: 0.5717\n","Epoch 10/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 1.1836 - acc: 0.5788 - val_loss: 1.1527 - val_acc: 0.5837\n","Epoch 11/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 1.1469 - acc: 0.5960 - val_loss: 1.1045 - val_acc: 0.6189\n","Epoch 12/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 1.1540 - acc: 0.6003 - val_loss: 1.1385 - val_acc: 0.5740\n","Epoch 13/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 1.0999 - acc: 0.6243 - val_loss: 1.1197 - val_acc: 0.5888\n","Epoch 14/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 1.0974 - acc: 0.6132 - val_loss: 1.0815 - val_acc: 0.6372\n","Epoch 15/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 1.0844 - acc: 0.6149 - val_loss: 1.1066 - val_acc: 0.5908\n","Epoch 16/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 1.0764 - acc: 0.6226 - val_loss: 1.0289 - val_acc: 0.6489\n","Epoch 17/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 1.0442 - acc: 0.6258 - val_loss: 1.0249 - val_acc: 0.6535\n","Epoch 18/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 1.0521 - acc: 0.6272 - val_loss: 1.0161 - val_acc: 0.6395\n","Epoch 19/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 1.0330 - acc: 0.6412 - val_loss: 0.9876 - val_acc: 0.6587\n","Epoch 20/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 1.0210 - acc: 0.6426 - val_loss: 0.9966 - val_acc: 0.6469\n","Epoch 21/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 1.0230 - acc: 0.6355 - val_loss: 1.0400 - val_acc: 0.6060\n","Epoch 22/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 0.9920 - acc: 0.6549 - val_loss: 0.9751 - val_acc: 0.6627\n","Epoch 23/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 0.9797 - acc: 0.6526 - val_loss: 0.9691 - val_acc: 0.6555\n","Epoch 24/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 0.9805 - acc: 0.6584 - val_loss: 0.9549 - val_acc: 0.6821\n","Epoch 25/60\n","3495/3495 [==============================] - 37s 11ms/step - loss: 0.9694 - acc: 0.6655 - val_loss: 0.9247 - val_acc: 0.6898\n","Epoch 26/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 0.9645 - acc: 0.6655 - val_loss: 0.9411 - val_acc: 0.6658\n","Epoch 27/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 0.9592 - acc: 0.6638 - val_loss: 0.9307 - val_acc: 0.6667\n","Epoch 28/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 0.9346 - acc: 0.6784 - val_loss: 0.9235 - val_acc: 0.6750\n","Epoch 29/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.9359 - acc: 0.6698 - val_loss: 0.9125 - val_acc: 0.6781\n","Epoch 30/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 0.9392 - acc: 0.6724 - val_loss: 0.9307 - val_acc: 0.6813\n","Epoch 31/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.9206 - acc: 0.6807 - val_loss: 0.8948 - val_acc: 0.6967\n","Epoch 32/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.9082 - acc: 0.6793 - val_loss: 0.8786 - val_acc: 0.6941\n","Epoch 33/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.9191 - acc: 0.6790 - val_loss: 0.8719 - val_acc: 0.7087\n","Epoch 34/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8901 - acc: 0.6921 - val_loss: 0.8926 - val_acc: 0.6893\n","Epoch 35/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8875 - acc: 0.6864 - val_loss: 0.8583 - val_acc: 0.7056\n","Epoch 36/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8705 - acc: 0.7027 - val_loss: 0.9069 - val_acc: 0.6827\n","Epoch 37/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 0.8854 - acc: 0.6867 - val_loss: 0.9534 - val_acc: 0.6501\n","Epoch 38/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8686 - acc: 0.6950 - val_loss: 0.8558 - val_acc: 0.7102\n","Epoch 39/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8602 - acc: 0.6973 - val_loss: 0.9212 - val_acc: 0.6584\n","Epoch 40/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8662 - acc: 0.6981 - val_loss: 0.8492 - val_acc: 0.7044\n","Epoch 41/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8663 - acc: 0.6956 - val_loss: 0.8383 - val_acc: 0.7093\n","Epoch 42/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8526 - acc: 0.7019 - val_loss: 0.8160 - val_acc: 0.7233\n","Epoch 43/60\n","3495/3495 [==============================] - 37s 11ms/step - loss: 0.8386 - acc: 0.7116 - val_loss: 0.8390 - val_acc: 0.7136\n","Epoch 44/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8354 - acc: 0.7059 - val_loss: 0.8098 - val_acc: 0.7190\n","Epoch 45/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8470 - acc: 0.7007 - val_loss: 0.8109 - val_acc: 0.7133\n","Epoch 46/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8214 - acc: 0.7165 - val_loss: 0.8078 - val_acc: 0.7259\n","Epoch 47/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8219 - acc: 0.7104 - val_loss: 0.8023 - val_acc: 0.7250\n","Epoch 48/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8186 - acc: 0.7130 - val_loss: 0.7907 - val_acc: 0.7299\n","Epoch 49/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8155 - acc: 0.7142 - val_loss: 0.7869 - val_acc: 0.7259\n","Epoch 50/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8142 - acc: 0.7144 - val_loss: 0.7960 - val_acc: 0.7362\n","Epoch 51/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8054 - acc: 0.7239 - val_loss: 0.7661 - val_acc: 0.7359\n","Epoch 52/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.7947 - acc: 0.7202 - val_loss: 0.7799 - val_acc: 0.7368\n","Epoch 53/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.7966 - acc: 0.7153 - val_loss: 0.8075 - val_acc: 0.6979\n","Epoch 54/60\n","3495/3495 [==============================] - 34s 10ms/step - loss: 0.7809 - acc: 0.7262 - val_loss: 0.7872 - val_acc: 0.7107\n","Epoch 55/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.7871 - acc: 0.7256 - val_loss: 0.8654 - val_acc: 0.6750\n","Epoch 56/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.8000 - acc: 0.7170 - val_loss: 0.7496 - val_acc: 0.7433\n","Epoch 57/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.7745 - acc: 0.7342 - val_loss: 0.7460 - val_acc: 0.7388\n","Epoch 58/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.7716 - acc: 0.7296 - val_loss: 0.8145 - val_acc: 0.6876\n","Epoch 59/60\n","3495/3495 [==============================] - 35s 10ms/step - loss: 0.7746 - acc: 0.7273 - val_loss: 0.7706 - val_acc: 0.7288\n","Epoch 60/60\n","3495/3495 [==============================] - 37s 11ms/step - loss: 0.7637 - acc: 0.7333 - val_loss: 0.7411 - val_acc: 0.7379\n","Accuracy[0.6935] Recall[0.6349] F1[0.6362] at fold[7]\n","______________________________________________________\n","Start Training\n","Train on 3497 samples, validate on 3497 samples\n","Epoch 1/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 2.2187 - acc: 0.3100 - val_loss: 1.9328 - val_acc: 0.3900\n","Epoch 2/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.7509 - acc: 0.4232 - val_loss: 1.7745 - val_acc: 0.3915\n","Epoch 3/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.4960 - acc: 0.4827 - val_loss: 1.3449 - val_acc: 0.5164\n","Epoch 4/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.3349 - acc: 0.5202 - val_loss: 1.2972 - val_acc: 0.4990\n","Epoch 5/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.2542 - acc: 0.5456 - val_loss: 1.2341 - val_acc: 0.5648\n","Epoch 6/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.1912 - acc: 0.5711 - val_loss: 1.1409 - val_acc: 0.5825\n","Epoch 7/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.1547 - acc: 0.5848 - val_loss: 1.1152 - val_acc: 0.5985\n","Epoch 8/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.1283 - acc: 0.5891 - val_loss: 1.1345 - val_acc: 0.6042\n","Epoch 9/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.0948 - acc: 0.6168 - val_loss: 1.0114 - val_acc: 0.6511\n","Epoch 10/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.0460 - acc: 0.6265 - val_loss: 0.9809 - val_acc: 0.6500\n","Epoch 11/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.0245 - acc: 0.6354 - val_loss: 1.0103 - val_acc: 0.6440\n","Epoch 12/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.0028 - acc: 0.6423 - val_loss: 1.0459 - val_acc: 0.6160\n","Epoch 13/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9871 - acc: 0.6471 - val_loss: 0.9332 - val_acc: 0.6854\n","Epoch 14/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9670 - acc: 0.6526 - val_loss: 0.9202 - val_acc: 0.6754\n","Epoch 15/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9493 - acc: 0.6663 - val_loss: 0.9908 - val_acc: 0.6506\n","Epoch 16/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9257 - acc: 0.6666 - val_loss: 0.8930 - val_acc: 0.6834\n","Epoch 17/60\n","3497/3497 [==============================] - 40s 11ms/step - loss: 0.9245 - acc: 0.6726 - val_loss: 0.8808 - val_acc: 0.6995\n","Epoch 18/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9060 - acc: 0.6746 - val_loss: 0.8867 - val_acc: 0.6926\n","Epoch 19/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8936 - acc: 0.6846 - val_loss: 0.8932 - val_acc: 0.6883\n","Epoch 20/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8825 - acc: 0.6943 - val_loss: 0.9034 - val_acc: 0.6663\n","Epoch 21/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8688 - acc: 0.6980 - val_loss: 0.8309 - val_acc: 0.7198\n","Epoch 22/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8498 - acc: 0.7103 - val_loss: 0.8466 - val_acc: 0.6857\n","Epoch 23/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8544 - acc: 0.7023 - val_loss: 0.8134 - val_acc: 0.7183\n","Epoch 24/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8417 - acc: 0.7052 - val_loss: 0.8067 - val_acc: 0.7272\n","Epoch 25/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8316 - acc: 0.7083 - val_loss: 0.8215 - val_acc: 0.7029\n","Epoch 26/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8194 - acc: 0.7203 - val_loss: 0.7964 - val_acc: 0.7235\n","Epoch 27/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8174 - acc: 0.7123 - val_loss: 0.8043 - val_acc: 0.7166\n","Epoch 28/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8092 - acc: 0.7152 - val_loss: 0.8187 - val_acc: 0.7083\n","Epoch 29/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8055 - acc: 0.7180 - val_loss: 0.7749 - val_acc: 0.7398\n","Epoch 30/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7976 - acc: 0.7238 - val_loss: 0.7685 - val_acc: 0.7389\n","Epoch 31/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7931 - acc: 0.7246 - val_loss: 0.7866 - val_acc: 0.7369\n","Epoch 32/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7896 - acc: 0.7246 - val_loss: 0.7648 - val_acc: 0.7261\n","Epoch 33/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7813 - acc: 0.7266 - val_loss: 0.7656 - val_acc: 0.7200\n","Epoch 34/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7736 - acc: 0.7352 - val_loss: 0.7580 - val_acc: 0.7378\n","Epoch 35/60\n","3497/3497 [==============================] - 37s 11ms/step - loss: 0.7615 - acc: 0.7295 - val_loss: 0.7640 - val_acc: 0.7386\n","Epoch 36/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7611 - acc: 0.7398 - val_loss: 0.7414 - val_acc: 0.7429\n","Epoch 37/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7551 - acc: 0.7378 - val_loss: 0.7345 - val_acc: 0.7489\n","Epoch 38/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7552 - acc: 0.7378 - val_loss: 0.7304 - val_acc: 0.7504\n","Epoch 39/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7420 - acc: 0.7475 - val_loss: 0.7117 - val_acc: 0.7546\n","Epoch 40/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7365 - acc: 0.7432 - val_loss: 0.7184 - val_acc: 0.7532\n","Epoch 41/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7359 - acc: 0.7504 - val_loss: 0.7309 - val_acc: 0.7486\n","Epoch 42/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7281 - acc: 0.7466 - val_loss: 0.7088 - val_acc: 0.7541\n","Epoch 43/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7355 - acc: 0.7438 - val_loss: 0.7073 - val_acc: 0.7601\n","Epoch 44/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7233 - acc: 0.7492 - val_loss: 0.7145 - val_acc: 0.7512\n","Epoch 45/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7163 - acc: 0.7515 - val_loss: 0.6913 - val_acc: 0.7589\n","Epoch 46/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7083 - acc: 0.7509 - val_loss: 0.6986 - val_acc: 0.7532\n","Epoch 47/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.6979 - acc: 0.7581 - val_loss: 0.7388 - val_acc: 0.7292\n","Epoch 48/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.7164 - acc: 0.7512 - val_loss: 0.7246 - val_acc: 0.7455\n","Epoch 49/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.6963 - acc: 0.7552 - val_loss: 0.6784 - val_acc: 0.7652\n","Epoch 50/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.6948 - acc: 0.7558 - val_loss: 0.7063 - val_acc: 0.7544\n","Epoch 51/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.6860 - acc: 0.7604 - val_loss: 0.7317 - val_acc: 0.7355\n","Epoch 52/60\n","3497/3497 [==============================] - 37s 11ms/step - loss: 0.6933 - acc: 0.7607 - val_loss: 0.6581 - val_acc: 0.7718\n","Epoch 53/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.6781 - acc: 0.7635 - val_loss: 0.6845 - val_acc: 0.7641\n","Epoch 54/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.6911 - acc: 0.7515 - val_loss: 0.6828 - val_acc: 0.7632\n","Epoch 55/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.6678 - acc: 0.7652 - val_loss: 0.6668 - val_acc: 0.7669\n","Epoch 56/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.6658 - acc: 0.7689 - val_loss: 0.6498 - val_acc: 0.7790\n","Epoch 57/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.6635 - acc: 0.7644 - val_loss: 0.6489 - val_acc: 0.7870\n","Epoch 58/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.6579 - acc: 0.7709 - val_loss: 0.6786 - val_acc: 0.7435\n","Epoch 59/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.6604 - acc: 0.7695 - val_loss: 0.6329 - val_acc: 0.7775\n","Epoch 60/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.6534 - acc: 0.7721 - val_loss: 0.6399 - val_acc: 0.7764\n","Accuracy[0.7232] Recall[0.6277] F1[0.6312] at fold[8]\n","______________________________________________________\n","Start Training\n","Train on 3497 samples, validate on 3497 samples\n","Epoch 1/60\n","3497/3497 [==============================] - 36s 10ms/step - loss: 2.6521 - acc: 0.2196 - val_loss: 2.1876 - val_acc: 0.2468\n","Epoch 2/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 2.1370 - acc: 0.3117 - val_loss: 2.2197 - val_acc: 0.2565\n","Epoch 3/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 2.0597 - acc: 0.3380 - val_loss: 1.9607 - val_acc: 0.3440\n","Epoch 4/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.8922 - acc: 0.4149 - val_loss: 1.7201 - val_acc: 0.4613\n","Epoch 5/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.7213 - acc: 0.4430 - val_loss: 1.5665 - val_acc: 0.4761\n","Epoch 6/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.5388 - acc: 0.4773 - val_loss: 1.6234 - val_acc: 0.4675\n","Epoch 7/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.4522 - acc: 0.4853 - val_loss: 1.3707 - val_acc: 0.5342\n","Epoch 8/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.3883 - acc: 0.5030 - val_loss: 1.4081 - val_acc: 0.4810\n","Epoch 9/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.3327 - acc: 0.5202 - val_loss: 1.3186 - val_acc: 0.5399\n","Epoch 10/60\n","3497/3497 [==============================] - 40s 11ms/step - loss: 1.2804 - acc: 0.5505 - val_loss: 1.2456 - val_acc: 0.5582\n","Epoch 11/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.2604 - acc: 0.5602 - val_loss: 1.2056 - val_acc: 0.5854\n","Epoch 12/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.2077 - acc: 0.5911 - val_loss: 1.2084 - val_acc: 0.5599\n","Epoch 13/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.1982 - acc: 0.5848 - val_loss: 1.1478 - val_acc: 0.6168\n","Epoch 14/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.1637 - acc: 0.5865 - val_loss: 1.1543 - val_acc: 0.5882\n","Epoch 15/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.1384 - acc: 0.6031 - val_loss: 1.1205 - val_acc: 0.6059\n","Epoch 16/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.1153 - acc: 0.6111 - val_loss: 1.0923 - val_acc: 0.6428\n","Epoch 17/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.1010 - acc: 0.6248 - val_loss: 1.1047 - val_acc: 0.6374\n","Epoch 18/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.0850 - acc: 0.6265 - val_loss: 1.0633 - val_acc: 0.6174\n","Epoch 19/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.0785 - acc: 0.6323 - val_loss: 1.0862 - val_acc: 0.6019\n","Epoch 20/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.0512 - acc: 0.6400 - val_loss: 1.0298 - val_acc: 0.6411\n","Epoch 21/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.0437 - acc: 0.6494 - val_loss: 1.0445 - val_acc: 0.6363\n","Epoch 22/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.0423 - acc: 0.6365 - val_loss: 1.0135 - val_acc: 0.6468\n","Epoch 23/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.0276 - acc: 0.6483 - val_loss: 1.0205 - val_acc: 0.6720\n","Epoch 24/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.0270 - acc: 0.6403 - val_loss: 0.9880 - val_acc: 0.6637\n","Epoch 25/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9979 - acc: 0.6471 - val_loss: 0.9908 - val_acc: 0.6657\n","Epoch 26/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 1.0082 - acc: 0.6474 - val_loss: 1.0560 - val_acc: 0.6474\n","Epoch 27/60\n","3497/3497 [==============================] - 37s 11ms/step - loss: 1.0025 - acc: 0.6546 - val_loss: 0.9634 - val_acc: 0.6814\n","Epoch 28/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9897 - acc: 0.6511 - val_loss: 0.9822 - val_acc: 0.6486\n","Epoch 29/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9804 - acc: 0.6640 - val_loss: 0.9718 - val_acc: 0.6566\n","Epoch 30/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9785 - acc: 0.6563 - val_loss: 0.9551 - val_acc: 0.6589\n","Epoch 31/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9675 - acc: 0.6686 - val_loss: 0.9278 - val_acc: 0.6883\n","Epoch 32/60\n","3497/3497 [==============================] - 36s 10ms/step - loss: 0.9593 - acc: 0.6663 - val_loss: 0.9326 - val_acc: 0.6852\n","Epoch 33/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9462 - acc: 0.6743 - val_loss: 0.9554 - val_acc: 0.6774\n","Epoch 34/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9538 - acc: 0.6760 - val_loss: 0.9497 - val_acc: 0.6634\n","Epoch 35/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9456 - acc: 0.6717 - val_loss: 0.9371 - val_acc: 0.6854\n","Epoch 36/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9336 - acc: 0.6760 - val_loss: 0.9703 - val_acc: 0.6420\n","Epoch 37/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9279 - acc: 0.6752 - val_loss: 0.9118 - val_acc: 0.6834\n","Epoch 38/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9192 - acc: 0.6857 - val_loss: 0.9270 - val_acc: 0.6714\n","Epoch 39/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9149 - acc: 0.6906 - val_loss: 0.9729 - val_acc: 0.6420\n","Epoch 40/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9149 - acc: 0.6749 - val_loss: 0.9131 - val_acc: 0.6774\n","Epoch 41/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9051 - acc: 0.6872 - val_loss: 0.9449 - val_acc: 0.6846\n","Epoch 42/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9060 - acc: 0.6854 - val_loss: 0.8848 - val_acc: 0.6940\n","Epoch 43/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.9082 - acc: 0.6843 - val_loss: 0.9036 - val_acc: 0.6777\n","Epoch 44/60\n","3497/3497 [==============================] - 37s 11ms/step - loss: 0.9009 - acc: 0.6877 - val_loss: 0.9042 - val_acc: 0.7109\n","Epoch 45/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8878 - acc: 0.6957 - val_loss: 0.9263 - val_acc: 0.6832\n","Epoch 46/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8749 - acc: 0.6992 - val_loss: 0.8529 - val_acc: 0.7149\n","Epoch 47/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8821 - acc: 0.6992 - val_loss: 0.8784 - val_acc: 0.6960\n","Epoch 48/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8647 - acc: 0.7052 - val_loss: 0.8494 - val_acc: 0.7123\n","Epoch 49/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8749 - acc: 0.7055 - val_loss: 0.8773 - val_acc: 0.7009\n","Epoch 50/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8649 - acc: 0.7046 - val_loss: 0.8580 - val_acc: 0.7126\n","Epoch 51/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8705 - acc: 0.6952 - val_loss: 0.8337 - val_acc: 0.7160\n","Epoch 52/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8522 - acc: 0.7052 - val_loss: 0.8813 - val_acc: 0.7089\n","Epoch 53/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8599 - acc: 0.7057 - val_loss: 0.8350 - val_acc: 0.7192\n","Epoch 54/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8435 - acc: 0.7098 - val_loss: 0.8510 - val_acc: 0.6937\n","Epoch 55/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8386 - acc: 0.7106 - val_loss: 0.8263 - val_acc: 0.7146\n","Epoch 56/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8493 - acc: 0.7080 - val_loss: 0.8299 - val_acc: 0.7266\n","Epoch 57/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8325 - acc: 0.7155 - val_loss: 0.8089 - val_acc: 0.7309\n","Epoch 58/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8406 - acc: 0.7152 - val_loss: 0.8275 - val_acc: 0.7200\n","Epoch 59/60\n","3497/3497 [==============================] - 37s 10ms/step - loss: 0.8334 - acc: 0.7152 - val_loss: 0.7913 - val_acc: 0.7412\n","Epoch 60/60\n","3497/3497 [==============================] - 35s 10ms/step - loss: 0.8224 - acc: 0.7169 - val_loss: 0.7923 - val_acc: 0.7275\n","Accuracy[0.6736] Recall[0.5772] F1[0.5927] at fold[9]\n","______________________________________________________\n","Mean Accuracy[0.6895] IC [0.6767, 0.7023]\n","Mean Recall[0.6126] IC [0.5979, 0.6274]\n","Mean F1[0.6204] IC [0.6064, 0.6343]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3wgqVJNdhc9P","colab_type":"code","outputId":"cb5199c7-2cb4-49c8-8d15-0eced6817f7d","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["RunWisdom('data/LOSO/WISDM.npz')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["6\n","(20846, 1, 100, 3)\n","(20846, 6)\n","(20846, 1, 250, 29)\n","(20167, 1, 250, 29)\n","(679, 1, 250, 29)\n","[11, 19, 27]\n","Start Training\n","Train on 20167 samples, validate on 20167 samples\n","Epoch 1/100\n","20167/20167 [==============================] - 175s 9ms/step - loss: 1.5223 - acc: 0.3451 - val_loss: 1.2309 - val_acc: 0.4439\n","Epoch 2/100\n","20167/20167 [==============================] - 174s 9ms/step - loss: 1.1885 - acc: 0.4568 - val_loss: 1.2280 - val_acc: 0.3475\n","Epoch 3/100\n","20167/20167 [==============================] - 170s 8ms/step - loss: 1.1205 - acc: 0.5000 - val_loss: 1.1111 - val_acc: 0.5158\n","Epoch 4/100\n","20167/20167 [==============================] - 169s 8ms/step - loss: 1.0325 - acc: 0.5568 - val_loss: 0.9566 - val_acc: 0.6247\n","Epoch 5/100\n","20167/20167 [==============================] - 170s 8ms/step - loss: 0.9438 - acc: 0.6316 - val_loss: 0.8675 - val_acc: 0.6743\n","Epoch 6/100\n","20167/20167 [==============================] - 171s 8ms/step - loss: 0.8581 - acc: 0.6606 - val_loss: 0.7915 - val_acc: 0.6905\n","Epoch 7/100\n","20167/20167 [==============================] - 173s 9ms/step - loss: 0.7739 - acc: 0.6934 - val_loss: 0.7037 - val_acc: 0.7222\n","Epoch 8/100\n","20167/20167 [==============================] - 168s 8ms/step - loss: 0.7535 - acc: 0.6991 - val_loss: 0.7526 - val_acc: 0.7055\n","Epoch 9/100\n","20167/20167 [==============================] - 164s 8ms/step - loss: 0.7071 - acc: 0.7181 - val_loss: 0.6676 - val_acc: 0.7430\n","Epoch 10/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.6823 - acc: 0.7327 - val_loss: 0.6545 - val_acc: 0.7465\n","Epoch 11/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.6992 - acc: 0.7307 - val_loss: 0.6439 - val_acc: 0.7516\n","Epoch 12/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.6285 - acc: 0.7572 - val_loss: 0.6185 - val_acc: 0.7624\n","Epoch 13/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.6490 - acc: 0.7490 - val_loss: 0.6715 - val_acc: 0.7302\n","Epoch 14/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.6216 - acc: 0.7582 - val_loss: 0.6141 - val_acc: 0.7619\n","Epoch 15/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.6185 - acc: 0.7575 - val_loss: 0.5975 - val_acc: 0.7642\n","Epoch 16/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.6101 - acc: 0.7591 - val_loss: 0.5976 - val_acc: 0.7603\n","Epoch 17/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.5914 - acc: 0.7682 - val_loss: 0.6616 - val_acc: 0.7393\n","Epoch 18/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.6041 - acc: 0.7635 - val_loss: 0.6087 - val_acc: 0.7605\n","Epoch 19/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.5917 - acc: 0.7651 - val_loss: 0.6251 - val_acc: 0.7555\n","Epoch 20/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.5961 - acc: 0.7646 - val_loss: 0.6605 - val_acc: 0.7457\n","Epoch 21/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.5887 - acc: 0.7679 - val_loss: 0.5723 - val_acc: 0.7730\n","Epoch 22/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.5710 - acc: 0.7733 - val_loss: 0.5620 - val_acc: 0.7694\n","Epoch 23/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.5738 - acc: 0.7718 - val_loss: 0.6003 - val_acc: 0.7630\n","Epoch 24/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.5701 - acc: 0.7749 - val_loss: 0.5724 - val_acc: 0.7752\n","Epoch 25/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.5652 - acc: 0.7746 - val_loss: 0.5553 - val_acc: 0.7724\n","Epoch 26/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.5684 - acc: 0.7756 - val_loss: 0.5363 - val_acc: 0.7794\n","Epoch 27/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.5359 - acc: 0.7854 - val_loss: 0.5414 - val_acc: 0.7809\n","Epoch 28/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.5473 - acc: 0.7827 - val_loss: 0.5433 - val_acc: 0.7806\n","Epoch 29/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.5431 - acc: 0.7858 - val_loss: 0.5386 - val_acc: 0.7806\n","Epoch 30/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.5303 - acc: 0.7867 - val_loss: 0.5382 - val_acc: 0.7892\n","Epoch 31/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.5338 - acc: 0.7884 - val_loss: 0.5586 - val_acc: 0.7807\n","Epoch 32/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.5325 - acc: 0.7873 - val_loss: 0.5409 - val_acc: 0.7920\n","Epoch 33/100\n","20167/20167 [==============================] - 161s 8ms/step - loss: 0.5294 - acc: 0.7913 - val_loss: 0.5235 - val_acc: 0.7923\n","Epoch 34/100\n","20167/20167 [==============================] - 161s 8ms/step - loss: 0.5224 - acc: 0.7917 - val_loss: 0.5189 - val_acc: 0.7901\n","Epoch 35/100\n","20167/20167 [==============================] - 161s 8ms/step - loss: 0.5220 - acc: 0.7922 - val_loss: 0.5040 - val_acc: 0.8030\n","Epoch 36/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.5209 - acc: 0.7922 - val_loss: 0.5114 - val_acc: 0.7918\n","Epoch 37/100\n","20167/20167 [==============================] - 161s 8ms/step - loss: 0.5020 - acc: 0.7987 - val_loss: 0.5246 - val_acc: 0.7874\n","Epoch 38/100\n","20167/20167 [==============================] - 161s 8ms/step - loss: 0.4949 - acc: 0.8016 - val_loss: 0.5016 - val_acc: 0.8086\n","Epoch 39/100\n","20167/20167 [==============================] - 160s 8ms/step - loss: 0.4977 - acc: 0.8021 - val_loss: 0.5268 - val_acc: 0.7912\n","Epoch 40/100\n","20167/20167 [==============================] - 160s 8ms/step - loss: 0.5137 - acc: 0.7963 - val_loss: 0.5352 - val_acc: 0.7906\n","Epoch 41/100\n","20167/20167 [==============================] - 161s 8ms/step - loss: 0.4917 - acc: 0.8024 - val_loss: 0.5132 - val_acc: 0.7907\n","Epoch 42/100\n","20167/20167 [==============================] - 161s 8ms/step - loss: 0.4936 - acc: 0.8030 - val_loss: 0.4914 - val_acc: 0.8027\n","Epoch 43/100\n","20167/20167 [==============================] - 161s 8ms/step - loss: 0.4845 - acc: 0.8051 - val_loss: 0.5176 - val_acc: 0.7981\n","Epoch 44/100\n","20167/20167 [==============================] - 161s 8ms/step - loss: 0.4998 - acc: 0.8009 - val_loss: 0.4868 - val_acc: 0.8033\n","Epoch 45/100\n","20167/20167 [==============================] - 161s 8ms/step - loss: 0.4822 - acc: 0.8086 - val_loss: 0.4773 - val_acc: 0.8157\n","Epoch 46/100\n","20167/20167 [==============================] - 161s 8ms/step - loss: 0.4629 - acc: 0.8156 - val_loss: 0.5022 - val_acc: 0.7975\n","Epoch 47/100\n","20167/20167 [==============================] - 161s 8ms/step - loss: 0.4828 - acc: 0.8081 - val_loss: 0.5184 - val_acc: 0.7856\n","Epoch 48/100\n","20167/20167 [==============================] - 160s 8ms/step - loss: 0.4709 - acc: 0.8119 - val_loss: 0.5262 - val_acc: 0.7853\n","Epoch 49/100\n","20167/20167 [==============================] - 160s 8ms/step - loss: 0.4628 - acc: 0.8145 - val_loss: 0.4881 - val_acc: 0.8094\n","Epoch 50/100\n","20167/20167 [==============================] - 160s 8ms/step - loss: 0.4703 - acc: 0.8129 - val_loss: 0.4524 - val_acc: 0.8141\n","Epoch 51/100\n","20167/20167 [==============================] - 160s 8ms/step - loss: 0.4591 - acc: 0.8149 - val_loss: 0.4728 - val_acc: 0.8090\n","Epoch 52/100\n","20167/20167 [==============================] - 160s 8ms/step - loss: 0.4697 - acc: 0.8124 - val_loss: 0.4526 - val_acc: 0.8134\n","Epoch 53/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4553 - acc: 0.8195 - val_loss: 0.4588 - val_acc: 0.8234\n","Epoch 54/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.4532 - acc: 0.8179 - val_loss: 0.4423 - val_acc: 0.8226\n","Epoch 55/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4525 - acc: 0.8199 - val_loss: 0.5018 - val_acc: 0.8002\n","Epoch 56/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4584 - acc: 0.8174 - val_loss: 0.4589 - val_acc: 0.8178\n","Epoch 57/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4590 - acc: 0.8177 - val_loss: 0.4522 - val_acc: 0.8185\n","Epoch 58/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4406 - acc: 0.8258 - val_loss: 0.4494 - val_acc: 0.8242\n","Epoch 59/100\n","20167/20167 [==============================] - 164s 8ms/step - loss: 0.4554 - acc: 0.8165 - val_loss: 0.4480 - val_acc: 0.8227\n","Epoch 60/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4434 - acc: 0.8229 - val_loss: 0.4981 - val_acc: 0.7964\n","Epoch 61/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4360 - acc: 0.8256 - val_loss: 0.4342 - val_acc: 0.8289\n","Epoch 62/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4310 - acc: 0.8268 - val_loss: 0.4322 - val_acc: 0.8287\n","Epoch 63/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4419 - acc: 0.8222 - val_loss: 0.4216 - val_acc: 0.8310\n","Epoch 64/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4369 - acc: 0.8238 - val_loss: 0.4498 - val_acc: 0.8153\n","Epoch 65/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4402 - acc: 0.8233 - val_loss: 0.4158 - val_acc: 0.8348\n","Epoch 66/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4341 - acc: 0.8253 - val_loss: 0.4270 - val_acc: 0.8278\n","Epoch 67/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4165 - acc: 0.8336 - val_loss: 0.4366 - val_acc: 0.8223\n","Epoch 68/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4405 - acc: 0.8241 - val_loss: 0.4161 - val_acc: 0.8356\n","Epoch 69/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.4133 - acc: 0.8346 - val_loss: 0.4103 - val_acc: 0.8341\n","Epoch 70/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.4229 - acc: 0.8315 - val_loss: 0.4370 - val_acc: 0.8227\n","Epoch 71/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.4188 - acc: 0.8323 - val_loss: 0.4256 - val_acc: 0.8279\n","Epoch 72/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4186 - acc: 0.8344 - val_loss: 0.4079 - val_acc: 0.8362\n","Epoch 73/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.4142 - acc: 0.8341 - val_loss: 0.4459 - val_acc: 0.8193\n","Epoch 74/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4169 - acc: 0.8323 - val_loss: 0.4733 - val_acc: 0.8111\n","Epoch 75/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.4175 - acc: 0.8337 - val_loss: 0.4147 - val_acc: 0.8292\n","Epoch 76/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4215 - acc: 0.8298 - val_loss: 0.4184 - val_acc: 0.8324\n","Epoch 77/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.3993 - acc: 0.8396 - val_loss: 0.4017 - val_acc: 0.8360\n","Epoch 78/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.4062 - acc: 0.8363 - val_loss: 0.4081 - val_acc: 0.8357\n","Epoch 79/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4054 - acc: 0.8375 - val_loss: 0.4120 - val_acc: 0.8301\n","Epoch 80/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4090 - acc: 0.8346 - val_loss: 0.4185 - val_acc: 0.8320\n","Epoch 81/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4032 - acc: 0.8383 - val_loss: 0.4276 - val_acc: 0.8264\n","Epoch 82/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4044 - acc: 0.8367 - val_loss: 0.4080 - val_acc: 0.8334\n","Epoch 83/100\n","20167/20167 [==============================] - 162s 8ms/step - loss: 0.4058 - acc: 0.8373 - val_loss: 0.3988 - val_acc: 0.8420\n","Epoch 84/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.3943 - acc: 0.8398 - val_loss: 0.4107 - val_acc: 0.8320\n","Epoch 85/100\n","20167/20167 [==============================] - 163s 8ms/step - loss: 0.4031 - acc: 0.8386 - val_loss: 0.4160 - val_acc: 0.8314\n","Epoch 86/100\n","20167/20167 [==============================] - 164s 8ms/step - loss: 0.3990 - acc: 0.8402 - val_loss: 0.4000 - val_acc: 0.8384\n","Epoch 87/100\n","20167/20167 [==============================] - 169s 8ms/step - loss: 0.3980 - acc: 0.8402 - val_loss: 0.4146 - val_acc: 0.8322\n","Epoch 88/100\n","20167/20167 [==============================] - 167s 8ms/step - loss: 0.3919 - acc: 0.8414 - val_loss: 0.4096 - val_acc: 0.8327\n","Epoch 89/100\n","20167/20167 [==============================] - 170s 8ms/step - loss: 0.3922 - acc: 0.8421 - val_loss: 0.3921 - val_acc: 0.8427\n","Epoch 90/100\n","20167/20167 [==============================] - 169s 8ms/step - loss: 0.3847 - acc: 0.8440 - val_loss: 0.4135 - val_acc: 0.8313\n","Epoch 91/100\n","20167/20167 [==============================] - 169s 8ms/step - loss: 0.3978 - acc: 0.8393 - val_loss: 0.3871 - val_acc: 0.8443\n","Epoch 92/100\n","20167/20167 [==============================] - 170s 8ms/step - loss: 0.3815 - acc: 0.8472 - val_loss: 0.3950 - val_acc: 0.8428\n","Epoch 93/100\n","20167/20167 [==============================] - 171s 8ms/step - loss: 0.3852 - acc: 0.8457 - val_loss: 0.3927 - val_acc: 0.8422\n","Epoch 94/100\n","20167/20167 [==============================] - 173s 9ms/step - loss: 0.3940 - acc: 0.8390 - val_loss: 0.3844 - val_acc: 0.8415\n","Epoch 95/100\n","20167/20167 [==============================] - 170s 8ms/step - loss: 0.3798 - acc: 0.8459 - val_loss: 0.3800 - val_acc: 0.8447\n","Epoch 96/100\n","20167/20167 [==============================] - 171s 8ms/step - loss: 0.3826 - acc: 0.8459 - val_loss: 0.4008 - val_acc: 0.8346\n","Epoch 97/100\n","20167/20167 [==============================] - 167s 8ms/step - loss: 0.3768 - acc: 0.8480 - val_loss: 0.3811 - val_acc: 0.8464\n","Epoch 98/100\n","20167/20167 [==============================] - 168s 8ms/step - loss: 0.3762 - acc: 0.8496 - val_loss: 0.4343 - val_acc: 0.8259\n","Epoch 99/100\n","20167/20167 [==============================] - 169s 8ms/step - loss: 0.3873 - acc: 0.8425 - val_loss: 0.3778 - val_acc: 0.8491\n","Epoch 100/100\n","20167/20167 [==============================] - 166s 8ms/step - loss: 0.3737 - acc: 0.8493 - val_loss: 0.3691 - val_acc: 0.8529\n","Accuracy[0.6922] Recall[0.5990] F1[0.5807] at fold[0]\n","______________________________________________________\n","Start Training\n","Train on 20465 samples, validate on 20465 samples\n","Epoch 1/100\n","20465/20465 [==============================] - 169s 8ms/step - loss: 1.4742 - acc: 0.3472 - val_loss: 1.2799 - val_acc: 0.4284\n","Epoch 2/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 1.2589 - acc: 0.4319 - val_loss: 1.2506 - val_acc: 0.4963\n","Epoch 3/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 1.2061 - acc: 0.4630 - val_loss: 1.1959 - val_acc: 0.3886\n","Epoch 4/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 1.1246 - acc: 0.5189 - val_loss: 1.0661 - val_acc: 0.5585\n","Epoch 5/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 1.0470 - acc: 0.5651 - val_loss: 0.9622 - val_acc: 0.6319\n","Epoch 6/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 0.9653 - acc: 0.6114 - val_loss: 0.9213 - val_acc: 0.6276\n","Epoch 7/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.8761 - acc: 0.6600 - val_loss: 0.7979 - val_acc: 0.6941\n","Epoch 8/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.8390 - acc: 0.6623 - val_loss: 0.9148 - val_acc: 0.6211\n","Epoch 9/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.8182 - acc: 0.6639 - val_loss: 0.7941 - val_acc: 0.6774\n","Epoch 10/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.7653 - acc: 0.6933 - val_loss: 0.6986 - val_acc: 0.7222\n","Epoch 11/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.7265 - acc: 0.7083 - val_loss: 0.6997 - val_acc: 0.7236\n","Epoch 12/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.7361 - acc: 0.7060 - val_loss: 0.6613 - val_acc: 0.7419\n","Epoch 13/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.6655 - acc: 0.7355 - val_loss: 0.8475 - val_acc: 0.6670\n","Epoch 14/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.6767 - acc: 0.7319 - val_loss: 0.6748 - val_acc: 0.7278\n","Epoch 15/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.6844 - acc: 0.7269 - val_loss: 0.6614 - val_acc: 0.7350\n","Epoch 16/100\n","20465/20465 [==============================] - 164s 8ms/step - loss: 0.6486 - acc: 0.7407 - val_loss: 0.6201 - val_acc: 0.7529\n","Epoch 17/100\n","20465/20465 [==============================] - 164s 8ms/step - loss: 0.6675 - acc: 0.7306 - val_loss: 0.6130 - val_acc: 0.7518\n","Epoch 18/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.6424 - acc: 0.7403 - val_loss: 0.6305 - val_acc: 0.7452\n","Epoch 19/100\n","20465/20465 [==============================] - 164s 8ms/step - loss: 0.6378 - acc: 0.7431 - val_loss: 0.6049 - val_acc: 0.7569\n","Epoch 20/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.6095 - acc: 0.7552 - val_loss: 0.6302 - val_acc: 0.7496\n","Epoch 21/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.6190 - acc: 0.7510 - val_loss: 0.6777 - val_acc: 0.7276\n","Epoch 22/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.6066 - acc: 0.7553 - val_loss: 0.6013 - val_acc: 0.7634\n","Epoch 23/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.6177 - acc: 0.7532 - val_loss: 0.5671 - val_acc: 0.7686\n","Epoch 24/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.6041 - acc: 0.7535 - val_loss: 0.5753 - val_acc: 0.7664\n","Epoch 25/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5928 - acc: 0.7609 - val_loss: 0.6199 - val_acc: 0.7525\n","Epoch 26/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5883 - acc: 0.7610 - val_loss: 0.5561 - val_acc: 0.7755\n","Epoch 27/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5823 - acc: 0.7650 - val_loss: 0.5821 - val_acc: 0.7643\n","Epoch 28/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5462 - acc: 0.7764 - val_loss: 0.5435 - val_acc: 0.7787\n","Epoch 29/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5747 - acc: 0.7667 - val_loss: 0.5704 - val_acc: 0.7662\n","Epoch 30/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5643 - acc: 0.7704 - val_loss: 0.5353 - val_acc: 0.7835\n","Epoch 31/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5786 - acc: 0.7654 - val_loss: 0.5291 - val_acc: 0.7835\n","Epoch 32/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5314 - acc: 0.7815 - val_loss: 0.5202 - val_acc: 0.7895\n","Epoch 33/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5484 - acc: 0.7772 - val_loss: 0.5174 - val_acc: 0.7859\n","Epoch 34/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5170 - acc: 0.7886 - val_loss: 0.5212 - val_acc: 0.7932\n","Epoch 35/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5161 - acc: 0.7922 - val_loss: 0.5291 - val_acc: 0.7828\n","Epoch 36/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5431 - acc: 0.7782 - val_loss: 0.5359 - val_acc: 0.7894\n","Epoch 37/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5099 - acc: 0.7925 - val_loss: 0.4975 - val_acc: 0.7928\n","Epoch 38/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5177 - acc: 0.7897 - val_loss: 0.5411 - val_acc: 0.7793\n","Epoch 39/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5210 - acc: 0.7901 - val_loss: 0.5181 - val_acc: 0.7954\n","Epoch 40/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5004 - acc: 0.7988 - val_loss: 0.5384 - val_acc: 0.7778\n","Epoch 41/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 0.5112 - acc: 0.7932 - val_loss: 0.5109 - val_acc: 0.7874\n","Epoch 42/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 0.4956 - acc: 0.8011 - val_loss: 0.4807 - val_acc: 0.8080\n","Epoch 43/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5056 - acc: 0.7974 - val_loss: 0.4870 - val_acc: 0.8040\n","Epoch 44/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.5021 - acc: 0.7996 - val_loss: 0.4931 - val_acc: 0.8083\n","Epoch 45/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4790 - acc: 0.8082 - val_loss: 0.4797 - val_acc: 0.8165\n","Epoch 46/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4897 - acc: 0.8046 - val_loss: 0.4926 - val_acc: 0.8020\n","Epoch 47/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4977 - acc: 0.8021 - val_loss: 0.4728 - val_acc: 0.8132\n","Epoch 48/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4857 - acc: 0.8049 - val_loss: 0.4846 - val_acc: 0.8035\n","Epoch 49/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 0.4965 - acc: 0.8003 - val_loss: 0.4641 - val_acc: 0.8165\n","Epoch 50/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4665 - acc: 0.8152 - val_loss: 0.5693 - val_acc: 0.7608\n","Epoch 51/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4841 - acc: 0.8058 - val_loss: 0.4575 - val_acc: 0.8139\n","Epoch 52/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4690 - acc: 0.8136 - val_loss: 0.4564 - val_acc: 0.8181\n","Epoch 53/100\n","20465/20465 [==============================] - 164s 8ms/step - loss: 0.4565 - acc: 0.8161 - val_loss: 0.4782 - val_acc: 0.8060\n","Epoch 54/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4756 - acc: 0.8096 - val_loss: 0.4564 - val_acc: 0.8137\n","Epoch 55/100\n","20465/20465 [==============================] - 164s 8ms/step - loss: 0.4726 - acc: 0.8112 - val_loss: 0.4788 - val_acc: 0.8115\n","Epoch 56/100\n","20465/20465 [==============================] - 163s 8ms/step - loss: 0.4656 - acc: 0.8151 - val_loss: 0.4473 - val_acc: 0.8215\n","Epoch 57/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4583 - acc: 0.8166 - val_loss: 0.4800 - val_acc: 0.8061\n","Epoch 58/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4649 - acc: 0.8140 - val_loss: 0.4444 - val_acc: 0.8225\n","Epoch 59/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 0.4593 - acc: 0.8171 - val_loss: 0.4438 - val_acc: 0.8271\n","Epoch 60/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 0.4422 - acc: 0.8233 - val_loss: 0.4649 - val_acc: 0.8109\n","Epoch 61/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 0.4548 - acc: 0.8191 - val_loss: 0.4542 - val_acc: 0.8139\n","Epoch 62/100\n","20465/20465 [==============================] - 170s 8ms/step - loss: 0.4412 - acc: 0.8238 - val_loss: 0.4465 - val_acc: 0.8240\n","Epoch 63/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 0.4470 - acc: 0.8219 - val_loss: 0.4410 - val_acc: 0.8241\n","Epoch 64/100\n","20465/20465 [==============================] - 167s 8ms/step - loss: 0.4487 - acc: 0.8217 - val_loss: 0.4357 - val_acc: 0.8236\n","Epoch 65/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 0.4467 - acc: 0.8200 - val_loss: 0.4526 - val_acc: 0.8237\n","Epoch 66/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 0.4377 - acc: 0.8250 - val_loss: 0.4445 - val_acc: 0.8218\n","Epoch 67/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 0.4482 - acc: 0.8214 - val_loss: 0.4803 - val_acc: 0.8065\n","Epoch 68/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 0.4340 - acc: 0.8260 - val_loss: 0.4256 - val_acc: 0.8269\n","Epoch 69/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 0.4468 - acc: 0.8208 - val_loss: 0.4249 - val_acc: 0.8310\n","Epoch 70/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4333 - acc: 0.8275 - val_loss: 0.4404 - val_acc: 0.8267\n","Epoch 71/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4367 - acc: 0.8268 - val_loss: 0.4274 - val_acc: 0.8262\n","Epoch 72/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4281 - acc: 0.8300 - val_loss: 0.4271 - val_acc: 0.8281\n","Epoch 73/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4307 - acc: 0.8255 - val_loss: 0.4402 - val_acc: 0.8263\n","Epoch 74/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4318 - acc: 0.8267 - val_loss: 0.4556 - val_acc: 0.8200\n","Epoch 75/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4324 - acc: 0.8257 - val_loss: 0.4562 - val_acc: 0.8151\n","Epoch 76/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 0.4338 - acc: 0.8275 - val_loss: 0.4244 - val_acc: 0.8291\n","Epoch 77/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4274 - acc: 0.8286 - val_loss: 0.4319 - val_acc: 0.8234\n","Epoch 78/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4256 - acc: 0.8283 - val_loss: 0.4143 - val_acc: 0.8364\n","Epoch 79/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4226 - acc: 0.8307 - val_loss: 0.4153 - val_acc: 0.8309\n","Epoch 80/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4321 - acc: 0.8282 - val_loss: 0.4132 - val_acc: 0.8331\n","Epoch 81/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4197 - acc: 0.8313 - val_loss: 0.4205 - val_acc: 0.8321\n","Epoch 82/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4146 - acc: 0.8353 - val_loss: 0.4238 - val_acc: 0.8282\n","Epoch 83/100\n","20465/20465 [==============================] - 165s 8ms/step - loss: 0.4413 - acc: 0.8247 - val_loss: 0.4049 - val_acc: 0.8383\n","Epoch 84/100\n","20465/20465 [==============================] - 166s 8ms/step - loss: 0.4067 - acc: 0.8371 - val_loss: 0.4028 - val_acc: 0.8394\n","Epoch 85/100\n","20465/20465 [==============================] - 167s 8ms/step - loss: 0.4159 - acc: 0.8324 - val_loss: 0.4032 - val_acc: 0.8387\n","Epoch 86/100\n","20465/20465 [==============================] - 168s 8ms/step - loss: 0.4067 - acc: 0.8371 - val_loss: 0.4055 - val_acc: 0.8348\n","Epoch 87/100\n","20465/20465 [==============================] - 169s 8ms/step - loss: 0.4105 - acc: 0.8346 - val_loss: 0.4032 - val_acc: 0.8366\n","Epoch 88/100\n","20465/20465 [==============================] - 169s 8ms/step - loss: 0.4138 - acc: 0.8346 - val_loss: 0.3990 - val_acc: 0.8408\n","Epoch 89/100\n","20465/20465 [==============================] - 173s 8ms/step - loss: 0.4019 - acc: 0.8388 - val_loss: 0.4137 - val_acc: 0.8352\n","Epoch 90/100\n","20465/20465 [==============================] - 173s 8ms/step - loss: 0.4078 - acc: 0.8363 - val_loss: 0.4159 - val_acc: 0.8305\n","Epoch 91/100\n","20465/20465 [==============================] - 173s 8ms/step - loss: 0.4135 - acc: 0.8333 - val_loss: 0.3965 - val_acc: 0.8406\n","Epoch 92/100\n","20465/20465 [==============================] - 173s 8ms/step - loss: 0.4118 - acc: 0.8343 - val_loss: 0.3953 - val_acc: 0.8402\n","Epoch 93/100\n","20465/20465 [==============================] - 173s 8ms/step - loss: 0.4088 - acc: 0.8357 - val_loss: 0.4048 - val_acc: 0.8383\n","Epoch 94/100\n","20465/20465 [==============================] - 174s 8ms/step - loss: 0.4036 - acc: 0.8367 - val_loss: 0.4078 - val_acc: 0.8388\n","Epoch 95/100\n","20465/20465 [==============================] - 174s 8ms/step - loss: 0.3971 - acc: 0.8394 - val_loss: 0.4251 - val_acc: 0.8323\n","Epoch 96/100\n","20465/20465 [==============================] - 174s 8ms/step - loss: 0.4057 - acc: 0.8369 - val_loss: 0.3912 - val_acc: 0.8429\n","Epoch 97/100\n","20465/20465 [==============================] - 174s 9ms/step - loss: 0.3994 - acc: 0.8401 - val_loss: 0.3938 - val_acc: 0.8409\n","Epoch 98/100\n","20465/20465 [==============================] - 174s 8ms/step - loss: 0.4001 - acc: 0.8383 - val_loss: 0.4074 - val_acc: 0.8328\n","Epoch 99/100\n","20465/20465 [==============================] - 175s 9ms/step - loss: 0.3978 - acc: 0.8385 - val_loss: 0.3842 - val_acc: 0.8451\n","Epoch 100/100\n","20465/20465 [==============================] - 176s 9ms/step - loss: 0.3892 - acc: 0.8426 - val_loss: 0.3929 - val_acc: 0.8380\n","Accuracy[0.4934] Recall[0.2882] F1[0.3199] at fold[1]\n","______________________________________________________\n","Start Training\n","Train on 20215 samples, validate on 20215 samples\n","Epoch 1/100\n","20215/20215 [==============================] - 176s 9ms/step - loss: 1.4702 - acc: 0.3867 - val_loss: 1.3109 - val_acc: 0.4205\n","Epoch 2/100\n","20215/20215 [==============================] - 175s 9ms/step - loss: 1.2683 - acc: 0.4657 - val_loss: 1.2663 - val_acc: 0.3517\n","Epoch 3/100\n","20215/20215 [==============================] - 178s 9ms/step - loss: 1.1645 - acc: 0.5348 - val_loss: 1.0729 - val_acc: 0.6024\n","Epoch 4/100\n","20215/20215 [==============================] - 174s 9ms/step - loss: 1.0471 - acc: 0.5833 - val_loss: 1.0499 - val_acc: 0.5710\n","Epoch 5/100\n","20215/20215 [==============================] - 174s 9ms/step - loss: 0.9643 - acc: 0.6098 - val_loss: 0.8488 - val_acc: 0.6711\n","Epoch 6/100\n","20215/20215 [==============================] - 173s 9ms/step - loss: 0.8471 - acc: 0.6835 - val_loss: 0.8662 - val_acc: 0.6813\n","Epoch 7/100\n","20215/20215 [==============================] - 173s 9ms/step - loss: 0.7875 - acc: 0.6978 - val_loss: 0.7861 - val_acc: 0.6925\n","Epoch 8/100\n","20215/20215 [==============================] - 174s 9ms/step - loss: 0.7434 - acc: 0.7097 - val_loss: 0.6991 - val_acc: 0.7223\n","Epoch 9/100\n","20215/20215 [==============================] - 174s 9ms/step - loss: 0.7164 - acc: 0.7183 - val_loss: 0.8165 - val_acc: 0.6665\n","Epoch 10/100\n","20215/20215 [==============================] - 173s 9ms/step - loss: 0.6953 - acc: 0.7204 - val_loss: 0.6816 - val_acc: 0.7345\n","Epoch 11/100\n","20215/20215 [==============================] - 171s 8ms/step - loss: 0.6666 - acc: 0.7310 - val_loss: 0.6580 - val_acc: 0.7412\n","Epoch 12/100\n","20215/20215 [==============================] - 169s 8ms/step - loss: 0.6506 - acc: 0.7364 - val_loss: 0.6250 - val_acc: 0.7468\n","Epoch 13/100\n","20215/20215 [==============================] - 168s 8ms/step - loss: 0.6365 - acc: 0.7439 - val_loss: 0.7193 - val_acc: 0.7190\n","Epoch 14/100\n","20215/20215 [==============================] - 168s 8ms/step - loss: 0.6319 - acc: 0.7450 - val_loss: 0.6385 - val_acc: 0.7418\n","Epoch 15/100\n","20215/20215 [==============================] - 167s 8ms/step - loss: 0.6181 - acc: 0.7494 - val_loss: 0.6167 - val_acc: 0.7508\n","Epoch 16/100\n","20215/20215 [==============================] - 167s 8ms/step - loss: 0.6222 - acc: 0.7504 - val_loss: 0.6069 - val_acc: 0.7542\n","Epoch 17/100\n","20215/20215 [==============================] - 170s 8ms/step - loss: 0.6163 - acc: 0.7514 - val_loss: 0.6155 - val_acc: 0.7461\n","Epoch 18/100\n","13000/20215 [==================>...........] - ETA: 37s - loss: 0.6107 - acc: 0.7543"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WpEGQ6F3lFVs","colab_type":"code","outputId":"2110baf3-9fdf-4b2d-fe6c-66ce3378c987","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["RunWisdom('data/LOTO/WISDM.npz')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["6\n","(20846, 1, 100, 3)\n","(20846, 6)\n","(20846, 1, 250, 29)\n","(18393, 1, 250, 29)\n","(2453, 1, 250, 29)\n","[11, 19, 27]\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","Start Training\n","Train on 18393 samples, validate on 18393 samples\n","Epoch 1/60\n","18393/18393 [==============================] - 150s 8ms/step - loss: 1.5524 - acc: 0.3272 - val_loss: 1.2477 - val_acc: 0.4261\n","Epoch 2/60\n","18393/18393 [==============================] - 149s 8ms/step - loss: 1.2010 - acc: 0.4466 - val_loss: 1.1513 - val_acc: 0.4627\n","Epoch 3/60\n","18393/18393 [==============================] - 148s 8ms/step - loss: 1.1527 - acc: 0.4715 - val_loss: 1.1037 - val_acc: 0.5284\n","Epoch 4/60\n","18393/18393 [==============================] - 148s 8ms/step - loss: 1.0850 - acc: 0.5110 - val_loss: 0.9811 - val_acc: 0.6024\n","Epoch 5/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 1.0123 - acc: 0.5763 - val_loss: 0.9462 - val_acc: 0.6598\n","Epoch 6/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.9238 - acc: 0.6391 - val_loss: 0.8885 - val_acc: 0.6351\n","Epoch 7/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.8701 - acc: 0.6476 - val_loss: 0.8442 - val_acc: 0.6611\n","Epoch 8/60\n","18393/18393 [==============================] - 146s 8ms/step - loss: 0.8152 - acc: 0.6664 - val_loss: 0.8101 - val_acc: 0.6669\n","Epoch 9/60\n","18393/18393 [==============================] - 148s 8ms/step - loss: 0.7494 - acc: 0.6970 - val_loss: 0.8577 - val_acc: 0.6438\n","Epoch 10/60\n","18393/18393 [==============================] - 148s 8ms/step - loss: 0.7410 - acc: 0.7009 - val_loss: 0.6756 - val_acc: 0.7309\n","Epoch 11/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.7281 - acc: 0.7085 - val_loss: 0.6794 - val_acc: 0.7323\n","Epoch 12/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.6682 - acc: 0.7369 - val_loss: 0.7519 - val_acc: 0.6970\n","Epoch 13/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.6901 - acc: 0.7263 - val_loss: 0.6493 - val_acc: 0.7441\n","Epoch 14/60\n","18393/18393 [==============================] - 146s 8ms/step - loss: 0.6565 - acc: 0.7436 - val_loss: 0.6664 - val_acc: 0.7297\n","Epoch 15/60\n","18393/18393 [==============================] - 146s 8ms/step - loss: 0.6605 - acc: 0.7370 - val_loss: 0.6894 - val_acc: 0.7207\n","Epoch 16/60\n","18393/18393 [==============================] - 146s 8ms/step - loss: 0.6541 - acc: 0.7385 - val_loss: 0.6419 - val_acc: 0.7412\n","Epoch 17/60\n","18393/18393 [==============================] - 146s 8ms/step - loss: 0.6425 - acc: 0.7380 - val_loss: 0.6180 - val_acc: 0.7505\n","Epoch 18/60\n","18393/18393 [==============================] - 146s 8ms/step - loss: 0.6296 - acc: 0.7460 - val_loss: 0.6075 - val_acc: 0.7570\n","Epoch 19/60\n","18393/18393 [==============================] - 146s 8ms/step - loss: 0.6285 - acc: 0.7468 - val_loss: 0.7174 - val_acc: 0.7049\n","Epoch 20/60\n","18393/18393 [==============================] - 146s 8ms/step - loss: 0.6216 - acc: 0.7457 - val_loss: 0.6271 - val_acc: 0.7480\n","Epoch 21/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.6017 - acc: 0.7529 - val_loss: 0.6525 - val_acc: 0.7459\n","Epoch 22/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.6101 - acc: 0.7532 - val_loss: 0.5885 - val_acc: 0.7592\n","Epoch 23/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.5935 - acc: 0.7583 - val_loss: 0.5940 - val_acc: 0.7598\n","Epoch 24/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.6119 - acc: 0.7511 - val_loss: 0.5921 - val_acc: 0.7538\n","Epoch 25/60\n","18393/18393 [==============================] - 148s 8ms/step - loss: 0.5816 - acc: 0.7602 - val_loss: 0.6075 - val_acc: 0.7584\n","Epoch 26/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.5796 - acc: 0.7627 - val_loss: 0.5791 - val_acc: 0.7640\n","Epoch 27/60\n","18393/18393 [==============================] - 148s 8ms/step - loss: 0.6025 - acc: 0.7589 - val_loss: 0.5754 - val_acc: 0.7657\n","Epoch 28/60\n","18393/18393 [==============================] - 148s 8ms/step - loss: 0.5684 - acc: 0.7681 - val_loss: 0.5846 - val_acc: 0.7621\n","Epoch 29/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.5727 - acc: 0.7678 - val_loss: 0.6352 - val_acc: 0.7346\n","Epoch 30/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.5690 - acc: 0.7667 - val_loss: 0.5711 - val_acc: 0.7680\n","Epoch 31/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.5501 - acc: 0.7776 - val_loss: 0.5544 - val_acc: 0.7745\n","Epoch 32/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.5494 - acc: 0.7771 - val_loss: 0.5509 - val_acc: 0.7756\n","Epoch 33/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.5634 - acc: 0.7726 - val_loss: 0.5479 - val_acc: 0.7814\n","Epoch 34/60\n","18393/18393 [==============================] - 148s 8ms/step - loss: 0.5524 - acc: 0.7790 - val_loss: 0.5335 - val_acc: 0.7808\n","Epoch 35/60\n","18393/18393 [==============================] - 148s 8ms/step - loss: 0.5315 - acc: 0.7814 - val_loss: 0.5574 - val_acc: 0.7784\n","Epoch 36/60\n","18393/18393 [==============================] - 149s 8ms/step - loss: 0.5377 - acc: 0.7831 - val_loss: 0.5814 - val_acc: 0.7701\n","Epoch 37/60\n","18393/18393 [==============================] - 149s 8ms/step - loss: 0.5503 - acc: 0.7780 - val_loss: 0.5331 - val_acc: 0.7883\n","Epoch 38/60\n","18393/18393 [==============================] - 149s 8ms/step - loss: 0.5343 - acc: 0.7839 - val_loss: 0.5758 - val_acc: 0.7665\n","Epoch 39/60\n","18393/18393 [==============================] - 149s 8ms/step - loss: 0.5342 - acc: 0.7829 - val_loss: 0.5063 - val_acc: 0.7967\n","Epoch 40/60\n","18393/18393 [==============================] - 148s 8ms/step - loss: 0.5266 - acc: 0.7857 - val_loss: 0.5632 - val_acc: 0.7761\n","Epoch 41/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.5263 - acc: 0.7857 - val_loss: 0.5638 - val_acc: 0.7708\n","Epoch 42/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.5293 - acc: 0.7866 - val_loss: 0.4989 - val_acc: 0.7927\n","Epoch 43/60\n","18393/18393 [==============================] - 148s 8ms/step - loss: 0.5031 - acc: 0.7966 - val_loss: 0.5742 - val_acc: 0.7676\n","Epoch 44/60\n","18393/18393 [==============================] - 149s 8ms/step - loss: 0.5039 - acc: 0.7943 - val_loss: 0.4877 - val_acc: 0.7989\n","Epoch 45/60\n","18393/18393 [==============================] - 148s 8ms/step - loss: 0.4948 - acc: 0.7985 - val_loss: 0.5001 - val_acc: 0.8035\n","Epoch 46/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.5074 - acc: 0.7946 - val_loss: 0.5073 - val_acc: 0.7903\n","Epoch 47/60\n","18393/18393 [==============================] - 148s 8ms/step - loss: 0.5107 - acc: 0.7934 - val_loss: 0.4750 - val_acc: 0.8079\n","Epoch 48/60\n","18393/18393 [==============================] - 148s 8ms/step - loss: 0.4922 - acc: 0.8003 - val_loss: 0.4930 - val_acc: 0.8005\n","Epoch 49/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.4937 - acc: 0.7987 - val_loss: 0.4735 - val_acc: 0.8012\n","Epoch 50/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.4810 - acc: 0.8064 - val_loss: 0.4892 - val_acc: 0.7981\n","Epoch 51/60\n","18393/18393 [==============================] - 146s 8ms/step - loss: 0.4745 - acc: 0.8052 - val_loss: 0.4940 - val_acc: 0.7950\n","Epoch 52/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.4859 - acc: 0.8037 - val_loss: 0.4611 - val_acc: 0.8149\n","Epoch 53/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.4750 - acc: 0.8089 - val_loss: 0.4901 - val_acc: 0.7968\n","Epoch 54/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.4727 - acc: 0.8066 - val_loss: 0.4525 - val_acc: 0.8131\n","Epoch 55/60\n","18393/18393 [==============================] - 146s 8ms/step - loss: 0.4691 - acc: 0.8081 - val_loss: 0.4612 - val_acc: 0.8129\n","Epoch 56/60\n","18393/18393 [==============================] - 146s 8ms/step - loss: 0.4614 - acc: 0.8124 - val_loss: 0.4773 - val_acc: 0.8028\n","Epoch 57/60\n","18393/18393 [==============================] - 146s 8ms/step - loss: 0.4819 - acc: 0.8051 - val_loss: 0.4543 - val_acc: 0.8202\n","Epoch 58/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.4474 - acc: 0.8178 - val_loss: 0.4817 - val_acc: 0.8006\n","Epoch 59/60\n","18393/18393 [==============================] - 147s 8ms/step - loss: 0.4470 - acc: 0.8178 - val_loss: 0.4472 - val_acc: 0.8148\n","Epoch 60/60\n","18393/18393 [==============================] - 146s 8ms/step - loss: 0.4559 - acc: 0.8131 - val_loss: 0.4532 - val_acc: 0.8089\n","Accuracy[0.8463] Recall[0.7011] F1[0.7124] at fold[0]\n","______________________________________________________\n","Start Training\n","Train on 18866 samples, validate on 18866 samples\n","Epoch 1/60\n","18866/18866 [==============================] - 150s 8ms/step - loss: 1.3706 - acc: 0.3652 - val_loss: 1.2608 - val_acc: 0.5338\n","Epoch 2/60\n","18866/18866 [==============================] - 149s 8ms/step - loss: 1.2086 - acc: 0.4969 - val_loss: 1.1787 - val_acc: 0.5373\n","Epoch 3/60\n","18866/18866 [==============================] - 150s 8ms/step - loss: 1.1424 - acc: 0.5060 - val_loss: 1.1057 - val_acc: 0.4876\n","Epoch 4/60\n","18866/18866 [==============================] - 149s 8ms/step - loss: 1.0584 - acc: 0.5510 - val_loss: 1.0088 - val_acc: 0.5757\n","Epoch 5/60\n","18866/18866 [==============================] - 150s 8ms/step - loss: 0.9984 - acc: 0.6014 - val_loss: 0.9714 - val_acc: 0.6321\n","Epoch 6/60\n","18866/18866 [==============================] - 149s 8ms/step - loss: 0.9170 - acc: 0.6581 - val_loss: 0.8071 - val_acc: 0.7170\n","Epoch 7/60\n","18866/18866 [==============================] - 150s 8ms/step - loss: 0.8445 - acc: 0.6782 - val_loss: 0.7608 - val_acc: 0.7137\n","Epoch 8/60\n","18866/18866 [==============================] - 151s 8ms/step - loss: 0.8008 - acc: 0.6845 - val_loss: 0.7351 - val_acc: 0.7166\n","Epoch 9/60\n","18866/18866 [==============================] - 150s 8ms/step - loss: 0.8024 - acc: 0.6790 - val_loss: 0.6979 - val_acc: 0.7254\n","Epoch 10/60\n","18866/18866 [==============================] - 150s 8ms/step - loss: 0.7161 - acc: 0.7114 - val_loss: 0.6867 - val_acc: 0.7315\n","Epoch 11/60\n","18866/18866 [==============================] - 150s 8ms/step - loss: 0.7293 - acc: 0.7049 - val_loss: 0.6715 - val_acc: 0.7300\n","Epoch 12/60\n","18866/18866 [==============================] - 149s 8ms/step - loss: 0.7009 - acc: 0.7149 - val_loss: 0.6469 - val_acc: 0.7455\n","Epoch 13/60\n","18866/18866 [==============================] - 150s 8ms/step - loss: 0.6807 - acc: 0.7277 - val_loss: 0.6336 - val_acc: 0.7446\n","Epoch 14/60\n","18866/18866 [==============================] - 151s 8ms/step - loss: 0.6638 - acc: 0.7329 - val_loss: 0.6157 - val_acc: 0.7541\n","Epoch 15/60\n","18866/18866 [==============================] - 150s 8ms/step - loss: 0.6276 - acc: 0.7480 - val_loss: 0.6502 - val_acc: 0.7331\n","Epoch 16/60\n","18866/18866 [==============================] - 150s 8ms/step - loss: 0.6385 - acc: 0.7436 - val_loss: 0.6264 - val_acc: 0.7527\n","Epoch 17/60\n","18866/18866 [==============================] - 150s 8ms/step - loss: 0.6225 - acc: 0.7490 - val_loss: 0.6000 - val_acc: 0.7550\n","Epoch 18/60\n","18866/18866 [==============================] - 149s 8ms/step - loss: 0.6314 - acc: 0.7461 - val_loss: 0.5827 - val_acc: 0.7585\n","Epoch 19/60\n","18866/18866 [==============================] - 150s 8ms/step - loss: 0.6153 - acc: 0.7481 - val_loss: 0.6138 - val_acc: 0.7509\n","Epoch 20/60\n","18866/18866 [==============================] - 150s 8ms/step - loss: 0.5985 - acc: 0.7592 - val_loss: 0.6034 - val_acc: 0.7586\n","Epoch 21/60\n","18866/18866 [==============================] - 149s 8ms/step - loss: 0.5957 - acc: 0.7597 - val_loss: 0.5563 - val_acc: 0.7727\n","Epoch 22/60\n","18866/18866 [==============================] - 149s 8ms/step - loss: 0.5803 - acc: 0.7631 - val_loss: 0.5897 - val_acc: 0.7496\n","Epoch 23/60\n","18866/18866 [==============================] - 149s 8ms/step - loss: 0.5702 - acc: 0.7685 - val_loss: 0.5585 - val_acc: 0.7733\n","Epoch 24/60\n","18866/18866 [==============================] - 148s 8ms/step - loss: 0.5597 - acc: 0.7696 - val_loss: 0.5994 - val_acc: 0.7604\n","Epoch 25/60\n","18866/18866 [==============================] - 148s 8ms/step - loss: 0.5644 - acc: 0.7704 - val_loss: 0.5402 - val_acc: 0.7738\n","Epoch 26/60\n","18866/18866 [==============================] - 148s 8ms/step - loss: 0.5652 - acc: 0.7691 - val_loss: 0.5444 - val_acc: 0.7860\n","Epoch 27/60\n","18866/18866 [==============================] - 149s 8ms/step - loss: 0.5401 - acc: 0.7776 - val_loss: 0.5210 - val_acc: 0.7835\n","Epoch 28/60\n","18866/18866 [==============================] - 149s 8ms/step - loss: 0.5424 - acc: 0.7766 - val_loss: 0.5347 - val_acc: 0.7704\n","Epoch 29/60\n","18866/18866 [==============================] - 150s 8ms/step - loss: 0.5432 - acc: 0.7783 - val_loss: 0.5372 - val_acc: 0.7875\n","Epoch 30/60\n","18866/18866 [==============================] - 150s 8ms/step - loss: 0.5298 - acc: 0.7850 - val_loss: 0.5329 - val_acc: 0.7779\n","Epoch 31/60\n","18866/18866 [==============================] - 152s 8ms/step - loss: 0.5339 - acc: 0.7846 - val_loss: 0.5259 - val_acc: 0.7924\n","Epoch 32/60\n","18866/18866 [==============================] - 152s 8ms/step - loss: 0.5194 - acc: 0.7860 - val_loss: 0.5483 - val_acc: 0.7801\n","Epoch 33/60\n","18866/18866 [==============================] - 152s 8ms/step - loss: 0.5400 - acc: 0.7815 - val_loss: 0.4927 - val_acc: 0.7998\n","Epoch 34/60\n","18866/18866 [==============================] - 152s 8ms/step - loss: 0.5085 - acc: 0.7921 - val_loss: 0.5131 - val_acc: 0.7930\n","Epoch 35/60\n","18866/18866 [==============================] - 152s 8ms/step - loss: 0.5135 - acc: 0.7897 - val_loss: 0.5510 - val_acc: 0.7762\n","Epoch 36/60\n","18866/18866 [==============================] - 153s 8ms/step - loss: 0.5050 - acc: 0.7930 - val_loss: 0.5266 - val_acc: 0.7894\n","Epoch 37/60\n","18866/18866 [==============================] - 153s 8ms/step - loss: 0.5102 - acc: 0.7921 - val_loss: 0.5000 - val_acc: 0.7918\n","Epoch 38/60\n","18866/18866 [==============================] - 154s 8ms/step - loss: 0.5150 - acc: 0.7898 - val_loss: 0.5363 - val_acc: 0.7816\n","Epoch 39/60\n","18866/18866 [==============================] - 154s 8ms/step - loss: 0.4791 - acc: 0.8030 - val_loss: 0.4903 - val_acc: 0.7962\n","Epoch 40/60\n","18866/18866 [==============================] - 154s 8ms/step - loss: 0.5097 - acc: 0.7917 - val_loss: 0.4799 - val_acc: 0.8111\n","Epoch 41/60\n","18866/18866 [==============================] - 154s 8ms/step - loss: 0.4805 - acc: 0.8037 - val_loss: 0.5142 - val_acc: 0.7935\n","Epoch 42/60\n","18866/18866 [==============================] - 153s 8ms/step - loss: 0.4936 - acc: 0.7992 - val_loss: 0.4858 - val_acc: 0.7941\n","Epoch 43/60\n","18866/18866 [==============================] - 153s 8ms/step - loss: 0.4814 - acc: 0.8034 - val_loss: 0.4523 - val_acc: 0.8165\n","Epoch 44/60\n","18866/18866 [==============================] - 153s 8ms/step - loss: 0.4786 - acc: 0.8036 - val_loss: 0.4765 - val_acc: 0.8114\n","Epoch 45/60\n","18866/18866 [==============================] - 153s 8ms/step - loss: 0.4588 - acc: 0.8136 - val_loss: 0.5035 - val_acc: 0.7898\n","Epoch 46/60\n","18866/18866 [==============================] - 153s 8ms/step - loss: 0.4872 - acc: 0.8030 - val_loss: 0.4599 - val_acc: 0.8071\n","Epoch 47/60\n","18866/18866 [==============================] - 154s 8ms/step - loss: 0.4539 - acc: 0.8141 - val_loss: 0.4958 - val_acc: 0.7932\n","Epoch 48/60\n","18866/18866 [==============================] - 155s 8ms/step - loss: 0.4658 - acc: 0.8090 - val_loss: 0.4357 - val_acc: 0.8219\n","Epoch 49/60\n","18866/18866 [==============================] - 155s 8ms/step - loss: 0.4571 - acc: 0.8118 - val_loss: 0.4659 - val_acc: 0.8161\n","Epoch 50/60\n","18866/18866 [==============================] - 157s 8ms/step - loss: 0.4560 - acc: 0.8144 - val_loss: 0.4319 - val_acc: 0.8251\n","Epoch 51/60\n","18866/18866 [==============================] - 160s 9ms/step - loss: 0.4601 - acc: 0.8111 - val_loss: 0.4838 - val_acc: 0.7970\n","Epoch 52/60\n","18866/18866 [==============================] - 159s 8ms/step - loss: 0.4422 - acc: 0.8163 - val_loss: 0.4432 - val_acc: 0.8230\n","Epoch 53/60\n","18866/18866 [==============================] - 157s 8ms/step - loss: 0.4426 - acc: 0.8174 - val_loss: 0.4241 - val_acc: 0.8261\n","Epoch 54/60\n","18866/18866 [==============================] - 158s 8ms/step - loss: 0.4517 - acc: 0.8140 - val_loss: 0.4233 - val_acc: 0.8289\n","Epoch 55/60\n","18866/18866 [==============================] - 159s 8ms/step - loss: 0.4231 - acc: 0.8276 - val_loss: 0.4463 - val_acc: 0.8105\n","Epoch 56/60\n","18866/18866 [==============================] - 158s 8ms/step - loss: 0.4532 - acc: 0.8147 - val_loss: 0.4299 - val_acc: 0.8282\n","Epoch 57/60\n","18866/18866 [==============================] - 159s 8ms/step - loss: 0.4262 - acc: 0.8238 - val_loss: 0.4197 - val_acc: 0.8248\n","Epoch 58/60\n","18866/18866 [==============================] - 159s 8ms/step - loss: 0.4415 - acc: 0.8189 - val_loss: 0.4166 - val_acc: 0.8321\n","Epoch 59/60\n","18866/18866 [==============================] - 159s 8ms/step - loss: 0.4312 - acc: 0.8235 - val_loss: 0.4192 - val_acc: 0.8238\n","Epoch 60/60\n","18866/18866 [==============================] - 158s 8ms/step - loss: 0.4191 - acc: 0.8267 - val_loss: 0.4195 - val_acc: 0.8299\n","Accuracy[0.7914] Recall[0.6937] F1[0.6849] at fold[1]\n","______________________________________________________\n","Start Training\n","Train on 18169 samples, validate on 18169 samples\n","Epoch 1/60\n","18169/18169 [==============================] - 151s 8ms/step - loss: 1.5722 - acc: 0.3039 - val_loss: 1.2992 - val_acc: 0.4183\n","Epoch 2/60\n","18169/18169 [==============================] - 152s 8ms/step - loss: 1.2561 - acc: 0.4239 - val_loss: 1.2110 - val_acc: 0.4407\n","Epoch 3/60\n","18169/18169 [==============================] - 152s 8ms/step - loss: 1.1733 - acc: 0.4652 - val_loss: 1.1798 - val_acc: 0.3975\n","Epoch 4/60\n","18169/18169 [==============================] - 149s 8ms/step - loss: 1.0926 - acc: 0.5398 - val_loss: 1.0235 - val_acc: 0.5776\n","Epoch 5/60\n","18169/18169 [==============================] - 148s 8ms/step - loss: 1.0268 - acc: 0.5794 - val_loss: 1.0048 - val_acc: 0.6101\n","Epoch 6/60\n","18169/18169 [==============================] - 147s 8ms/step - loss: 0.9497 - acc: 0.6260 - val_loss: 0.8851 - val_acc: 0.6820\n","Epoch 7/60\n","18169/18169 [==============================] - 147s 8ms/step - loss: 0.8650 - acc: 0.6746 - val_loss: 0.8074 - val_acc: 0.6947\n","Epoch 8/60\n","18169/18169 [==============================] - 147s 8ms/step - loss: 0.8299 - acc: 0.6765 - val_loss: 0.7180 - val_acc: 0.7383\n","Epoch 9/60\n","18169/18169 [==============================] - 147s 8ms/step - loss: 0.7625 - acc: 0.7061 - val_loss: 0.7413 - val_acc: 0.7066\n","Epoch 10/60\n","18169/18169 [==============================] - 147s 8ms/step - loss: 0.7375 - acc: 0.7160 - val_loss: 0.7784 - val_acc: 0.7028\n","Epoch 11/60\n","18169/18169 [==============================] - 147s 8ms/step - loss: 0.7062 - acc: 0.7269 - val_loss: 0.6574 - val_acc: 0.7483\n","Epoch 12/60\n","18169/18169 [==============================] - 147s 8ms/step - loss: 0.6763 - acc: 0.7358 - val_loss: 0.6274 - val_acc: 0.7561\n","Epoch 13/60\n","18169/18169 [==============================] - 147s 8ms/step - loss: 0.6697 - acc: 0.7367 - val_loss: 0.6536 - val_acc: 0.7392\n","Epoch 14/60\n","18169/18169 [==============================] - 147s 8ms/step - loss: 0.6512 - acc: 0.7410 - val_loss: 0.6603 - val_acc: 0.7455\n","Epoch 15/60\n","18169/18169 [==============================] - 147s 8ms/step - loss: 0.6520 - acc: 0.7403 - val_loss: 0.5989 - val_acc: 0.7617\n","Epoch 16/60\n","18169/18169 [==============================] - 146s 8ms/step - loss: 0.6187 - acc: 0.7511 - val_loss: 0.6769 - val_acc: 0.7341\n","Epoch 17/60\n","18169/18169 [==============================] - 146s 8ms/step - loss: 0.6374 - acc: 0.7428 - val_loss: 0.5943 - val_acc: 0.7671\n","Epoch 18/60\n","18169/18169 [==============================] - 146s 8ms/step - loss: 0.5871 - acc: 0.7644 - val_loss: 0.7348 - val_acc: 0.6986\n","Epoch 19/60\n","18169/18169 [==============================] - 146s 8ms/step - loss: 0.6128 - acc: 0.7542 - val_loss: 0.6198 - val_acc: 0.7469\n","Epoch 20/60\n","18169/18169 [==============================] - 146s 8ms/step - loss: 0.5987 - acc: 0.7590 - val_loss: 0.5916 - val_acc: 0.7699\n","Epoch 21/60\n","18169/18169 [==============================] - 146s 8ms/step - loss: 0.5760 - acc: 0.7691 - val_loss: 0.6680 - val_acc: 0.7492\n","Epoch 22/60\n","18169/18169 [==============================] - 145s 8ms/step - loss: 0.5733 - acc: 0.7715 - val_loss: 0.5499 - val_acc: 0.7789\n","Epoch 23/60\n","18169/18169 [==============================] - 144s 8ms/step - loss: 0.5704 - acc: 0.7707 - val_loss: 0.5474 - val_acc: 0.7779\n","Epoch 24/60\n","18169/18169 [==============================] - 144s 8ms/step - loss: 0.5721 - acc: 0.7701 - val_loss: 0.5716 - val_acc: 0.7715\n","Epoch 25/60\n","18169/18169 [==============================] - 144s 8ms/step - loss: 0.5548 - acc: 0.7740 - val_loss: 0.6624 - val_acc: 0.7213\n","Epoch 26/60\n","18169/18169 [==============================] - 144s 8ms/step - loss: 0.5665 - acc: 0.7710 - val_loss: 0.5734 - val_acc: 0.7695\n","Epoch 27/60\n","18169/18169 [==============================] - 144s 8ms/step - loss: 0.5404 - acc: 0.7813 - val_loss: 0.5171 - val_acc: 0.7902\n","Epoch 28/60\n","18169/18169 [==============================] - 144s 8ms/step - loss: 0.5177 - acc: 0.7894 - val_loss: 0.5467 - val_acc: 0.7841\n","Epoch 29/60\n","18169/18169 [==============================] - 144s 8ms/step - loss: 0.5558 - acc: 0.7772 - val_loss: 0.5252 - val_acc: 0.7842\n","Epoch 30/60\n","18169/18169 [==============================] - 144s 8ms/step - loss: 0.5391 - acc: 0.7826 - val_loss: 0.5380 - val_acc: 0.7841\n","Epoch 31/60\n","18169/18169 [==============================] - 143s 8ms/step - loss: 0.5439 - acc: 0.7791 - val_loss: 0.5082 - val_acc: 0.7958\n","Epoch 32/60\n","18169/18169 [==============================] - 143s 8ms/step - loss: 0.5321 - acc: 0.7836 - val_loss: 0.4998 - val_acc: 0.7958\n","Epoch 33/60\n","18169/18169 [==============================] - 142s 8ms/step - loss: 0.5179 - acc: 0.7891 - val_loss: 0.5892 - val_acc: 0.7532\n","Epoch 34/60\n","18169/18169 [==============================] - 143s 8ms/step - loss: 0.5092 - acc: 0.7958 - val_loss: 0.5144 - val_acc: 0.7901\n","Epoch 35/60\n","18169/18169 [==============================] - 143s 8ms/step - loss: 0.5086 - acc: 0.7942 - val_loss: 0.5129 - val_acc: 0.7922\n","Epoch 36/60\n","18169/18169 [==============================] - 143s 8ms/step - loss: 0.5158 - acc: 0.7916 - val_loss: 0.5723 - val_acc: 0.7607\n","Epoch 37/60\n","18169/18169 [==============================] - 142s 8ms/step - loss: 0.5171 - acc: 0.7922 - val_loss: 0.5040 - val_acc: 0.7978\n","Epoch 38/60\n","18169/18169 [==============================] - 142s 8ms/step - loss: 0.5066 - acc: 0.7952 - val_loss: 0.5197 - val_acc: 0.7910\n","Epoch 39/60\n","18169/18169 [==============================] - 142s 8ms/step - loss: 0.4931 - acc: 0.8004 - val_loss: 0.5333 - val_acc: 0.7901\n","Epoch 40/60\n","18169/18169 [==============================] - 142s 8ms/step - loss: 0.4920 - acc: 0.8009 - val_loss: 0.4933 - val_acc: 0.8081\n","Epoch 41/60\n","18169/18169 [==============================] - 141s 8ms/step - loss: 0.4793 - acc: 0.8070 - val_loss: 0.5103 - val_acc: 0.7951\n","Epoch 42/60\n","18169/18169 [==============================] - 142s 8ms/step - loss: 0.4848 - acc: 0.8049 - val_loss: 0.4698 - val_acc: 0.8097\n","Epoch 43/60\n","18169/18169 [==============================] - 143s 8ms/step - loss: 0.4781 - acc: 0.8070 - val_loss: 0.5146 - val_acc: 0.7972\n","Epoch 44/60\n","18169/18169 [==============================] - 143s 8ms/step - loss: 0.4723 - acc: 0.8108 - val_loss: 0.4716 - val_acc: 0.8080\n","Epoch 45/60\n","18169/18169 [==============================] - 143s 8ms/step - loss: 0.4709 - acc: 0.8094 - val_loss: 0.4527 - val_acc: 0.8151\n","Epoch 46/60\n","18169/18169 [==============================] - 142s 8ms/step - loss: 0.4595 - acc: 0.8170 - val_loss: 0.4890 - val_acc: 0.8015\n","Epoch 47/60\n","18169/18169 [==============================] - 142s 8ms/step - loss: 0.4798 - acc: 0.8103 - val_loss: 0.4495 - val_acc: 0.8194\n","Epoch 48/60\n","18169/18169 [==============================] - 141s 8ms/step - loss: 0.4516 - acc: 0.8191 - val_loss: 0.4607 - val_acc: 0.8183\n","Epoch 49/60\n","18169/18169 [==============================] - 141s 8ms/step - loss: 0.4758 - acc: 0.8115 - val_loss: 0.4402 - val_acc: 0.8264\n","Epoch 50/60\n","18169/18169 [==============================] - 141s 8ms/step - loss: 0.4464 - acc: 0.8211 - val_loss: 0.4837 - val_acc: 0.8039\n","Epoch 51/60\n","18169/18169 [==============================] - 141s 8ms/step - loss: 0.4460 - acc: 0.8226 - val_loss: 0.4872 - val_acc: 0.8050\n","Epoch 52/60\n","18169/18169 [==============================] - 141s 8ms/step - loss: 0.4505 - acc: 0.8215 - val_loss: 0.4599 - val_acc: 0.8136\n","Epoch 53/60\n","18169/18169 [==============================] - 141s 8ms/step - loss: 0.4479 - acc: 0.8237 - val_loss: 0.4446 - val_acc: 0.8256\n","Epoch 54/60\n","18169/18169 [==============================] - 141s 8ms/step - loss: 0.4380 - acc: 0.8255 - val_loss: 0.4942 - val_acc: 0.8052\n","Epoch 55/60\n","18169/18169 [==============================] - 141s 8ms/step - loss: 0.4483 - acc: 0.8244 - val_loss: 0.4645 - val_acc: 0.8128\n","Epoch 56/60\n","18169/18169 [==============================] - 140s 8ms/step - loss: 0.4368 - acc: 0.8244 - val_loss: 0.5228 - val_acc: 0.7959\n","Epoch 57/60\n","18169/18169 [==============================] - 140s 8ms/step - loss: 0.4340 - acc: 0.8285 - val_loss: 0.4422 - val_acc: 0.8256\n","Epoch 58/60\n","18169/18169 [==============================] - 141s 8ms/step - loss: 0.4209 - acc: 0.8328 - val_loss: 0.4286 - val_acc: 0.8268\n","Epoch 59/60\n","18169/18169 [==============================] - 140s 8ms/step - loss: 0.4418 - acc: 0.8270 - val_loss: 0.4285 - val_acc: 0.8326\n","Epoch 60/60\n","18169/18169 [==============================] - 140s 8ms/step - loss: 0.4249 - acc: 0.8309 - val_loss: 0.5045 - val_acc: 0.7976\n","Accuracy[0.6548] Recall[0.4883] F1[0.4626] at fold[2]\n","______________________________________________________\n","Start Training\n","Train on 18798 samples, validate on 18798 samples\n","Epoch 1/60\n","18798/18798 [==============================] - 145s 8ms/step - loss: 1.4376 - acc: 0.3669 - val_loss: 1.2962 - val_acc: 0.4031\n","Epoch 2/60\n","18798/18798 [==============================] - 145s 8ms/step - loss: 1.2624 - acc: 0.4241 - val_loss: 1.2282 - val_acc: 0.4088\n","Epoch 3/60\n","18798/18798 [==============================] - 145s 8ms/step - loss: 1.1951 - acc: 0.4772 - val_loss: 1.1579 - val_acc: 0.5552\n","Epoch 4/60\n","18798/18798 [==============================] - 145s 8ms/step - loss: 1.1508 - acc: 0.5028 - val_loss: 1.1209 - val_acc: 0.4678\n","Epoch 5/60\n","18798/18798 [==============================] - 144s 8ms/step - loss: 1.0799 - acc: 0.5435 - val_loss: 1.0534 - val_acc: 0.5535\n","Epoch 6/60\n","18798/18798 [==============================] - 145s 8ms/step - loss: 1.0309 - acc: 0.5801 - val_loss: 0.9767 - val_acc: 0.6178\n","Epoch 7/60\n","18798/18798 [==============================] - 145s 8ms/step - loss: 0.9621 - acc: 0.6205 - val_loss: 0.9032 - val_acc: 0.6368\n","Epoch 8/60\n","18798/18798 [==============================] - 146s 8ms/step - loss: 0.9099 - acc: 0.6323 - val_loss: 0.9644 - val_acc: 0.5985\n","Epoch 9/60\n","18798/18798 [==============================] - 146s 8ms/step - loss: 0.8897 - acc: 0.6366 - val_loss: 0.8569 - val_acc: 0.6403\n","Epoch 10/60\n","18798/18798 [==============================] - 146s 8ms/step - loss: 0.8396 - acc: 0.6570 - val_loss: 0.8391 - val_acc: 0.6592\n","Epoch 11/60\n","18798/18798 [==============================] - 149s 8ms/step - loss: 0.8277 - acc: 0.6626 - val_loss: 0.9991 - val_acc: 0.5941\n","Epoch 12/60\n","18798/18798 [==============================] - 149s 8ms/step - loss: 0.7525 - acc: 0.7028 - val_loss: 0.7067 - val_acc: 0.7203\n","Epoch 13/60\n","18798/18798 [==============================] - 150s 8ms/step - loss: 0.7694 - acc: 0.6939 - val_loss: 0.7000 - val_acc: 0.7258\n","Epoch 14/60\n","18798/18798 [==============================] - 150s 8ms/step - loss: 0.7367 - acc: 0.7049 - val_loss: 0.6847 - val_acc: 0.7290\n","Epoch 15/60\n","18798/18798 [==============================] - 149s 8ms/step - loss: 0.7419 - acc: 0.7011 - val_loss: 0.7573 - val_acc: 0.7004\n","Epoch 16/60\n","18798/18798 [==============================] - 148s 8ms/step - loss: 0.6758 - acc: 0.7326 - val_loss: 0.6691 - val_acc: 0.7326\n","Epoch 17/60\n","18798/18798 [==============================] - 148s 8ms/step - loss: 0.6884 - acc: 0.7247 - val_loss: 0.6584 - val_acc: 0.7385\n","Epoch 18/60\n","18798/18798 [==============================] - 148s 8ms/step - loss: 0.6721 - acc: 0.7324 - val_loss: 0.6821 - val_acc: 0.7312\n","Epoch 19/60\n","18798/18798 [==============================] - 148s 8ms/step - loss: 0.6677 - acc: 0.7329 - val_loss: 0.6616 - val_acc: 0.7365\n","Epoch 20/60\n","18798/18798 [==============================] - 147s 8ms/step - loss: 0.6290 - acc: 0.7498 - val_loss: 0.7226 - val_acc: 0.7072\n","Epoch 21/60\n","18798/18798 [==============================] - 147s 8ms/step - loss: 0.6319 - acc: 0.7478 - val_loss: 0.6065 - val_acc: 0.7597\n","Epoch 22/60\n","18798/18798 [==============================] - 148s 8ms/step - loss: 0.6344 - acc: 0.7440 - val_loss: 0.6032 - val_acc: 0.7628\n","Epoch 23/60\n","18000/18798 [===========================>..] - ETA: 3s - loss: 0.5998 - acc: 0.7605"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2E8PVrdclIs0","colab_type":"code","outputId":"4c872fc3-389e-4591-b257-7e6a2d7043e3","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["RunWisdom('data/SNOW/WISDM.npz')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["6\n","(20846, 1, 100, 3)\n","(20846, 6)\n","(20846, 1, 250, 29)\n","(18757, 1, 250, 29)\n","(2089, 1, 250, 29)\n","[11, 19, 27]\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","Start Training\n","Train on 18757 samples, validate on 18757 samples\n","Epoch 1/60\n","18757/18757 [==============================] - 171s 9ms/step - loss: 1.5490 - acc: 0.3224 - val_loss: 1.2569 - val_acc: 0.4085\n","Epoch 2/60\n","18757/18757 [==============================] - 171s 9ms/step - loss: 1.2035 - acc: 0.4561 - val_loss: 1.1545 - val_acc: 0.5144\n","Epoch 3/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 1.1407 - acc: 0.4815 - val_loss: 1.1210 - val_acc: 0.4497\n","Epoch 4/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 1.0752 - acc: 0.5168 - val_loss: 1.0262 - val_acc: 0.5719\n","Epoch 5/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.9887 - acc: 0.6026 - val_loss: 0.9584 - val_acc: 0.6096\n","Epoch 6/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.9013 - acc: 0.6449 - val_loss: 0.8773 - val_acc: 0.6535\n","Epoch 7/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.8473 - acc: 0.6611 - val_loss: 0.8943 - val_acc: 0.6281\n","Epoch 8/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.7856 - acc: 0.6845 - val_loss: 0.8726 - val_acc: 0.6349\n","Epoch 9/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.7457 - acc: 0.6990 - val_loss: 0.7644 - val_acc: 0.6993\n","Epoch 10/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.7139 - acc: 0.7168 - val_loss: 0.6604 - val_acc: 0.7388\n","Epoch 11/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.6828 - acc: 0.7340 - val_loss: 0.8589 - val_acc: 0.6707\n","Epoch 12/60\n","18757/18757 [==============================] - 173s 9ms/step - loss: 0.6923 - acc: 0.7314 - val_loss: 0.6455 - val_acc: 0.7537\n","Epoch 13/60\n","18757/18757 [==============================] - 172s 9ms/step - loss: 0.6741 - acc: 0.7405 - val_loss: 0.6300 - val_acc: 0.7569\n","Epoch 14/60\n","18757/18757 [==============================] - 171s 9ms/step - loss: 0.6327 - acc: 0.7543 - val_loss: 0.6539 - val_acc: 0.7463\n","Epoch 15/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.6656 - acc: 0.7414 - val_loss: 0.6167 - val_acc: 0.7567\n","Epoch 16/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.6224 - acc: 0.7551 - val_loss: 0.6082 - val_acc: 0.7626\n","Epoch 17/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.6287 - acc: 0.7536 - val_loss: 0.5984 - val_acc: 0.7612\n","Epoch 18/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.6163 - acc: 0.7567 - val_loss: 0.6241 - val_acc: 0.7521\n","Epoch 19/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.6164 - acc: 0.7556 - val_loss: 0.6794 - val_acc: 0.7356\n","Epoch 20/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.6136 - acc: 0.7564 - val_loss: 0.5915 - val_acc: 0.7667\n","Epoch 21/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.5998 - acc: 0.7617 - val_loss: 0.5810 - val_acc: 0.7676\n","Epoch 22/60\n","18757/18757 [==============================] - 169s 9ms/step - loss: 0.5903 - acc: 0.7675 - val_loss: 0.6369 - val_acc: 0.7501\n","Epoch 23/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.5887 - acc: 0.7673 - val_loss: 0.5856 - val_acc: 0.7684\n","Epoch 24/60\n","18757/18757 [==============================] - 169s 9ms/step - loss: 0.5978 - acc: 0.7637 - val_loss: 0.5797 - val_acc: 0.7649\n","Epoch 25/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.5899 - acc: 0.7688 - val_loss: 0.5606 - val_acc: 0.7760\n","Epoch 26/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.5659 - acc: 0.7754 - val_loss: 0.5847 - val_acc: 0.7678\n","Epoch 27/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.5653 - acc: 0.7760 - val_loss: 0.5437 - val_acc: 0.7864\n","Epoch 28/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.5753 - acc: 0.7712 - val_loss: 0.5493 - val_acc: 0.7878\n","Epoch 29/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.5490 - acc: 0.7825 - val_loss: 0.5680 - val_acc: 0.7789\n","Epoch 30/60\n","18757/18757 [==============================] - 171s 9ms/step - loss: 0.5614 - acc: 0.7771 - val_loss: 0.5449 - val_acc: 0.7803\n","Epoch 31/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.5492 - acc: 0.7830 - val_loss: 0.5427 - val_acc: 0.7838\n","Epoch 32/60\n","18757/18757 [==============================] - 170s 9ms/step - loss: 0.5451 - acc: 0.7834 - val_loss: 0.5382 - val_acc: 0.7826\n","Epoch 33/60\n","18757/18757 [==============================] - 172s 9ms/step - loss: 0.5436 - acc: 0.7849 - val_loss: 0.5345 - val_acc: 0.7914\n","Epoch 34/60\n","18757/18757 [==============================] - 173s 9ms/step - loss: 0.5350 - acc: 0.7877 - val_loss: 0.5682 - val_acc: 0.7735\n","Epoch 35/60\n","18757/18757 [==============================] - 169s 9ms/step - loss: 0.5256 - acc: 0.7905 - val_loss: 0.5143 - val_acc: 0.7863\n","Epoch 36/60\n","18757/18757 [==============================] - 167s 9ms/step - loss: 0.5266 - acc: 0.7889 - val_loss: 0.5142 - val_acc: 0.7977\n","Epoch 37/60\n","18757/18757 [==============================] - 166s 9ms/step - loss: 0.5338 - acc: 0.7897 - val_loss: 0.5172 - val_acc: 0.7888\n","Epoch 38/60\n","18757/18757 [==============================] - 165s 9ms/step - loss: 0.5137 - acc: 0.7943 - val_loss: 0.5652 - val_acc: 0.7765\n","Epoch 39/60\n","18757/18757 [==============================] - 166s 9ms/step - loss: 0.5094 - acc: 0.7947 - val_loss: 0.5055 - val_acc: 0.7945\n","Epoch 40/60\n","18757/18757 [==============================] - 166s 9ms/step - loss: 0.5326 - acc: 0.7917 - val_loss: 0.4906 - val_acc: 0.8054\n","Epoch 41/60\n","18757/18757 [==============================] - 166s 9ms/step - loss: 0.5005 - acc: 0.8014 - val_loss: 0.4857 - val_acc: 0.8104\n","Epoch 42/60\n","18757/18757 [==============================] - 166s 9ms/step - loss: 0.5061 - acc: 0.7995 - val_loss: 0.4916 - val_acc: 0.7994\n","Epoch 43/60\n","18757/18757 [==============================] - 167s 9ms/step - loss: 0.4967 - acc: 0.8023 - val_loss: 0.5284 - val_acc: 0.7884\n","Epoch 44/60\n","18757/18757 [==============================] - 167s 9ms/step - loss: 0.4980 - acc: 0.8024 - val_loss: 0.5416 - val_acc: 0.7879\n","Epoch 45/60\n","18757/18757 [==============================] - 168s 9ms/step - loss: 0.5043 - acc: 0.8000 - val_loss: 0.4756 - val_acc: 0.8114\n","Epoch 46/60\n","18757/18757 [==============================] - 168s 9ms/step - loss: 0.4969 - acc: 0.8027 - val_loss: 0.4724 - val_acc: 0.8076\n","Epoch 47/60\n","18757/18757 [==============================] - 168s 9ms/step - loss: 0.4773 - acc: 0.8087 - val_loss: 0.5060 - val_acc: 0.7956\n","Epoch 48/60\n","18757/18757 [==============================] - 168s 9ms/step - loss: 0.4901 - acc: 0.8040 - val_loss: 0.4640 - val_acc: 0.8162\n","Epoch 49/60\n","18757/18757 [==============================] - 167s 9ms/step - loss: 0.4672 - acc: 0.8149 - val_loss: 0.4924 - val_acc: 0.8016\n","Epoch 50/60\n","18757/18757 [==============================] - 167s 9ms/step - loss: 0.4804 - acc: 0.8090 - val_loss: 0.4930 - val_acc: 0.7998\n","Epoch 51/60\n","18757/18757 [==============================] - 169s 9ms/step - loss: 0.4775 - acc: 0.8118 - val_loss: 0.4637 - val_acc: 0.8200\n","Epoch 52/60\n","18757/18757 [==============================] - 169s 9ms/step - loss: 0.4785 - acc: 0.8077 - val_loss: 0.4934 - val_acc: 0.8009\n","Epoch 53/60\n","18757/18757 [==============================] - 169s 9ms/step - loss: 0.4722 - acc: 0.8112 - val_loss: 0.4498 - val_acc: 0.8207\n","Epoch 54/60\n","18757/18757 [==============================] - 169s 9ms/step - loss: 0.4776 - acc: 0.8097 - val_loss: 0.4865 - val_acc: 0.8028\n","Epoch 55/60\n","18757/18757 [==============================] - 172s 9ms/step - loss: 0.4599 - acc: 0.8169 - val_loss: 0.4463 - val_acc: 0.8241\n","Epoch 56/60\n","18757/18757 [==============================] - 171s 9ms/step - loss: 0.4597 - acc: 0.8173 - val_loss: 0.4733 - val_acc: 0.8138\n","Epoch 57/60\n","18757/18757 [==============================] - 168s 9ms/step - loss: 0.4569 - acc: 0.8159 - val_loss: 0.4721 - val_acc: 0.8083\n","Epoch 58/60\n","18757/18757 [==============================] - 168s 9ms/step - loss: 0.4470 - acc: 0.8231 - val_loss: 0.4349 - val_acc: 0.8274\n","Epoch 59/60\n","18757/18757 [==============================] - 169s 9ms/step - loss: 0.4660 - acc: 0.8146 - val_loss: 0.4445 - val_acc: 0.8207\n","Epoch 60/60\n","18757/18757 [==============================] - 169s 9ms/step - loss: 0.4488 - acc: 0.8221 - val_loss: 0.4418 - val_acc: 0.8208\n","Accuracy[0.8181] Recall[0.6928] F1[0.7043] at fold[0]\n","______________________________________________________\n","Start Training\n","Train on 18759 samples, validate on 18759 samples\n","Epoch 1/60\n","18759/18759 [==============================] - 167s 9ms/step - loss: 1.5910 - acc: 0.3238 - val_loss: 1.2921 - val_acc: 0.4167\n","Epoch 2/60\n","18759/18759 [==============================] - 165s 9ms/step - loss: 1.2386 - acc: 0.4135 - val_loss: 1.2018 - val_acc: 0.3960\n","Epoch 3/60\n","18759/18759 [==============================] - 165s 9ms/step - loss: 1.1865 - acc: 0.4532 - val_loss: 1.1637 - val_acc: 0.5358\n","Epoch 4/60\n","18759/18759 [==============================] - 170s 9ms/step - loss: 1.1419 - acc: 0.4837 - val_loss: 1.1634 - val_acc: 0.3810\n","Epoch 5/60\n","18759/18759 [==============================] - 169s 9ms/step - loss: 1.1066 - acc: 0.4991 - val_loss: 1.0410 - val_acc: 0.5733\n","Epoch 6/60\n","18759/18759 [==============================] - 168s 9ms/step - loss: 1.0245 - acc: 0.5746 - val_loss: 1.1333 - val_acc: 0.4849\n","Epoch 7/60\n","18759/18759 [==============================] - 168s 9ms/step - loss: 0.9856 - acc: 0.6121 - val_loss: 0.9598 - val_acc: 0.6190\n","Epoch 8/60\n","18759/18759 [==============================] - 168s 9ms/step - loss: 0.9259 - acc: 0.6343 - val_loss: 0.8359 - val_acc: 0.6941\n","Epoch 9/60\n","18759/18759 [==============================] - 169s 9ms/step - loss: 0.8894 - acc: 0.6473 - val_loss: 0.9106 - val_acc: 0.6238\n","Epoch 10/60\n","18759/18759 [==============================] - 168s 9ms/step - loss: 0.8413 - acc: 0.6644 - val_loss: 0.9085 - val_acc: 0.6282\n","Epoch 11/60\n","18759/18759 [==============================] - 169s 9ms/step - loss: 0.8110 - acc: 0.6762 - val_loss: 0.7647 - val_acc: 0.6949\n","Epoch 12/60\n","18759/18759 [==============================] - 167s 9ms/step - loss: 0.8028 - acc: 0.6795 - val_loss: 0.7894 - val_acc: 0.7022\n","Epoch 13/60\n","18759/18759 [==============================] - 166s 9ms/step - loss: 0.7421 - acc: 0.7092 - val_loss: 0.7049 - val_acc: 0.7229\n","Epoch 14/60\n","18759/18759 [==============================] - 166s 9ms/step - loss: 0.7603 - acc: 0.6999 - val_loss: 0.7254 - val_acc: 0.7136\n","Epoch 15/60\n","18759/18759 [==============================] - 166s 9ms/step - loss: 0.7255 - acc: 0.7137 - val_loss: 0.6960 - val_acc: 0.7230\n","Epoch 16/60\n","18759/18759 [==============================] - 168s 9ms/step - loss: 0.7188 - acc: 0.7160 - val_loss: 0.7191 - val_acc: 0.7189\n","Epoch 17/60\n","18759/18759 [==============================] - 168s 9ms/step - loss: 0.7232 - acc: 0.7122 - val_loss: 0.7017 - val_acc: 0.7176\n","Epoch 18/60\n","18759/18759 [==============================] - 165s 9ms/step - loss: 0.6864 - acc: 0.7275 - val_loss: 0.6433 - val_acc: 0.7491\n","Epoch 19/60\n","18759/18759 [==============================] - 165s 9ms/step - loss: 0.6837 - acc: 0.7309 - val_loss: 0.6277 - val_acc: 0.7514\n","Epoch 20/60\n","18759/18759 [==============================] - 165s 9ms/step - loss: 0.6802 - acc: 0.7279 - val_loss: 0.6246 - val_acc: 0.7506\n","Epoch 21/60\n","18759/18759 [==============================] - 162s 9ms/step - loss: 0.6420 - acc: 0.7449 - val_loss: 0.6572 - val_acc: 0.7398\n","Epoch 22/60\n","18759/18759 [==============================] - 163s 9ms/step - loss: 0.6530 - acc: 0.7402 - val_loss: 0.6165 - val_acc: 0.7515\n","Epoch 23/60\n","18759/18759 [==============================] - 163s 9ms/step - loss: 0.6376 - acc: 0.7472 - val_loss: 0.6360 - val_acc: 0.7474\n","Epoch 24/60\n","18759/18759 [==============================] - 163s 9ms/step - loss: 0.6316 - acc: 0.7485 - val_loss: 0.6077 - val_acc: 0.7549\n","Epoch 25/60\n","18759/18759 [==============================] - 163s 9ms/step - loss: 0.6214 - acc: 0.7501 - val_loss: 0.6514 - val_acc: 0.7440\n","Epoch 26/60\n","18759/18759 [==============================] - 164s 9ms/step - loss: 0.6196 - acc: 0.7512 - val_loss: 0.5715 - val_acc: 0.7672\n","Epoch 27/60\n","18759/18759 [==============================] - 163s 9ms/step - loss: 0.6212 - acc: 0.7504 - val_loss: 0.5816 - val_acc: 0.7614\n","Epoch 28/60\n","18759/18759 [==============================] - 163s 9ms/step - loss: 0.5964 - acc: 0.7601 - val_loss: 0.5746 - val_acc: 0.7713\n","Epoch 29/60\n","18759/18759 [==============================] - 162s 9ms/step - loss: 0.5824 - acc: 0.7640 - val_loss: 0.5697 - val_acc: 0.7636\n","Epoch 30/60\n","18759/18759 [==============================] - 162s 9ms/step - loss: 0.5898 - acc: 0.7633 - val_loss: 0.5699 - val_acc: 0.7732\n","Epoch 31/60\n","18759/18759 [==============================] - 162s 9ms/step - loss: 0.5749 - acc: 0.7661 - val_loss: 0.5381 - val_acc: 0.7794\n","Epoch 32/60\n","18759/18759 [==============================] - 163s 9ms/step - loss: 0.5710 - acc: 0.7695 - val_loss: 0.5363 - val_acc: 0.7793\n","Epoch 33/60\n","18759/18759 [==============================] - 162s 9ms/step - loss: 0.5676 - acc: 0.7696 - val_loss: 0.5315 - val_acc: 0.7764\n","Epoch 34/60\n"," 5000/18759 [======>.......................] - ETA: 1:14 - loss: 0.5296 - acc: 0.7796"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oZX1qx9NlKph","colab_type":"code","outputId":"2fa66cc5-21aa-4a30-eb67-1eb115ddb031","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["RunWisdom('data/FNOW/WISDM.npz')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["6\n","(10516, 1, 100, 3)\n","(10516, 6)\n","(10516, 1, 250, 29)\n","(9461, 1, 250, 29)\n","(1055, 1, 250, 29)\n","[11, 19, 27]\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","Start Training\n","Train on 9461 samples, validate on 9461 samples\n","Epoch 1/60\n","9461/9461 [==============================] - 93s 10ms/step - loss: 1.7582 - acc: 0.2605 - val_loss: 1.4194 - val_acc: 0.3845\n","Epoch 2/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 1.3210 - acc: 0.3953 - val_loss: 1.2502 - val_acc: 0.4251\n","Epoch 3/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 1.2211 - acc: 0.4398 - val_loss: 1.1890 - val_acc: 0.4521\n","Epoch 4/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 1.1661 - acc: 0.4857 - val_loss: 1.1204 - val_acc: 0.5266\n","Epoch 5/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 1.1355 - acc: 0.4891 - val_loss: 1.1104 - val_acc: 0.4776\n","Epoch 6/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 1.1036 - acc: 0.5038 - val_loss: 1.1168 - val_acc: 0.4538\n","Epoch 7/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 1.0525 - acc: 0.5377 - val_loss: 1.1293 - val_acc: 0.4576\n","Epoch 8/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 1.0145 - acc: 0.5749 - val_loss: 0.9297 - val_acc: 0.6659\n","Epoch 9/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.9958 - acc: 0.6134 - val_loss: 0.9159 - val_acc: 0.6581\n","Epoch 10/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.9103 - acc: 0.6542 - val_loss: 0.8482 - val_acc: 0.6876\n","Epoch 11/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.9207 - acc: 0.6352 - val_loss: 0.8188 - val_acc: 0.6971\n","Epoch 12/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.7969 - acc: 0.7011 - val_loss: 1.0303 - val_acc: 0.5747\n","Epoch 13/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.8602 - acc: 0.6605 - val_loss: 0.7454 - val_acc: 0.7109\n","Epoch 14/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.7931 - acc: 0.6858 - val_loss: 0.8685 - val_acc: 0.6355\n","Epoch 15/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.7745 - acc: 0.6897 - val_loss: 0.7290 - val_acc: 0.7045\n","Epoch 16/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.7234 - acc: 0.7079 - val_loss: 0.7097 - val_acc: 0.7101\n","Epoch 17/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.7506 - acc: 0.6973 - val_loss: 0.7419 - val_acc: 0.6925\n","Epoch 18/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.7144 - acc: 0.7116 - val_loss: 0.6884 - val_acc: 0.7341\n","Epoch 19/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.7076 - acc: 0.7247 - val_loss: 0.6945 - val_acc: 0.7140\n","Epoch 20/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6926 - acc: 0.7233 - val_loss: 0.6813 - val_acc: 0.7316\n","Epoch 21/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6778 - acc: 0.7334 - val_loss: 0.7248 - val_acc: 0.7086\n","Epoch 22/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6974 - acc: 0.7249 - val_loss: 0.7128 - val_acc: 0.7173\n","Epoch 23/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6816 - acc: 0.7327 - val_loss: 0.6407 - val_acc: 0.7520\n","Epoch 24/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6531 - acc: 0.7454 - val_loss: 0.6745 - val_acc: 0.7357\n","Epoch 25/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.7038 - acc: 0.7242 - val_loss: 0.6573 - val_acc: 0.7440\n","Epoch 26/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6587 - acc: 0.7416 - val_loss: 0.6273 - val_acc: 0.7535\n","Epoch 27/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6358 - acc: 0.7500 - val_loss: 0.6657 - val_acc: 0.7364\n","Epoch 28/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6734 - acc: 0.7334 - val_loss: 0.6504 - val_acc: 0.7436\n","Epoch 29/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6410 - acc: 0.7469 - val_loss: 0.6170 - val_acc: 0.7535\n","Epoch 30/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6210 - acc: 0.7508 - val_loss: 0.6086 - val_acc: 0.7574\n","Epoch 31/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6595 - acc: 0.7396 - val_loss: 0.6571 - val_acc: 0.7440\n","Epoch 32/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6263 - acc: 0.7511 - val_loss: 0.6134 - val_acc: 0.7577\n","Epoch 33/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6187 - acc: 0.7540 - val_loss: 0.6854 - val_acc: 0.7295\n","Epoch 34/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6346 - acc: 0.7460 - val_loss: 0.6360 - val_acc: 0.7433\n","Epoch 35/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6035 - acc: 0.7580 - val_loss: 0.6157 - val_acc: 0.7527\n","Epoch 36/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6209 - acc: 0.7525 - val_loss: 0.6198 - val_acc: 0.7565\n","Epoch 37/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5972 - acc: 0.7607 - val_loss: 0.6116 - val_acc: 0.7605\n","Epoch 38/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6545 - acc: 0.7381 - val_loss: 0.6299 - val_acc: 0.7563\n","Epoch 39/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5976 - acc: 0.7643 - val_loss: 0.6135 - val_acc: 0.7582\n","Epoch 40/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5987 - acc: 0.7595 - val_loss: 0.6026 - val_acc: 0.7591\n","Epoch 41/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5886 - acc: 0.7631 - val_loss: 0.5931 - val_acc: 0.7721\n","Epoch 42/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5805 - acc: 0.7671 - val_loss: 0.5905 - val_acc: 0.7714\n","Epoch 43/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6053 - acc: 0.7622 - val_loss: 0.5747 - val_acc: 0.7681\n","Epoch 44/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5810 - acc: 0.7705 - val_loss: 0.5732 - val_acc: 0.7696\n","Epoch 45/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5891 - acc: 0.7636 - val_loss: 0.6182 - val_acc: 0.7605\n","Epoch 46/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5943 - acc: 0.7611 - val_loss: 0.5608 - val_acc: 0.7753\n","Epoch 47/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5724 - acc: 0.7706 - val_loss: 0.6213 - val_acc: 0.7580\n","Epoch 48/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5929 - acc: 0.7646 - val_loss: 0.5869 - val_acc: 0.7732\n","Epoch 49/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5856 - acc: 0.7673 - val_loss: 0.5690 - val_acc: 0.7775\n","Epoch 50/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5819 - acc: 0.7684 - val_loss: 0.5636 - val_acc: 0.7768\n","Epoch 51/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5726 - acc: 0.7728 - val_loss: 0.5504 - val_acc: 0.7790\n","Epoch 52/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5446 - acc: 0.7805 - val_loss: 0.5496 - val_acc: 0.7761\n","Epoch 53/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5735 - acc: 0.7739 - val_loss: 0.5507 - val_acc: 0.7749\n","Epoch 54/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5584 - acc: 0.7763 - val_loss: 0.5795 - val_acc: 0.7658\n","Epoch 55/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5580 - acc: 0.7803 - val_loss: 0.5463 - val_acc: 0.7750\n","Epoch 56/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5536 - acc: 0.7778 - val_loss: 0.5326 - val_acc: 0.7858\n","Epoch 57/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5545 - acc: 0.7803 - val_loss: 0.6103 - val_acc: 0.7554\n","Epoch 58/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5458 - acc: 0.7827 - val_loss: 0.5225 - val_acc: 0.7907\n","Epoch 59/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5476 - acc: 0.7819 - val_loss: 0.6051 - val_acc: 0.7663\n","Epoch 60/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5797 - acc: 0.7723 - val_loss: 0.5300 - val_acc: 0.7924\n","Accuracy[0.7763] Recall[0.6273] F1[0.6272] at fold[0]\n","______________________________________________________\n","Start Training\n","Train on 9461 samples, validate on 9461 samples\n","Epoch 1/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 1.5301 - acc: 0.3013 - val_loss: 1.3378 - val_acc: 0.4087\n","Epoch 2/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 1.2912 - acc: 0.4281 - val_loss: 1.2506 - val_acc: 0.4350\n","Epoch 3/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 1.2269 - acc: 0.4516 - val_loss: 1.2036 - val_acc: 0.4446\n","Epoch 4/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 1.1886 - acc: 0.4675 - val_loss: 1.1979 - val_acc: 0.3860\n","Epoch 5/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 1.1623 - acc: 0.4819 - val_loss: 1.1775 - val_acc: 0.3995\n","Epoch 6/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 1.1231 - acc: 0.5024 - val_loss: 1.0978 - val_acc: 0.5087\n","Epoch 7/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 1.0935 - acc: 0.5257 - val_loss: 1.0347 - val_acc: 0.5814\n","Epoch 8/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 1.0277 - acc: 0.5975 - val_loss: 0.9752 - val_acc: 0.6219\n","Epoch 9/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 1.0138 - acc: 0.5848 - val_loss: 0.9864 - val_acc: 0.5911\n","Epoch 10/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.9760 - acc: 0.5949 - val_loss: 0.9493 - val_acc: 0.5995\n","Epoch 11/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 0.9321 - acc: 0.6134 - val_loss: 1.0019 - val_acc: 0.5714\n","Epoch 12/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.9053 - acc: 0.6271 - val_loss: 0.8873 - val_acc: 0.6301\n","Epoch 13/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.9006 - acc: 0.6286 - val_loss: 0.8298 - val_acc: 0.6616\n","Epoch 14/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 0.8901 - acc: 0.6330 - val_loss: 0.8498 - val_acc: 0.6524\n","Epoch 15/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 0.7960 - acc: 0.6871 - val_loss: 0.9155 - val_acc: 0.6221\n","Epoch 16/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 0.8612 - acc: 0.6505 - val_loss: 0.7591 - val_acc: 0.7027\n","Epoch 17/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.8645 - acc: 0.6542 - val_loss: 0.9195 - val_acc: 0.6264\n","Epoch 18/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.7942 - acc: 0.6844 - val_loss: 0.7401 - val_acc: 0.7129\n","Epoch 19/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 0.7990 - acc: 0.6836 - val_loss: 0.8622 - val_acc: 0.6507\n","Epoch 20/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 0.7711 - acc: 0.6925 - val_loss: 0.7123 - val_acc: 0.7306\n","Epoch 21/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 0.7378 - acc: 0.7176 - val_loss: 0.9852 - val_acc: 0.6082\n","Epoch 22/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 0.7975 - acc: 0.6835 - val_loss: 0.6967 - val_acc: 0.7309\n","Epoch 23/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 0.6949 - acc: 0.7294 - val_loss: 0.8044 - val_acc: 0.6790\n","Epoch 24/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.7979 - acc: 0.6824 - val_loss: 0.7496 - val_acc: 0.7005\n","Epoch 25/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 0.7564 - acc: 0.6979 - val_loss: 0.7025 - val_acc: 0.7274\n","Epoch 26/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 0.6824 - acc: 0.7331 - val_loss: 0.6654 - val_acc: 0.7404\n","Epoch 27/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.7586 - acc: 0.6997 - val_loss: 0.8078 - val_acc: 0.6794\n","Epoch 28/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 0.7125 - acc: 0.7176 - val_loss: 0.6836 - val_acc: 0.7325\n","Epoch 29/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 0.6641 - acc: 0.7416 - val_loss: 0.6523 - val_acc: 0.7419\n","Epoch 30/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.7034 - acc: 0.7253 - val_loss: 0.7390 - val_acc: 0.7071\n","Epoch 31/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 0.7041 - acc: 0.7184 - val_loss: 0.6577 - val_acc: 0.7479\n","Epoch 32/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6582 - acc: 0.7424 - val_loss: 0.7110 - val_acc: 0.7244\n","Epoch 33/60\n","9461/9461 [==============================] - 91s 10ms/step - loss: 0.7130 - acc: 0.7164 - val_loss: 0.6473 - val_acc: 0.7476\n","Epoch 34/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6647 - acc: 0.7439 - val_loss: 0.7143 - val_acc: 0.7178\n","Epoch 35/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6720 - acc: 0.7322 - val_loss: 0.7562 - val_acc: 0.7166\n","Epoch 36/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.7223 - acc: 0.7165 - val_loss: 0.6376 - val_acc: 0.7504\n","Epoch 37/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6367 - acc: 0.7471 - val_loss: 0.6373 - val_acc: 0.7534\n","Epoch 38/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6231 - acc: 0.7520 - val_loss: 0.6644 - val_acc: 0.7487\n","Epoch 39/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6780 - acc: 0.7353 - val_loss: 0.6338 - val_acc: 0.7546\n","Epoch 40/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6116 - acc: 0.7580 - val_loss: 0.6035 - val_acc: 0.7559\n","Epoch 41/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6388 - acc: 0.7483 - val_loss: 0.6765 - val_acc: 0.7380\n","Epoch 42/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6477 - acc: 0.7456 - val_loss: 0.6591 - val_acc: 0.7585\n","Epoch 43/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6422 - acc: 0.7512 - val_loss: 0.6355 - val_acc: 0.7516\n","Epoch 44/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6359 - acc: 0.7457 - val_loss: 0.5980 - val_acc: 0.7587\n","Epoch 45/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6279 - acc: 0.7515 - val_loss: 0.7148 - val_acc: 0.7311\n","Epoch 46/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6457 - acc: 0.7485 - val_loss: 0.5936 - val_acc: 0.7669\n","Epoch 47/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5971 - acc: 0.7629 - val_loss: 0.5906 - val_acc: 0.7695\n","Epoch 48/60\n","9461/9461 [==============================] - 93s 10ms/step - loss: 0.6070 - acc: 0.7633 - val_loss: 0.5855 - val_acc: 0.7706\n","Epoch 49/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6071 - acc: 0.7618 - val_loss: 0.6555 - val_acc: 0.7615\n","Epoch 50/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6335 - acc: 0.7547 - val_loss: 0.6046 - val_acc: 0.7762\n","Epoch 51/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5925 - acc: 0.7642 - val_loss: 0.6095 - val_acc: 0.7717\n","Epoch 52/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6038 - acc: 0.7626 - val_loss: 0.6171 - val_acc: 0.7753\n","Epoch 53/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5849 - acc: 0.7659 - val_loss: 0.5910 - val_acc: 0.7736\n","Epoch 54/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6469 - acc: 0.7525 - val_loss: 0.5683 - val_acc: 0.7758\n","Epoch 55/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5731 - acc: 0.7706 - val_loss: 0.5926 - val_acc: 0.7816\n","Epoch 56/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5790 - acc: 0.7714 - val_loss: 0.6454 - val_acc: 0.7625\n","Epoch 57/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6050 - acc: 0.7651 - val_loss: 0.5800 - val_acc: 0.7742\n","Epoch 58/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5801 - acc: 0.7699 - val_loss: 0.7822 - val_acc: 0.6682\n","Epoch 59/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.6316 - acc: 0.7481 - val_loss: 0.5545 - val_acc: 0.7868\n","Epoch 60/60\n","9461/9461 [==============================] - 92s 10ms/step - loss: 0.5627 - acc: 0.7760 - val_loss: 0.5652 - val_acc: 0.7757\n","Accuracy[0.7640] Recall[0.5875] F1[0.5765] at fold[1]\n","______________________________________________________\n","Start Training\n","Train on 9462 samples, validate on 9462 samples\n","Epoch 1/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 1.5981 - acc: 0.3263 - val_loss: 1.3547 - val_acc: 0.3893\n","Epoch 2/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 1.3060 - acc: 0.4232 - val_loss: 1.2663 - val_acc: 0.4167\n","Epoch 3/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 1.2593 - acc: 0.4506 - val_loss: 1.2098 - val_acc: 0.4430\n","Epoch 4/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 1.2067 - acc: 0.4724 - val_loss: 1.2384 - val_acc: 0.3964\n","Epoch 5/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 1.1952 - acc: 0.4662 - val_loss: 1.1176 - val_acc: 0.4947\n","Epoch 6/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 1.1363 - acc: 0.5036 - val_loss: 1.0939 - val_acc: 0.4975\n","Epoch 7/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 1.1098 - acc: 0.5260 - val_loss: 1.0350 - val_acc: 0.5848\n","Epoch 8/60\n","9462/9462 [==============================] - 93s 10ms/step - loss: 1.0367 - acc: 0.5965 - val_loss: 1.0560 - val_acc: 0.5413\n","Epoch 9/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 1.0282 - acc: 0.5830 - val_loss: 0.9715 - val_acc: 0.6088\n","Epoch 10/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.9811 - acc: 0.6035 - val_loss: 0.9487 - val_acc: 0.6131\n","Epoch 11/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.9158 - acc: 0.6334 - val_loss: 0.9126 - val_acc: 0.6253\n","Epoch 12/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.9253 - acc: 0.6178 - val_loss: 0.8357 - val_acc: 0.6671\n","Epoch 13/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.8383 - acc: 0.6582 - val_loss: 0.9485 - val_acc: 0.6095\n","Epoch 14/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.8791 - acc: 0.6332 - val_loss: 0.8005 - val_acc: 0.6840\n","Epoch 15/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.7696 - acc: 0.6984 - val_loss: 0.8250 - val_acc: 0.6618\n","Epoch 16/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.8643 - acc: 0.6394 - val_loss: 0.8448 - val_acc: 0.6597\n","Epoch 17/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.8061 - acc: 0.6762 - val_loss: 0.7606 - val_acc: 0.6983\n","Epoch 18/60\n","9462/9462 [==============================] - 93s 10ms/step - loss: 0.7755 - acc: 0.6890 - val_loss: 0.7585 - val_acc: 0.6976\n","Epoch 19/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.8128 - acc: 0.6714 - val_loss: 0.7799 - val_acc: 0.6858\n","Epoch 20/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.7143 - acc: 0.7211 - val_loss: 0.6872 - val_acc: 0.7295\n","Epoch 21/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.7623 - acc: 0.6977 - val_loss: 0.7868 - val_acc: 0.6753\n","Epoch 22/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.7002 - acc: 0.7247 - val_loss: 0.6683 - val_acc: 0.7420\n","Epoch 23/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6689 - acc: 0.7379 - val_loss: 0.7169 - val_acc: 0.7105\n","Epoch 24/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.7992 - acc: 0.6880 - val_loss: 0.6777 - val_acc: 0.7332\n","Epoch 25/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6778 - acc: 0.7325 - val_loss: 0.6526 - val_acc: 0.7468\n","Epoch 26/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6506 - acc: 0.7452 - val_loss: 0.6958 - val_acc: 0.7175\n","Epoch 27/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6776 - acc: 0.7308 - val_loss: 0.7156 - val_acc: 0.7106\n","Epoch 28/60\n","9462/9462 [==============================] - 93s 10ms/step - loss: 0.7357 - acc: 0.7089 - val_loss: 0.7048 - val_acc: 0.7198\n","Epoch 29/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6540 - acc: 0.7409 - val_loss: 0.6331 - val_acc: 0.7436\n","Epoch 30/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6357 - acc: 0.7487 - val_loss: 0.6296 - val_acc: 0.7435\n","Epoch 31/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6436 - acc: 0.7424 - val_loss: 0.6505 - val_acc: 0.7413\n","Epoch 32/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6984 - acc: 0.7241 - val_loss: 0.6506 - val_acc: 0.7428\n","Epoch 33/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6546 - acc: 0.7397 - val_loss: 0.6163 - val_acc: 0.7543\n","Epoch 34/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6186 - acc: 0.7540 - val_loss: 0.6389 - val_acc: 0.7456\n","Epoch 35/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6934 - acc: 0.7216 - val_loss: 0.6817 - val_acc: 0.7286\n","Epoch 36/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6271 - acc: 0.7484 - val_loss: 0.6277 - val_acc: 0.7476\n","Epoch 37/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6137 - acc: 0.7543 - val_loss: 0.6105 - val_acc: 0.7545\n","Epoch 38/60\n","9462/9462 [==============================] - 93s 10ms/step - loss: 0.6077 - acc: 0.7572 - val_loss: 0.6791 - val_acc: 0.7270\n","Epoch 39/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6576 - acc: 0.7375 - val_loss: 0.6048 - val_acc: 0.7564\n","Epoch 40/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.5975 - acc: 0.7600 - val_loss: 0.6203 - val_acc: 0.7535\n","Epoch 41/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6405 - acc: 0.7432 - val_loss: 0.6344 - val_acc: 0.7422\n","Epoch 42/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6060 - acc: 0.7598 - val_loss: 0.5924 - val_acc: 0.7645\n","Epoch 43/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.5932 - acc: 0.7655 - val_loss: 0.5831 - val_acc: 0.7668\n","Epoch 44/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.5917 - acc: 0.7611 - val_loss: 0.6161 - val_acc: 0.7579\n","Epoch 45/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6329 - acc: 0.7427 - val_loss: 0.5961 - val_acc: 0.7636\n","Epoch 46/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.5831 - acc: 0.7656 - val_loss: 0.5763 - val_acc: 0.7669\n","Epoch 47/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.5843 - acc: 0.7668 - val_loss: 0.6087 - val_acc: 0.7555\n","Epoch 48/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6376 - acc: 0.7456 - val_loss: 0.5977 - val_acc: 0.7572\n","Epoch 49/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.5762 - acc: 0.7684 - val_loss: 0.5727 - val_acc: 0.7695\n","Epoch 50/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.5719 - acc: 0.7695 - val_loss: 0.5751 - val_acc: 0.7666\n","Epoch 51/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.5894 - acc: 0.7636 - val_loss: 0.6074 - val_acc: 0.7557\n","Epoch 52/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.5846 - acc: 0.7661 - val_loss: 0.5640 - val_acc: 0.7697\n","Epoch 53/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.6002 - acc: 0.7529 - val_loss: 0.6115 - val_acc: 0.7516\n","Epoch 54/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.5868 - acc: 0.7628 - val_loss: 0.5587 - val_acc: 0.7697\n","Epoch 55/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.5671 - acc: 0.7700 - val_loss: 0.5623 - val_acc: 0.7685\n","Epoch 56/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.5614 - acc: 0.7734 - val_loss: 0.5777 - val_acc: 0.7740\n","Epoch 57/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.5872 - acc: 0.7656 - val_loss: 0.6214 - val_acc: 0.7559\n","Epoch 58/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.5931 - acc: 0.7603 - val_loss: 0.5663 - val_acc: 0.7740\n","Epoch 59/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.5824 - acc: 0.7707 - val_loss: 0.5723 - val_acc: 0.7721\n","Epoch 60/60\n","9462/9462 [==============================] - 92s 10ms/step - loss: 0.5652 - acc: 0.7737 - val_loss: 0.5511 - val_acc: 0.7845\n","Accuracy[0.7761] Recall[0.6301] F1[0.6350] at fold[2]\n","______________________________________________________\n","Start Training\n","Train on 9463 samples, validate on 9463 samples\n","Epoch 1/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 1.6048 - acc: 0.2835 - val_loss: 1.3788 - val_acc: 0.3946\n","Epoch 2/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 1.3136 - acc: 0.4202 - val_loss: 1.2611 - val_acc: 0.4179\n","Epoch 3/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 1.2374 - acc: 0.4554 - val_loss: 1.2207 - val_acc: 0.4291\n","Epoch 4/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 1.2002 - acc: 0.4885 - val_loss: 1.1921 - val_acc: 0.4270\n","Epoch 5/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 1.1892 - acc: 0.4752 - val_loss: 1.1784 - val_acc: 0.4189\n","Epoch 6/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 1.1441 - acc: 0.5092 - val_loss: 1.1420 - val_acc: 0.4639\n","Epoch 7/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 1.1367 - acc: 0.4957 - val_loss: 1.0796 - val_acc: 0.5673\n","Epoch 8/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 1.1069 - acc: 0.5184 - val_loss: 1.0597 - val_acc: 0.5602\n","Epoch 9/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 1.0727 - acc: 0.5385 - val_loss: 1.0504 - val_acc: 0.5557\n","Epoch 10/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 1.0457 - acc: 0.5571 - val_loss: 1.0304 - val_acc: 0.5747\n","Epoch 11/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.9928 - acc: 0.6005 - val_loss: 1.0149 - val_acc: 0.5730\n","Epoch 12/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.9896 - acc: 0.5899 - val_loss: 0.9166 - val_acc: 0.6478\n","Epoch 13/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.9534 - acc: 0.6058 - val_loss: 0.9850 - val_acc: 0.5976\n","Epoch 14/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.9141 - acc: 0.6447 - val_loss: 0.9864 - val_acc: 0.6057\n","Epoch 15/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.9022 - acc: 0.6474 - val_loss: 0.9001 - val_acc: 0.6479\n","Epoch 16/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.8494 - acc: 0.6700 - val_loss: 0.8027 - val_acc: 0.6969\n","Epoch 17/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.8418 - acc: 0.6633 - val_loss: 0.8075 - val_acc: 0.6845\n","Epoch 18/60\n","9463/9463 [==============================] - 93s 10ms/step - loss: 0.7830 - acc: 0.6951 - val_loss: 0.9716 - val_acc: 0.6054\n","Epoch 19/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.8085 - acc: 0.6768 - val_loss: 0.7711 - val_acc: 0.6940\n","Epoch 20/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.7960 - acc: 0.6757 - val_loss: 0.8345 - val_acc: 0.6611\n","Epoch 21/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.7569 - acc: 0.6934 - val_loss: 0.7433 - val_acc: 0.7029\n","Epoch 22/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.7760 - acc: 0.6827 - val_loss: 0.7712 - val_acc: 0.6883\n","Epoch 23/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.7001 - acc: 0.7233 - val_loss: 0.6743 - val_acc: 0.7297\n","Epoch 24/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.7316 - acc: 0.7043 - val_loss: 0.7682 - val_acc: 0.6770\n","Epoch 25/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.7364 - acc: 0.7000 - val_loss: 0.6799 - val_acc: 0.7313\n","Epoch 26/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6684 - acc: 0.7322 - val_loss: 0.6546 - val_acc: 0.7405\n","Epoch 27/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.7121 - acc: 0.7117 - val_loss: 0.7180 - val_acc: 0.7135\n","Epoch 28/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6762 - acc: 0.7275 - val_loss: 0.6917 - val_acc: 0.7217\n","Epoch 29/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6906 - acc: 0.7213 - val_loss: 0.6891 - val_acc: 0.7237\n","Epoch 30/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6885 - acc: 0.7230 - val_loss: 0.7378 - val_acc: 0.7103\n","Epoch 31/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6584 - acc: 0.7368 - val_loss: 0.6379 - val_acc: 0.7472\n","Epoch 32/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6473 - acc: 0.7367 - val_loss: 0.6528 - val_acc: 0.7357\n","Epoch 33/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6262 - acc: 0.7486 - val_loss: 0.6132 - val_acc: 0.7576\n","Epoch 34/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6608 - acc: 0.7331 - val_loss: 0.7966 - val_acc: 0.6981\n","Epoch 35/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6554 - acc: 0.7400 - val_loss: 0.6061 - val_acc: 0.7593\n","Epoch 36/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6186 - acc: 0.7529 - val_loss: 0.6119 - val_acc: 0.7548\n","Epoch 37/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6242 - acc: 0.7506 - val_loss: 0.6154 - val_acc: 0.7519\n","Epoch 38/60\n","9463/9463 [==============================] - 94s 10ms/step - loss: 0.6283 - acc: 0.7524 - val_loss: 0.6695 - val_acc: 0.7354\n","Epoch 39/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6252 - acc: 0.7527 - val_loss: 0.5930 - val_acc: 0.7627\n","Epoch 40/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.5939 - acc: 0.7632 - val_loss: 0.5845 - val_acc: 0.7693\n","Epoch 41/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6067 - acc: 0.7576 - val_loss: 0.6664 - val_acc: 0.7204\n","Epoch 42/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6355 - acc: 0.7466 - val_loss: 0.6595 - val_acc: 0.7432\n","Epoch 43/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6321 - acc: 0.7461 - val_loss: 0.5896 - val_acc: 0.7623\n","Epoch 44/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.5961 - acc: 0.7620 - val_loss: 0.6157 - val_acc: 0.7545\n","Epoch 45/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6043 - acc: 0.7576 - val_loss: 0.6119 - val_acc: 0.7546\n","Epoch 46/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.5912 - acc: 0.7649 - val_loss: 0.5757 - val_acc: 0.7778\n","Epoch 47/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.5893 - acc: 0.7653 - val_loss: 0.6348 - val_acc: 0.7432\n","Epoch 48/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6211 - acc: 0.7522 - val_loss: 0.6520 - val_acc: 0.7445\n","Epoch 49/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.5986 - acc: 0.7599 - val_loss: 0.5963 - val_acc: 0.7629\n","Epoch 50/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.5738 - acc: 0.7711 - val_loss: 0.5572 - val_acc: 0.7785\n","Epoch 51/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.5620 - acc: 0.7769 - val_loss: 0.6049 - val_acc: 0.7601\n","Epoch 52/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6116 - acc: 0.7593 - val_loss: 0.5967 - val_acc: 0.7628\n","Epoch 53/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.5710 - acc: 0.7702 - val_loss: 0.5558 - val_acc: 0.7807\n","Epoch 54/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.5482 - acc: 0.7795 - val_loss: 0.5511 - val_acc: 0.7791\n","Epoch 55/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.6011 - acc: 0.7631 - val_loss: 0.5570 - val_acc: 0.7755\n","Epoch 56/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.5666 - acc: 0.7735 - val_loss: 0.6190 - val_acc: 0.7538\n","Epoch 57/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.5577 - acc: 0.7796 - val_loss: 0.5720 - val_acc: 0.7726\n","Epoch 58/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.5711 - acc: 0.7703 - val_loss: 0.5453 - val_acc: 0.7918\n","Epoch 59/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.5500 - acc: 0.7830 - val_loss: 0.5510 - val_acc: 0.7845\n","Epoch 60/60\n","9463/9463 [==============================] - 92s 10ms/step - loss: 0.5603 - acc: 0.7781 - val_loss: 0.5422 - val_acc: 0.7835\n","Accuracy[0.7664] Recall[0.6374] F1[0.6274] at fold[3]\n","______________________________________________________\n","Start Training\n","Train on 9465 samples, validate on 9465 samples\n","Epoch 1/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 1.7832 - acc: 0.2003 - val_loss: 1.4399 - val_acc: 0.3893\n","Epoch 2/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 1.3536 - acc: 0.3932 - val_loss: 1.3014 - val_acc: 0.3698\n","Epoch 3/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 1.2749 - acc: 0.4052 - val_loss: 1.2526 - val_acc: 0.4222\n","Epoch 4/60\n","9465/9465 [==============================] - 91s 10ms/step - loss: 1.2496 - acc: 0.4129 - val_loss: 1.2366 - val_acc: 0.3794\n","Epoch 5/60\n","9465/9465 [==============================] - 91s 10ms/step - loss: 1.2199 - acc: 0.4264 - val_loss: 1.1932 - val_acc: 0.4615\n","Epoch 6/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 1.1882 - acc: 0.4491 - val_loss: 1.1822 - val_acc: 0.3934\n","Epoch 7/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 1.1590 - acc: 0.4722 - val_loss: 1.1900 - val_acc: 0.3564\n","Epoch 8/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 1.1505 - acc: 0.4610 - val_loss: 1.1864 - val_acc: 0.3899\n","Epoch 9/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 1.0896 - acc: 0.5570 - val_loss: 1.0491 - val_acc: 0.6106\n","Epoch 10/60\n","9465/9465 [==============================] - 91s 10ms/step - loss: 1.1070 - acc: 0.5373 - val_loss: 1.0674 - val_acc: 0.5948\n","Epoch 11/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 1.0581 - acc: 0.5741 - val_loss: 1.0253 - val_acc: 0.5932\n","Epoch 12/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 1.0225 - acc: 0.5830 - val_loss: 1.0651 - val_acc: 0.5536\n","Epoch 13/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.9956 - acc: 0.5891 - val_loss: 1.0906 - val_acc: 0.5269\n","Epoch 14/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.9972 - acc: 0.5798 - val_loss: 0.8909 - val_acc: 0.6432\n","Epoch 15/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.9531 - acc: 0.6072 - val_loss: 0.9298 - val_acc: 0.6042\n","Epoch 16/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.9923 - acc: 0.5831 - val_loss: 0.9537 - val_acc: 0.5932\n","Epoch 17/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.9101 - acc: 0.6168 - val_loss: 0.9669 - val_acc: 0.5900\n","Epoch 18/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.9116 - acc: 0.6181 - val_loss: 0.7927 - val_acc: 0.6819\n","Epoch 19/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.7957 - acc: 0.6802 - val_loss: 1.0604 - val_acc: 0.5422\n","Epoch 20/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.9460 - acc: 0.6092 - val_loss: 0.8043 - val_acc: 0.6653\n","Epoch 21/60\n","9465/9465 [==============================] - 91s 10ms/step - loss: 0.8054 - acc: 0.6666 - val_loss: 0.8383 - val_acc: 0.6451\n","Epoch 22/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.8542 - acc: 0.6429 - val_loss: 0.7838 - val_acc: 0.6762\n","Epoch 23/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.8316 - acc: 0.6498 - val_loss: 0.9526 - val_acc: 0.5995\n","Epoch 24/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.8116 - acc: 0.6653 - val_loss: 0.7372 - val_acc: 0.7004\n","Epoch 25/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.8005 - acc: 0.6672 - val_loss: 0.8627 - val_acc: 0.6274\n","Epoch 26/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.7850 - acc: 0.6731 - val_loss: 0.7112 - val_acc: 0.7143\n","Epoch 27/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.7060 - acc: 0.7139 - val_loss: 0.7267 - val_acc: 0.7053\n","Epoch 28/60\n","9465/9465 [==============================] - 93s 10ms/step - loss: 0.7811 - acc: 0.6718 - val_loss: 0.7704 - val_acc: 0.6818\n","Epoch 29/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.7806 - acc: 0.6731 - val_loss: 0.7458 - val_acc: 0.6943\n","Epoch 30/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.7011 - acc: 0.7111 - val_loss: 0.6777 - val_acc: 0.7222\n","Epoch 31/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6938 - acc: 0.7156 - val_loss: 0.9081 - val_acc: 0.6444\n","Epoch 32/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.8312 - acc: 0.6601 - val_loss: 0.6894 - val_acc: 0.7238\n","Epoch 33/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6980 - acc: 0.7095 - val_loss: 0.6857 - val_acc: 0.7194\n","Epoch 34/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6595 - acc: 0.7272 - val_loss: 0.6521 - val_acc: 0.7267\n","Epoch 35/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6803 - acc: 0.7212 - val_loss: 0.8146 - val_acc: 0.6768\n","Epoch 36/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.7376 - acc: 0.6959 - val_loss: 0.6645 - val_acc: 0.7293\n","Epoch 37/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6710 - acc: 0.7241 - val_loss: 0.6373 - val_acc: 0.7348\n","Epoch 38/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6371 - acc: 0.7372 - val_loss: 0.6385 - val_acc: 0.7351\n","Epoch 39/60\n","9465/9465 [==============================] - 91s 10ms/step - loss: 0.6597 - acc: 0.7286 - val_loss: 0.7556 - val_acc: 0.6825\n","Epoch 40/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6859 - acc: 0.7182 - val_loss: 0.6496 - val_acc: 0.7245\n","Epoch 41/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6529 - acc: 0.7276 - val_loss: 0.7068 - val_acc: 0.7006\n","Epoch 42/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6878 - acc: 0.7152 - val_loss: 0.6386 - val_acc: 0.7283\n","Epoch 43/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6469 - acc: 0.7339 - val_loss: 0.6213 - val_acc: 0.7381\n","Epoch 44/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6212 - acc: 0.7415 - val_loss: 0.6401 - val_acc: 0.7311\n","Epoch 45/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.7111 - acc: 0.7088 - val_loss: 0.6123 - val_acc: 0.7389\n","Epoch 46/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6094 - acc: 0.7446 - val_loss: 0.6225 - val_acc: 0.7404\n","Epoch 47/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6185 - acc: 0.7455 - val_loss: 0.6076 - val_acc: 0.7556\n","Epoch 48/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6029 - acc: 0.7506 - val_loss: 0.6056 - val_acc: 0.7520\n","Epoch 49/60\n","9465/9465 [==============================] - 91s 10ms/step - loss: 0.6809 - acc: 0.7199 - val_loss: 0.6031 - val_acc: 0.7556\n","Epoch 50/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.5923 - acc: 0.7517 - val_loss: 0.5951 - val_acc: 0.7564\n","Epoch 51/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.5930 - acc: 0.7525 - val_loss: 0.6208 - val_acc: 0.7521\n","Epoch 52/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6070 - acc: 0.7496 - val_loss: 0.5803 - val_acc: 0.7558\n","Epoch 53/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.5808 - acc: 0.7550 - val_loss: 0.5879 - val_acc: 0.7652\n","Epoch 54/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6076 - acc: 0.7503 - val_loss: 0.6872 - val_acc: 0.7198\n","Epoch 55/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6346 - acc: 0.7409 - val_loss: 0.6499 - val_acc: 0.7369\n","Epoch 56/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6035 - acc: 0.7514 - val_loss: 0.5789 - val_acc: 0.7645\n","Epoch 57/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.5887 - acc: 0.7568 - val_loss: 0.6137 - val_acc: 0.7531\n","Epoch 58/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.5950 - acc: 0.7526 - val_loss: 0.5682 - val_acc: 0.7658\n","Epoch 59/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.5770 - acc: 0.7606 - val_loss: 0.6348 - val_acc: 0.7398\n","Epoch 60/60\n","9465/9465 [==============================] - 92s 10ms/step - loss: 0.6073 - acc: 0.7492 - val_loss: 0.5570 - val_acc: 0.7714\n","Accuracy[0.7612] Recall[0.5932] F1[0.5902] at fold[4]\n","______________________________________________________\n","Start Training\n","Train on 9466 samples, validate on 9466 samples\n","Epoch 1/60\n","9466/9466 [==============================] - 93s 10ms/step - loss: 1.7125 - acc: 0.2042 - val_loss: 1.3957 - val_acc: 0.3225\n","Epoch 2/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.3362 - acc: 0.3467 - val_loss: 1.2908 - val_acc: 0.3525\n","Epoch 3/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.2720 - acc: 0.3946 - val_loss: 1.2468 - val_acc: 0.3874\n","Epoch 4/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.2290 - acc: 0.4586 - val_loss: 1.2012 - val_acc: 0.5354\n","Epoch 5/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.1923 - acc: 0.4950 - val_loss: 1.1894 - val_acc: 0.5331\n","Epoch 6/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.1590 - acc: 0.5160 - val_loss: 1.1657 - val_acc: 0.5176\n","Epoch 7/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.1390 - acc: 0.5202 - val_loss: 1.1047 - val_acc: 0.5690\n","Epoch 8/60\n","9466/9466 [==============================] - 93s 10ms/step - loss: 1.1067 - acc: 0.5338 - val_loss: 1.0637 - val_acc: 0.5778\n","Epoch 9/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.0553 - acc: 0.5691 - val_loss: 1.0569 - val_acc: 0.5501\n","Epoch 10/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.0286 - acc: 0.5937 - val_loss: 1.0028 - val_acc: 0.6028\n","Epoch 11/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.9901 - acc: 0.6158 - val_loss: 0.9476 - val_acc: 0.6335\n","Epoch 12/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.9531 - acc: 0.6378 - val_loss: 0.9524 - val_acc: 0.6228\n","Epoch 13/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.9293 - acc: 0.6535 - val_loss: 0.8722 - val_acc: 0.6803\n","Epoch 14/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.8877 - acc: 0.6718 - val_loss: 0.9066 - val_acc: 0.6385\n","Epoch 15/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.8291 - acc: 0.6898 - val_loss: 0.8298 - val_acc: 0.6703\n","Epoch 16/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.8486 - acc: 0.6692 - val_loss: 0.7773 - val_acc: 0.7028\n","Epoch 17/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.8067 - acc: 0.6847 - val_loss: 0.8383 - val_acc: 0.6557\n","Epoch 18/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7917 - acc: 0.6909 - val_loss: 0.7220 - val_acc: 0.7168\n","Epoch 19/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7175 - acc: 0.7165 - val_loss: 0.7891 - val_acc: 0.6941\n","Epoch 20/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.8057 - acc: 0.6787 - val_loss: 0.7361 - val_acc: 0.7052\n","Epoch 21/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7466 - acc: 0.7026 - val_loss: 0.7880 - val_acc: 0.6971\n","Epoch 22/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7585 - acc: 0.6981 - val_loss: 0.7474 - val_acc: 0.7065\n","Epoch 23/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7280 - acc: 0.7139 - val_loss: 0.6989 - val_acc: 0.7224\n","Epoch 24/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7456 - acc: 0.7045 - val_loss: 0.7047 - val_acc: 0.7188\n","Epoch 25/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6953 - acc: 0.7247 - val_loss: 0.6654 - val_acc: 0.7372\n","Epoch 26/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7029 - acc: 0.7242 - val_loss: 0.8510 - val_acc: 0.6796\n","Epoch 27/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7183 - acc: 0.7178 - val_loss: 0.6956 - val_acc: 0.7217\n","Epoch 28/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6776 - acc: 0.7334 - val_loss: 0.6503 - val_acc: 0.7446\n","Epoch 29/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6800 - acc: 0.7326 - val_loss: 0.7447 - val_acc: 0.7138\n","Epoch 30/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7012 - acc: 0.7259 - val_loss: 0.6773 - val_acc: 0.7326\n","Epoch 31/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6600 - acc: 0.7362 - val_loss: 0.7201 - val_acc: 0.7174\n","Epoch 32/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7208 - acc: 0.7146 - val_loss: 0.6412 - val_acc: 0.7478\n","Epoch 33/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6404 - acc: 0.7488 - val_loss: 0.6231 - val_acc: 0.7549\n","Epoch 34/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6205 - acc: 0.7551 - val_loss: 0.6216 - val_acc: 0.7515\n","Epoch 35/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6563 - acc: 0.7401 - val_loss: 0.6584 - val_acc: 0.7358\n","Epoch 36/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6872 - acc: 0.7270 - val_loss: 0.6172 - val_acc: 0.7586\n","Epoch 37/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6284 - acc: 0.7549 - val_loss: 0.6300 - val_acc: 0.7451\n","Epoch 38/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6603 - acc: 0.7354 - val_loss: 0.6259 - val_acc: 0.7487\n","Epoch 39/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6258 - acc: 0.7480 - val_loss: 0.6029 - val_acc: 0.7698\n","Epoch 40/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6173 - acc: 0.7567 - val_loss: 0.6422 - val_acc: 0.7465\n","Epoch 41/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6444 - acc: 0.7424 - val_loss: 0.6695 - val_acc: 0.7290\n","Epoch 42/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6395 - acc: 0.7472 - val_loss: 0.6148 - val_acc: 0.7541\n","Epoch 43/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6118 - acc: 0.7628 - val_loss: 0.6230 - val_acc: 0.7461\n","Epoch 44/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6289 - acc: 0.7453 - val_loss: 0.6052 - val_acc: 0.7584\n","Epoch 45/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6226 - acc: 0.7513 - val_loss: 0.6027 - val_acc: 0.7569\n","Epoch 46/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6033 - acc: 0.7613 - val_loss: 0.6266 - val_acc: 0.7518\n","Epoch 47/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6184 - acc: 0.7558 - val_loss: 0.6137 - val_acc: 0.7624\n","Epoch 48/60\n","9466/9466 [==============================] - 93s 10ms/step - loss: 0.5873 - acc: 0.7674 - val_loss: 0.5946 - val_acc: 0.7574\n","Epoch 49/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6249 - acc: 0.7530 - val_loss: 0.6044 - val_acc: 0.7624\n","Epoch 50/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6213 - acc: 0.7514 - val_loss: 0.5951 - val_acc: 0.7581\n","Epoch 51/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5853 - acc: 0.7681 - val_loss: 0.5782 - val_acc: 0.7709\n","Epoch 52/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5806 - acc: 0.7689 - val_loss: 0.5696 - val_acc: 0.7716\n","Epoch 53/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6302 - acc: 0.7470 - val_loss: 0.5678 - val_acc: 0.7764\n","Epoch 54/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5605 - acc: 0.7812 - val_loss: 0.5503 - val_acc: 0.7795\n","Epoch 55/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5559 - acc: 0.7815 - val_loss: 0.5572 - val_acc: 0.7830\n","Epoch 56/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5935 - acc: 0.7678 - val_loss: 0.5628 - val_acc: 0.7777\n","Epoch 57/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5743 - acc: 0.7699 - val_loss: 0.5510 - val_acc: 0.7842\n","Epoch 58/60\n","9466/9466 [==============================] - 93s 10ms/step - loss: 0.5764 - acc: 0.7734 - val_loss: 0.6402 - val_acc: 0.7473\n","Epoch 59/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5861 - acc: 0.7667 - val_loss: 0.5846 - val_acc: 0.7703\n","Epoch 60/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5560 - acc: 0.7835 - val_loss: 0.5309 - val_acc: 0.7870\n","Accuracy[0.7781] Recall[0.6318] F1[0.6171] at fold[5]\n","______________________________________________________\n","Start Training\n","Train on 9466 samples, validate on 9466 samples\n","Epoch 1/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.4718 - acc: 0.3181 - val_loss: 1.3400 - val_acc: 0.3814\n","Epoch 2/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.3126 - acc: 0.4121 - val_loss: 1.2857 - val_acc: 0.3896\n","Epoch 3/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.2675 - acc: 0.4283 - val_loss: 1.2360 - val_acc: 0.4600\n","Epoch 4/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.2157 - acc: 0.4868 - val_loss: 1.2321 - val_acc: 0.4828\n","Epoch 5/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 1.1973 - acc: 0.4643 - val_loss: 1.1709 - val_acc: 0.5331\n","Epoch 6/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.1746 - acc: 0.4598 - val_loss: 1.1272 - val_acc: 0.5466\n","Epoch 7/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.1103 - acc: 0.5192 - val_loss: 1.1175 - val_acc: 0.5089\n","Epoch 8/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.0883 - acc: 0.5137 - val_loss: 1.0601 - val_acc: 0.5426\n","Epoch 9/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 1.0428 - acc: 0.5657 - val_loss: 0.9696 - val_acc: 0.6402\n","Epoch 10/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.0213 - acc: 0.5818 - val_loss: 0.9323 - val_acc: 0.6464\n","Epoch 11/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.9843 - acc: 0.5957 - val_loss: 0.8925 - val_acc: 0.6600\n","Epoch 12/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.9132 - acc: 0.6352 - val_loss: 0.9375 - val_acc: 0.5957\n","Epoch 13/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.8983 - acc: 0.6268 - val_loss: 0.8657 - val_acc: 0.6350\n","Epoch 14/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.8718 - acc: 0.6390 - val_loss: 0.8808 - val_acc: 0.6187\n","Epoch 15/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.8203 - acc: 0.6652 - val_loss: 0.9300 - val_acc: 0.5898\n","Epoch 16/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.8394 - acc: 0.6506 - val_loss: 0.7460 - val_acc: 0.7025\n","Epoch 17/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.8158 - acc: 0.6647 - val_loss: 0.7973 - val_acc: 0.6707\n","Epoch 18/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7380 - acc: 0.7098 - val_loss: 0.7639 - val_acc: 0.6832\n","Epoch 19/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.8124 - acc: 0.6638 - val_loss: 0.7189 - val_acc: 0.7159\n","Epoch 20/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.7063 - acc: 0.7225 - val_loss: 0.7833 - val_acc: 0.6867\n","Epoch 21/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7928 - acc: 0.6717 - val_loss: 0.6963 - val_acc: 0.7253\n","Epoch 22/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.7421 - acc: 0.6959 - val_loss: 0.7196 - val_acc: 0.7064\n","Epoch 23/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.7217 - acc: 0.7081 - val_loss: 0.8181 - val_acc: 0.6674\n","Epoch 24/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7780 - acc: 0.6805 - val_loss: 0.7548 - val_acc: 0.6885\n","Epoch 25/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6850 - acc: 0.7254 - val_loss: 0.6584 - val_acc: 0.7333\n","Epoch 26/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6559 - acc: 0.7330 - val_loss: 0.6492 - val_acc: 0.7351\n","Epoch 27/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.6585 - acc: 0.7321 - val_loss: 0.8650 - val_acc: 0.6462\n","Epoch 28/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7200 - acc: 0.7054 - val_loss: 0.6541 - val_acc: 0.7325\n","Epoch 29/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6551 - acc: 0.7317 - val_loss: 0.7070 - val_acc: 0.7111\n","Epoch 30/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6728 - acc: 0.7217 - val_loss: 0.6637 - val_acc: 0.7265\n","Epoch 31/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6924 - acc: 0.7150 - val_loss: 0.6645 - val_acc: 0.7286\n","Epoch 32/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6407 - acc: 0.7342 - val_loss: 0.6214 - val_acc: 0.7454\n","Epoch 33/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6191 - acc: 0.7462 - val_loss: 0.6189 - val_acc: 0.7428\n","Epoch 34/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.6493 - acc: 0.7296 - val_loss: 0.7679 - val_acc: 0.6812\n","Epoch 35/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6423 - acc: 0.7357 - val_loss: 0.6012 - val_acc: 0.7546\n","Epoch 36/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.6006 - acc: 0.7544 - val_loss: 0.5985 - val_acc: 0.7536\n","Epoch 37/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.6017 - acc: 0.7487 - val_loss: 0.6363 - val_acc: 0.7414\n","Epoch 38/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6444 - acc: 0.7322 - val_loss: 0.7012 - val_acc: 0.7213\n","Epoch 39/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.6366 - acc: 0.7375 - val_loss: 0.6114 - val_acc: 0.7470\n","Epoch 40/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6013 - acc: 0.7507 - val_loss: 0.5796 - val_acc: 0.7608\n","Epoch 41/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5885 - acc: 0.7569 - val_loss: 0.5820 - val_acc: 0.7606\n","Epoch 42/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6141 - acc: 0.7453 - val_loss: 0.6046 - val_acc: 0.7489\n","Epoch 43/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6034 - acc: 0.7528 - val_loss: 0.5741 - val_acc: 0.7610\n","Epoch 44/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6154 - acc: 0.7462 - val_loss: 0.6224 - val_acc: 0.7461\n","Epoch 45/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6050 - acc: 0.7515 - val_loss: 0.5712 - val_acc: 0.7696\n","Epoch 46/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.5663 - acc: 0.7651 - val_loss: 0.6516 - val_acc: 0.7362\n","Epoch 47/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6399 - acc: 0.7389 - val_loss: 0.5600 - val_acc: 0.7704\n","Epoch 48/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5635 - acc: 0.7662 - val_loss: 0.5656 - val_acc: 0.7649\n","Epoch 49/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.5664 - acc: 0.7646 - val_loss: 0.5829 - val_acc: 0.7618\n","Epoch 50/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.5761 - acc: 0.7630 - val_loss: 0.5563 - val_acc: 0.7782\n","Epoch 51/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5641 - acc: 0.7700 - val_loss: 0.5966 - val_acc: 0.7595\n","Epoch 52/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.5755 - acc: 0.7645 - val_loss: 0.6241 - val_acc: 0.7483\n","Epoch 53/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.5711 - acc: 0.7670 - val_loss: 0.5437 - val_acc: 0.7750\n","Epoch 54/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5652 - acc: 0.7705 - val_loss: 0.5670 - val_acc: 0.7774\n","Epoch 55/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5678 - acc: 0.7670 - val_loss: 0.5851 - val_acc: 0.7680\n","Epoch 56/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5842 - acc: 0.7643 - val_loss: 0.5578 - val_acc: 0.7834\n","Epoch 57/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5349 - acc: 0.7819 - val_loss: 0.5759 - val_acc: 0.7646\n","Epoch 58/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5823 - acc: 0.7657 - val_loss: 0.5686 - val_acc: 0.7665\n","Epoch 59/60\n","9466/9466 [==============================] - 91s 10ms/step - loss: 0.5585 - acc: 0.7711 - val_loss: 0.5645 - val_acc: 0.7624\n","Epoch 60/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5643 - acc: 0.7665 - val_loss: 0.5341 - val_acc: 0.7758\n","Accuracy[0.7733] Recall[0.6010] F1[0.5935] at fold[6]\n","______________________________________________________\n","Start Training\n","Train on 9466 samples, validate on 9466 samples\n","Epoch 1/60\n","9466/9466 [==============================] - 93s 10ms/step - loss: 1.5057 - acc: 0.3634 - val_loss: 1.3727 - val_acc: 0.4021\n","Epoch 2/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.3387 - acc: 0.4084 - val_loss: 1.3036 - val_acc: 0.4071\n","Epoch 3/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.2806 - acc: 0.4331 - val_loss: 1.2589 - val_acc: 0.4665\n","Epoch 4/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.2420 - acc: 0.4475 - val_loss: 1.2140 - val_acc: 0.4997\n","Epoch 5/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.1943 - acc: 0.4906 - val_loss: 1.2064 - val_acc: 0.4986\n","Epoch 6/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.1909 - acc: 0.4618 - val_loss: 1.1802 - val_acc: 0.5116\n","Epoch 7/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.1479 - acc: 0.5098 - val_loss: 1.1324 - val_acc: 0.5380\n","Epoch 8/60\n","9466/9466 [==============================] - 94s 10ms/step - loss: 1.1025 - acc: 0.5356 - val_loss: 1.1147 - val_acc: 0.5423\n","Epoch 9/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.0210 - acc: 0.6043 - val_loss: 1.1152 - val_acc: 0.5432\n","Epoch 10/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 1.0206 - acc: 0.5876 - val_loss: 1.0292 - val_acc: 0.5760\n","Epoch 11/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.9824 - acc: 0.6003 - val_loss: 1.0071 - val_acc: 0.5817\n","Epoch 12/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.9522 - acc: 0.6138 - val_loss: 0.9116 - val_acc: 0.6293\n","Epoch 13/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.9335 - acc: 0.6187 - val_loss: 0.8619 - val_acc: 0.6532\n","Epoch 14/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.8848 - acc: 0.6379 - val_loss: 0.8862 - val_acc: 0.6244\n","Epoch 15/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.8615 - acc: 0.6419 - val_loss: 0.8895 - val_acc: 0.6157\n","Epoch 16/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.8272 - acc: 0.6667 - val_loss: 0.7795 - val_acc: 0.6849\n","Epoch 17/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.8468 - acc: 0.6478 - val_loss: 0.8248 - val_acc: 0.6534\n","Epoch 18/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7854 - acc: 0.6812 - val_loss: 0.7474 - val_acc: 0.7009\n","Epoch 19/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.8231 - acc: 0.6667 - val_loss: 0.8694 - val_acc: 0.6335\n","Epoch 20/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7376 - acc: 0.7059 - val_loss: 0.7228 - val_acc: 0.7127\n","Epoch 21/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7814 - acc: 0.6842 - val_loss: 0.7196 - val_acc: 0.7167\n","Epoch 22/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7158 - acc: 0.7120 - val_loss: 0.7003 - val_acc: 0.7248\n","Epoch 23/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7428 - acc: 0.7021 - val_loss: 0.8235 - val_acc: 0.6533\n","Epoch 24/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7081 - acc: 0.7132 - val_loss: 0.7192 - val_acc: 0.7085\n","Epoch 25/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7124 - acc: 0.7130 - val_loss: 0.6688 - val_acc: 0.7328\n","Epoch 26/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6539 - acc: 0.7378 - val_loss: 0.6448 - val_acc: 0.7395\n","Epoch 27/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.7182 - acc: 0.7113 - val_loss: 0.6894 - val_acc: 0.7226\n","Epoch 28/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6730 - acc: 0.7284 - val_loss: 0.6330 - val_acc: 0.7450\n","Epoch 29/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6420 - acc: 0.7432 - val_loss: 0.6805 - val_acc: 0.7229\n","Epoch 30/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6860 - acc: 0.7236 - val_loss: 0.6620 - val_acc: 0.7304\n","Epoch 31/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6390 - acc: 0.7416 - val_loss: 0.6280 - val_acc: 0.7422\n","Epoch 32/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6390 - acc: 0.7377 - val_loss: 0.6050 - val_acc: 0.7544\n","Epoch 33/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5978 - acc: 0.7569 - val_loss: 0.6764 - val_acc: 0.7254\n","Epoch 34/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6927 - acc: 0.7158 - val_loss: 0.5961 - val_acc: 0.7558\n","Epoch 35/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6025 - acc: 0.7541 - val_loss: 0.5914 - val_acc: 0.7577\n","Epoch 36/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6054 - acc: 0.7541 - val_loss: 0.6278 - val_acc: 0.7505\n","Epoch 37/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6059 - acc: 0.7566 - val_loss: 0.5719 - val_acc: 0.7666\n","Epoch 38/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6110 - acc: 0.7482 - val_loss: 0.7226 - val_acc: 0.7089\n","Epoch 39/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5875 - acc: 0.7609 - val_loss: 0.5745 - val_acc: 0.7755\n","Epoch 40/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5706 - acc: 0.7693 - val_loss: 0.6044 - val_acc: 0.7529\n","Epoch 41/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.6390 - acc: 0.7391 - val_loss: 0.5972 - val_acc: 0.7616\n","Epoch 42/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5610 - acc: 0.7749 - val_loss: 0.5543 - val_acc: 0.7736\n","Epoch 43/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5966 - acc: 0.7553 - val_loss: 0.5522 - val_acc: 0.7746\n","Epoch 44/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5620 - acc: 0.7735 - val_loss: 0.5396 - val_acc: 0.7820\n","Epoch 45/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5421 - acc: 0.7811 - val_loss: 0.5373 - val_acc: 0.7742\n","Epoch 46/60\n","9466/9466 [==============================] - 92s 10ms/step - loss: 0.5952 - acc: 0.7573 - val_loss: 0.5640 - val_acc: 0.7701\n","Epoch 47/60\n","9000/9466 [===========================>..] - ETA: 2s - loss: 0.5596 - acc: 0.7754"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8oZD9INcegNT","colab_type":"code","outputId":"dbc0e2bf-94da-4a37-e934-eb0291eb654d","executionInfo":{"status":"ok","timestamp":1584989377265,"user_tz":-120,"elapsed":301744,"user":{"displayName":"Rana mostafa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpLWLhJYcXKOOp7sprSKwnxN-x9hYM61yh__9kww=s64","userId":"07598775866819373078"}},"colab":{"base_uri":"https://localhost:8080/","height":712}},"source":["Run('data/LOSO/MHEALTH.npz')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Start Training\n","Epoch 00073: early stopping THR\n","Accuracy[0.8706] Recall[0.8763] F1[0.8684] at fold[0]\n","______________________________________________________\n","Start Training\n","Epoch 00054: early stopping THR\n","Accuracy[0.7567] Recall[0.7495] F1[0.7311] at fold[1]\n","______________________________________________________\n","Start Training\n","Epoch 00081: early stopping THR\n","Accuracy[0.7809] Recall[0.7652] F1[0.7539] at fold[2]\n","______________________________________________________\n","Start Training\n","Accuracy[0.7707] Recall[0.7587] F1[0.7177] at fold[3]\n","______________________________________________________\n","Start Training\n","Accuracy[0.7849] Recall[0.7369] F1[0.6947] at fold[4]\n","______________________________________________________\n","Start Training\n","Epoch 00054: early stopping THR\n","Accuracy[0.7273] Recall[0.6814] F1[0.6184] at fold[5]\n","______________________________________________________\n","Start Training\n","Epoch 00066: early stopping THR\n","Accuracy[0.7589] Recall[0.7285] F1[0.7105] at fold[6]\n","______________________________________________________\n","Start Training\n","Accuracy[0.8326] Recall[0.8519] F1[0.8151] at fold[7]\n","______________________________________________________\n","Start Training\n","Epoch 00065: early stopping THR\n","Accuracy[0.6335] Recall[0.6306] F1[0.5787] at fold[8]\n","______________________________________________________\n","Start Training\n","Epoch 00074: early stopping THR\n","Accuracy[0.6532] Recall[0.6220] F1[0.6196] at fold[9]\n","______________________________________________________\n","Mean Accuracy[0.7569] IC [0.7150, 0.7988]\n","Mean Recall[0.7401] IC [0.6922, 0.7881]\n","Mean F1[0.7108] IC [0.6587, 0.7629]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Wo4mPGQSTcL","colab_type":"code","outputId":"4e302e2e-d9c0-467e-eb42-acbd8c0f8d30","executionInfo":{"status":"ok","timestamp":1584865031151,"user_tz":-120,"elapsed":508697,"user":{"displayName":"Rana mostafa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpLWLhJYcXKOOp7sprSKwnxN-x9hYM61yh__9kww=s64","userId":"07598775866819373078"}},"colab":{"base_uri":"https://localhost:8080/","height":625}},"source":["Run('data/LOTO/MHEALTH.npz')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Start Training\n","Epoch 00070: early stopping THR\n","Accuracy[0.6953] Recall[0.6797] F1[0.6700] at fold[0]\n","______________________________________________________\n","Start Training\n","Accuracy[0.7977] Recall[0.7463] F1[0.7131] at fold[1]\n","______________________________________________________\n","Start Training\n","Accuracy[0.7463] Recall[0.7355] F1[0.6710] at fold[2]\n","______________________________________________________\n","Start Training\n","Epoch 00060: early stopping THR\n","Accuracy[0.7137] Recall[0.7123] F1[0.6922] at fold[3]\n","______________________________________________________\n","Start Training\n","Accuracy[0.8745] Recall[0.8283] F1[0.8164] at fold[4]\n","______________________________________________________\n","Start Training\n","Accuracy[0.8945] Recall[0.8713] F1[0.8459] at fold[5]\n","______________________________________________________\n","Start Training\n","Accuracy[0.8000] Recall[0.7526] F1[0.7195] at fold[6]\n","______________________________________________________\n","Start Training\n","Accuracy[0.7729] Recall[0.7284] F1[0.6898] at fold[7]\n","______________________________________________________\n","Start Training\n","Accuracy[0.7875] Recall[0.7841] F1[0.7521] at fold[8]\n","______________________________________________________\n","Start Training\n","Accuracy[0.5833] Recall[0.5646] F1[0.4854] at fold[9]\n","______________________________________________________\n","Mean Accuracy[0.7666] IC [0.7146, 0.8186]\n","Mean Recall[0.7403] IC [0.6920, 0.7886]\n","Mean F1[0.7055] IC [0.6490, 0.7621]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vSbkzIfEdYmI","colab_type":"code","outputId":"d3ef7e98-4899-4675-8ec5-d98a73be3c4e","executionInfo":{"status":"ok","timestamp":1584867770754,"user_tz":-120,"elapsed":328802,"user":{"displayName":"Rana mostafa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpLWLhJYcXKOOp7sprSKwnxN-x9hYM61yh__9kww=s64","userId":"07598775866819373078"}},"colab":{"base_uri":"https://localhost:8080/","height":746}},"source":["Run('data/SNOW/MHEALTH.npz')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Start Training\n","Epoch 00071: early stopping THR\n","Accuracy[0.8566] Recall[0.8323] F1[0.8400] at fold[0]\n","______________________________________________________\n","Start Training\n","Accuracy[0.8359] Recall[0.7883] F1[0.7508] at fold[1]\n","______________________________________________________\n","Start Training\n","Epoch 00063: early stopping THR\n","Accuracy[0.8633] Recall[0.8553] F1[0.8459] at fold[2]\n","______________________________________________________\n","Start Training\n","Epoch 00078: early stopping THR\n","Accuracy[0.8477] Recall[0.8239] F1[0.8235] at fold[3]\n","______________________________________________________\n","Start Training\n","Epoch 00062: early stopping THR\n","Accuracy[0.8196] Recall[0.8201] F1[0.8069] at fold[4]\n","______________________________________________________\n","Start Training\n","Epoch 00053: early stopping THR\n","Accuracy[0.8824] Recall[0.8557] F1[0.8593] at fold[5]\n","______________________________________________________\n","Start Training\n","Epoch 00068: early stopping THR\n","Accuracy[0.8039] Recall[0.7812] F1[0.7808] at fold[6]\n","______________________________________________________\n","Start Training\n","Epoch 00050: early stopping THR\n","Accuracy[0.8549] Recall[0.8360] F1[0.8408] at fold[7]\n","______________________________________________________\n","Start Training\n","Epoch 00066: early stopping THR\n","Accuracy[0.8902] Recall[0.8797] F1[0.8792] at fold[8]\n","______________________________________________________\n","Start Training\n","Epoch 00082: early stopping THR\n","Accuracy[0.8228] Recall[0.8152] F1[0.8124] at fold[9]\n","______________________________________________________\n","Mean Accuracy[0.8477] IC [0.8317, 0.8637]\n","Mean Recall[0.8288] IC [0.8112, 0.8463]\n","Mean F1[0.8239] IC [0.8019, 0.8459]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eemWhQfcdcp2","colab_type":"code","outputId":"44ca8e3d-a231-4c69-91dc-7bafe53b92af","executionInfo":{"status":"ok","timestamp":1584869415534,"user_tz":-120,"elapsed":362139,"user":{"displayName":"Rana mostafa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpLWLhJYcXKOOp7sprSKwnxN-x9hYM61yh__9kww=s64","userId":"07598775866819373078"}},"colab":{"base_uri":"https://localhost:8080/","height":625}},"source":["Run('data/FNOW/MHEALTH.npz')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Start Training\n","Epoch 00097: early stopping THR\n","Accuracy[0.7407] Recall[0.7386] F1[0.7297] at fold[0]\n","______________________________________________________\n","Start Training\n","Epoch 00095: early stopping THR\n","Accuracy[0.8741] Recall[0.8807] F1[0.8810] at fold[1]\n","______________________________________________________\n","Start Training\n","Accuracy[0.7463] Recall[0.7159] F1[0.6848] at fold[2]\n","______________________________________________________\n","Start Training\n","Accuracy[0.8134] Recall[0.7689] F1[0.7284] at fold[3]\n","______________________________________________________\n","Start Training\n","Accuracy[0.8060] Recall[0.7588] F1[0.7511] at fold[4]\n","______________________________________________________\n","Start Training\n","Accuracy[0.7970] Recall[0.7544] F1[0.7189] at fold[5]\n","______________________________________________________\n","Start Training\n","Accuracy[0.7970] Recall[0.7816] F1[0.7569] at fold[6]\n","______________________________________________________\n","Start Training\n","Accuracy[0.8421] Recall[0.7973] F1[0.7559] at fold[7]\n","______________________________________________________\n","Start Training\n","Accuracy[0.7500] Recall[0.7047] F1[0.6668] at fold[8]\n","______________________________________________________\n","Start Training\n","Accuracy[0.8182] Recall[0.8280] F1[0.7886] at fold[9]\n","______________________________________________________\n","Mean Accuracy[0.7985] IC [0.7735, 0.8234]\n","Mean Recall[0.7729] IC [0.7424, 0.8034]\n","Mean F1[0.7462] IC [0.7119, 0.7806]\n"],"name":"stdout"}]}]}