{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F3GYNEuUjLGV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import zipfile\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pickle as cp\n",
    "\n",
    "from io import BytesIO\n",
    "from pandas import Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1585584846249,
     "user": {
      "displayName": "brain pinky",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64",
      "userId": "06438107502629971890"
     },
     "user_tz": -120
    },
    "id": "awgYS4JMjQaS",
    "outputId": "ee5a3f6e-81dd-44a6-937b-0a597cebcd17"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26682,
     "status": "ok",
     "timestamp": 1585508452731,
     "user": {
      "displayName": "brain pinky",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64",
      "userId": "06438107502629971890"
     },
     "user_tz": -120
    },
    "id": "nvmAC3cijR8-",
    "outputId": "e70b0ba2-a660-4e70-bb83-0b419bd6f404"
   },
   "outputs": [],
   "source": [
    "!unzip '/content/drive/My Drive/Computer_vision_project/data/Opportunity/OpportunityUCIDataset.zip' -d '/content/drive/My Drive/Computer_vision_project/data/Opportunity/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iVeC9xhqjiPc"
   },
   "outputs": [],
   "source": [
    "NB_SENSOR_CHANNELS = 113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IoOFiaT2kNJO"
   },
   "outputs": [],
   "source": [
    "# Hardcoded names of the files defining the OPPORTUNITY challenge data. As named in the original data.\n",
    "OPPORTUNITY_DATA_FILES = ['OpportunityUCIDataset/dataset/S1-Drill.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S1-ADL1.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S1-ADL2.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S1-ADL3.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S1-ADL4.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S1-ADL5.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S2-Drill.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S2-ADL1.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S2-ADL2.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S2-ADL3.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S3-Drill.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S3-ADL1.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S3-ADL2.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S3-ADL3.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S2-ADL4.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S2-ADL5.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S3-ADL4.dat',\n",
    "                          'OpportunityUCIDataset/dataset/S3-ADL5.dat'\n",
    "                          ]\n",
    "\n",
    "# Hardcoded thresholds to define global maximums and minimums for every one of the 113 sensor channels employed in the\n",
    "# OPPORTUNITY challenge\n",
    "NORM_MAX_THRESHOLDS = [3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,\n",
    "                       3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,\n",
    "                       3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,\n",
    "                       3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,\n",
    "                       3000,   3000,   3000,   10000,  10000,  10000,  1500,   1500,   1500,\n",
    "                       3000,   3000,   3000,   10000,  10000,  10000,  1500,   1500,   1500,\n",
    "                       3000,   3000,   3000,   10000,  10000,  10000,  1500,   1500,   1500,\n",
    "                       3000,   3000,   3000,   10000,  10000,  10000,  1500,   1500,   1500,\n",
    "                       3000,   3000,   3000,   10000,  10000,  10000,  1500,   1500,   1500,\n",
    "                       250,    25,     200,    5000,   5000,   5000,   5000,   5000,   5000,\n",
    "                       10000,  10000,  10000,  10000,  10000,  10000,  250,    250,    25,\n",
    "                       200,    5000,   5000,   5000,   5000,   5000,   5000,   10000,  10000,\n",
    "                       10000,  10000,  10000,  10000,  250, ]\n",
    "\n",
    "NORM_MIN_THRESHOLDS = [-3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,\n",
    "                       -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,\n",
    "                       -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,\n",
    "                       -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,\n",
    "                       -3000,  -3000,  -3000,  -10000, -10000, -10000, -1000,  -1000,  -1000,\n",
    "                       -3000,  -3000,  -3000,  -10000, -10000, -10000, -1000,  -1000,  -1000,\n",
    "                       -3000,  -3000,  -3000,  -10000, -10000, -10000, -1000,  -1000,  -1000,\n",
    "                       -3000,  -3000,  -3000,  -10000, -10000, -10000, -1000,  -1000,  -1000,\n",
    "                       -3000,  -3000,  -3000,  -10000, -10000, -10000, -1000,  -1000,  -1000,\n",
    "                       -250,   -100,   -200,   -5000,  -5000,  -5000,  -5000,  -5000,  -5000,\n",
    "                       -10000, -10000, -10000, -10000, -10000, -10000, -250,   -250,   -100,\n",
    "                       -200,   -5000,  -5000,  -5000,  -5000,  -5000,  -5000,  -10000, -10000,\n",
    "                       -10000, -10000, -10000, -10000, -250, ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "85kW2NvXkST4"
   },
   "outputs": [],
   "source": [
    "def select_columns_opp(data):\n",
    "    \"\"\"Selection of the 113 columns employed in the OPPORTUNITY challenge\n",
    "    :param data: numpy integer matrix\n",
    "        Sensor data (all features)\n",
    "    :return: numpy integer matrix\n",
    "        Selection of features\n",
    "    \"\"\"\n",
    "\n",
    "    #                     included-excluded\n",
    "    features_delete = np.arange(46, 50)\n",
    "    features_delete = np.concatenate([features_delete, np.arange(59, 63)])\n",
    "    features_delete = np.concatenate([features_delete, np.arange(72, 76)])\n",
    "    features_delete = np.concatenate([features_delete, np.arange(85, 89)])\n",
    "    features_delete = np.concatenate([features_delete, np.arange(98, 102)])\n",
    "    features_delete = np.concatenate([features_delete, np.arange(134, 243)])\n",
    "    features_delete = np.concatenate([features_delete, np.arange(244, 249)])\n",
    "    return np.delete(data, features_delete, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PVzY5LpmkWXI"
   },
   "outputs": [],
   "source": [
    "def normalize(data, max_list, min_list):\n",
    "    \"\"\"Normalizes all sensor channels\n",
    "    :param data: numpy integer matrix\n",
    "        Sensor data\n",
    "    :param max_list: numpy integer array\n",
    "        Array containing maximums values for every one of the 113 sensor channels\n",
    "    :param min_list: numpy integer array\n",
    "        Array containing minimum values for every one of the 113 sensor channels\n",
    "    :return:\n",
    "        Normalized sensor data\n",
    "    \"\"\"\n",
    "    max_list, min_list = np.array(max_list), np.array(min_list)\n",
    "    diffs = max_list - min_list\n",
    "    for i in np.arange(data.shape[1]):\n",
    "        data[:, i] = (data[:, i]-min_list[i])/diffs[i]\n",
    "    #     Checking the boundaries\n",
    "    data[data > 1] = 0.99\n",
    "    data[data < 0] = 0.00\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L4gaKF0YkY6J"
   },
   "outputs": [],
   "source": [
    "def divide_x_y(data, label):\n",
    "    \"\"\"Segments each sample into features and label\n",
    "    :param data: numpy integer matrix\n",
    "        Sensor data\n",
    "    :param label: string, ['gestures' (default), 'locomotion']\n",
    "        Type of activities to be recognized\n",
    "    :return: numpy integer matrix, numpy integer array\n",
    "        Features encapsulated into a matrix and labels as an array\n",
    "    \"\"\"\n",
    "\n",
    "    data_x = data[:, 1:114]\n",
    "    if label not in ['locomotion', 'gestures']:\n",
    "            raise RuntimeError(\"Invalid label: '%s'\" % label)\n",
    "    if label == 'locomotion':\n",
    "        data_y = data[:, 114]  # Locomotion label\n",
    "    elif label == 'gestures':\n",
    "        data_y = data[:, 115]  # Gestures label\n",
    "\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpoEZEW5kcSp"
   },
   "outputs": [],
   "source": [
    "def adjust_idx_labels(data_y, label):\n",
    "    \"\"\"Transforms original labels into the range [0, nb_labels-1]\n",
    "    :param data_y: numpy integer array\n",
    "        Sensor labels\n",
    "    :param label: string, ['gestures' (default), 'locomotion']\n",
    "        Type of activities to be recognized\n",
    "    :return: numpy integer array\n",
    "        Modified sensor labels\n",
    "    \"\"\"\n",
    "\n",
    "    if label == 'locomotion':  # Labels for locomotion are adjusted\n",
    "        data_y[data_y == 4] = 3\n",
    "        data_y[data_y == 5] = 4\n",
    "    elif label == 'gestures':  # Labels for gestures are adjusted\n",
    "        data_y[data_y == 406516] = 1\n",
    "        data_y[data_y == 406517] = 2\n",
    "        data_y[data_y == 404516] = 3\n",
    "        data_y[data_y == 404517] = 4\n",
    "        data_y[data_y == 406520] = 5\n",
    "        data_y[data_y == 404520] = 6\n",
    "        data_y[data_y == 406505] = 7\n",
    "        data_y[data_y == 404505] = 8\n",
    "        data_y[data_y == 406519] = 9\n",
    "        data_y[data_y == 404519] = 10\n",
    "        data_y[data_y == 406511] = 11\n",
    "        data_y[data_y == 404511] = 12\n",
    "        data_y[data_y == 406508] = 13\n",
    "        data_y[data_y == 404508] = 14\n",
    "        data_y[data_y == 408512] = 15\n",
    "        data_y[data_y == 407521] = 16\n",
    "        data_y[data_y == 405506] = 17\n",
    "    return data_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FA6x_g6zl72N"
   },
   "outputs": [],
   "source": [
    "def check_data(data_set):\n",
    "    \"\"\"Try to access to the file and checks if dataset is in the data directory\n",
    "       In case the file is not found try to download it from original location\n",
    "    :param data_set:\n",
    "            Path with original OPPORTUNITY zip file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print ('Checking dataset {0}'.format(data_set))\n",
    "    data_dir, data_file = os.path.split(data_set)\n",
    "    # When a directory is not provided, check if dataset is in the data directory\n",
    "    if data_dir == \"\" and not os.path.isfile(data_set):\n",
    "        new_path = os.path.join(os.path.split(__file__)[0], \"data\", data_set)\n",
    "        if os.path.isfile(new_path) or data_file == 'OpportunityUCIDataset.zip':\n",
    "            data_set = new_path\n",
    "\n",
    "    # When dataset not found, try to download it from UCI repository\n",
    "    if (not os.path.isfile(data_set)) and data_file == 'OpportunityUCIDataset.zip':\n",
    "        print ('... dataset path {0} not found'.format(data_set))\n",
    "        import urllib\n",
    "        origin = (\n",
    "            'https://archive.ics.uci.edu/ml/machine-learning-databases/00226/OpportunityUCIDataset.zip'\n",
    "        )\n",
    "        if not os.path.exists(data_dir):\n",
    "            print ('... creating directory {0}'.format(data_dir))\n",
    "            os.makedirs(data_dir)\n",
    "        print ('... downloading data from {0}'.format(origin))\n",
    "        urllib.urlretrieve(origin, data_set)\n",
    "\n",
    "    return data_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVriZoyXmEhK"
   },
   "outputs": [],
   "source": [
    "def process_dataset_file(data, label):\n",
    "    \"\"\"Function defined as a pipeline to process individual OPPORTUNITY files\n",
    "    :param data: numpy integer matrix\n",
    "        Matrix containing data samples (rows) for every sensor channel (column)\n",
    "    :param label: string, ['gestures' (default), 'locomotion']\n",
    "        Type of activities to be recognized\n",
    "    :return: numpy integer matrix, numy integer array\n",
    "        Processed sensor data, segmented into features (x) and labels (y)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select correct columns\n",
    "    data = select_columns_opp(data)\n",
    "\n",
    "    # Colums are segmentd into features and labels\n",
    "    data_x, data_y =  divide_x_y(data, label)\n",
    "    data_y = adjust_idx_labels(data_y, label)\n",
    "    data_y = data_y.astype(int)\n",
    "\n",
    "    # Perform linear interpolation\n",
    "    data_x = np.array([Series(i).interpolate() for i in data_x.T]).T\n",
    "\n",
    "    # Remaining missing data are converted to zero\n",
    "    data_x[np.isnan(data_x)] = 0\n",
    "\n",
    "    # All sensor channels are normalized\n",
    "    data_x = normalize(data_x, NORM_MAX_THRESHOLDS, NORM_MIN_THRESHOLDS)\n",
    "\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGK3icVomJdB"
   },
   "outputs": [],
   "source": [
    "def generate_data(dataset, target_filename, label):\n",
    "    \"\"\"Function to read the OPPORTUNITY challenge raw data and process all sensor channels\n",
    "    :param dataset: string\n",
    "        Path with original OPPORTUNITY zip file\n",
    "    :param target_filename: string\n",
    "        Processed file\n",
    "    :param label: string, ['gestures' (default), 'locomotion']\n",
    "        Type of activities to be recognized. The OPPORTUNITY dataset includes several annotations to perform\n",
    "        recognition modes of locomotion/postures and recognition of sporadic gestures.\n",
    "    \"\"\"\n",
    "\n",
    "    data_dir = check_data(dataset)\n",
    "\n",
    "    data_x = np.empty((0, NB_SENSOR_CHANNELS))\n",
    "    data_y = np.empty((0))\n",
    "\n",
    "    zf = zipfile.ZipFile(dataset)\n",
    "    print ('Processing dataset files ...')\n",
    "    for filename in OPPORTUNITY_DATA_FILES:\n",
    "        try:\n",
    "            data = np.loadtxt(BytesIO(zf.read(filename)))\n",
    "            print ('... file {0}'.format(filename))\n",
    "            x, y = process_dataset_file(data, label)\n",
    "            data_x = np.vstack((data_x, x))\n",
    "            data_y = np.concatenate([data_y, y])\n",
    "        except KeyError:\n",
    "            print ('ERROR: Did not find {0} in zip file'.format(filename))\n",
    "\n",
    "    # Dataset is segmented into train and test\n",
    "    nb_training_samples = 557963\n",
    "    # The first 18 OPPORTUNITY data files define the traning dataset, comprising 557963 samples\n",
    "    X_train, y_train = data_x[:nb_training_samples,:], data_y[:nb_training_samples]\n",
    "    X_test, y_test = data_x[nb_training_samples:,:], data_y[nb_training_samples:]\n",
    "\n",
    "    print (\"Final datasets with size: | train {0} | test {1} | \".format(X_train.shape,X_test.shape))\n",
    "\n",
    "    obj = [(X_train, y_train), (X_test, y_test)]\n",
    "    f = open(target_filename,'wb')\n",
    "    cp.dump(obj, f, protocol=cp.HIGHEST_PROTOCOL)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 118768,
     "status": "ok",
     "timestamp": 1585584992371,
     "user": {
      "displayName": "brain pinky",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64",
      "userId": "06438107502629971890"
     },
     "user_tz": -120
    },
    "id": "ESgVO1qxmdcN",
    "outputId": "e7e180cf-0885-4653-94ac-a31cbfdfce99"
   },
   "outputs": [],
   "source": [
    "generate_data('/content/drive/My Drive/Computer_vision_project/data/Opportunity/OpportunityUCIDataset.zip', '/content/drive/My Drive/Computer_vision_project/data/Opportunity/Data_set.txt', 'locomotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "syJ1KRGhnKQx"
   },
   "outputs": [],
   "source": [
    "NB_SENSOR_CHANNELS = 113\n",
    "NB_SENSOR_CHANNELS_WITH_FILTERING = 149\n",
    "\n",
    "# Hardcoded number of classes in the gesture recognition problem\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "# Hardcoded length of the sliding window mechanism employed to segment the data\n",
    "SLIDING_WINDOW_LENGTH = 24\n",
    "\n",
    "# Length of the input sequence after convolutional operations\n",
    "FINAL_SEQUENCE_LENGTH = 8\n",
    "\n",
    "# Hardcoded step of the sliding window mechanism employed to segment the data\n",
    "SLIDING_WINDOW_STEP = int(SLIDING_WINDOW_LENGTH/2)\n",
    "SLIDING_WINDOW_STEP_SHORT = SLIDING_WINDOW_STEP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rmS-xedDnMhT"
   },
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "\n",
    "    f = open(filename, 'rb')\n",
    "    data = cp.load(f)\n",
    "    f.close()\n",
    "\n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "\n",
    "    print(\" ..from file {}\".format(filename))\n",
    "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    # The targets are casted to int8 for GPU compatibility.\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_test = y_test.astype(np.uint8)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GM78BbOunafZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided as ast\n",
    "\n",
    "def norm_shape(shape):\n",
    "    '''\n",
    "    Normalize numpy array shapes so they're always expressed as a tuple,\n",
    "    even for one-dimensional shapes.\n",
    "    Parameters\n",
    "        shape - an int, or a tuple of ints\n",
    "    Returns\n",
    "        a shape tuple\n",
    "    '''\n",
    "    try:\n",
    "        i = int(shape)\n",
    "        return (i,)\n",
    "    except TypeError:\n",
    "        # shape was not a number\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        t = tuple(shape)\n",
    "        return t\n",
    "    except TypeError:\n",
    "        # shape was not iterable\n",
    "        pass\n",
    "\n",
    "    raise TypeError('shape must be an int, or a tuple of ints')\n",
    "\n",
    "def sliding_window(a,ws,ss = None,flatten = True):\n",
    "    '''\n",
    "    Return a sliding window over a in any number of dimensions\n",
    "    Parameters:\n",
    "        a  - an n-dimensional numpy array\n",
    "        ws - an int (a is 1D) or tuple (a is 2D or greater) representing the size\n",
    "             of each dimension of the window\n",
    "        ss - an int (a is 1D) or tuple (a is 2D or greater) representing the\n",
    "             amount to slide the window in each dimension. If not specified, it\n",
    "             defaults to ws.\n",
    "        flatten - if True, all slices are flattened, otherwise, there is an\n",
    "                  extra dimension for each dimension of the input.\n",
    "    Returns\n",
    "        an array containing each n-dimensional window from a\n",
    "    '''\n",
    "\n",
    "    if None is ss:\n",
    "        # ss was not provided. the windows will not overlap in any direction.\n",
    "        ss = ws\n",
    "    ws = norm_shape(ws)\n",
    "    ss = norm_shape(ss)\n",
    "\n",
    "    # convert ws, ss, and a.shape to numpy arrays so that we can do math in every\n",
    "    # dimension at once.\n",
    "    ws = np.array(ws)\n",
    "    ss = np.array(ss)\n",
    "    shape = np.array(a.shape)\n",
    "\n",
    "\n",
    "    # ensure that ws, ss, and a.shape all have the same number of dimensions\n",
    "    ls = [len(shape),len(ws),len(ss)]\n",
    "    if 1 != len(set(ls)):\n",
    "        raise ValueError(\\\n",
    "        'a.shape, ws and ss must all have the same length. They were %s' % str(ls))\n",
    "\n",
    "    # ensure that ws is smaller than a in every dimension\n",
    "    if np.any(ws > shape):\n",
    "        raise ValueError(\\\n",
    "        'ws cannot be larger than a in any dimension.\\\n",
    " a.shape was %s and ws was %s' % (str(a.shape),str(ws)))\n",
    "\n",
    "    # how many slices will there be in each dimension?\n",
    "    newshape = norm_shape(((shape - ws) // ss) + 1)\n",
    "    # the shape of the strided array will be the number of slices in each dimension\n",
    "    # plus the shape of the window (tuple addition)\n",
    "    newshape += norm_shape(ws)\n",
    "    # the strides tuple will be the array's strides multiplied by step size, plus\n",
    "    # the array's strides (tuple addition)\n",
    "    newstrides = norm_shape(np.array(a.strides) * ss) + a.strides\n",
    "    strided = ast(a,shape = newshape,strides = newstrides)\n",
    "    if not flatten:\n",
    "        return strided\n",
    "\n",
    "    # Collapse strided so that it has one more dimension than the window.  I.e.,\n",
    "    # the new array is a flat list of slices.\n",
    "    meat = len(ws) if ws.shape else 0\n",
    "    firstdim = (np.product(newshape[:-meat]),) if ws.shape else ()\n",
    "    dim = firstdim + (newshape[-meat:])\n",
    "    # remove any dimensions with size 1\n",
    "    \n",
    "    dim = filter(lambda i : i != 1,dim)\n",
    "    # print('dim',list(dim))\n",
    "    dimm_=list(dim)\n",
    "    \n",
    "    # print('strided',strided)\n",
    "    print(dimm_)\n",
    "    return strided.reshape(tuple(dimm_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1855,
     "status": "ok",
     "timestamp": 1585584995224,
     "user": {
      "displayName": "brain pinky",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64",
      "userId": "06438107502629971890"
     },
     "user_tz": -120
    },
    "id": "FbphY2QbnRGv",
    "outputId": "e65508da-133c-4469-9779-c06adca2b244"
   },
   "outputs": [],
   "source": [
    "print(\"Loading data...\")\n",
    "X_train, y_train, X_test, y_test = load_dataset('/content/drive/My Drive/Computer_vision_project/data/Opportunity/Data_set.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNHyEmFJd-je"
   },
   "outputs": [],
   "source": [
    "def one_hot(y):\n",
    "    \"\"\"convert label from dense to one hot\n",
    "      argument:\n",
    "        label: ndarray dense label ,shape: [sample_num,1]\n",
    "      return:\n",
    "        one_hot_label: ndarray  one hot, shape: [sample_num,n_class]\n",
    "    \"\"\"\n",
    "    # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
    "\n",
    "    y = y.reshape(len(y))\n",
    "    n_values = np.max(y) + 1\n",
    "    return np.eye(n_values)[np.array(y, dtype=np.int32)]  # Returns FLOATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0FdXbOxcnUDm"
   },
   "outputs": [],
   "source": [
    "assert (NB_SENSOR_CHANNELS_WITH_FILTERING == X_train.shape[1] or NB_SENSOR_CHANNELS == X_train.shape[1])\n",
    "\n",
    "def opp_sliding_window(data_x, data_y, ws, ss):\n",
    "    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
    "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
    "    data_x,data_y = data_x.astype(np.float32),one_hot(data_y.reshape(len(data_y)).astype(np.uint8))\n",
    "    # print(\" ..after sliding window (testing): inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 716,
     "status": "ok",
     "timestamp": 1585584996763,
     "user": {
      "displayName": "brain pinky",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64",
      "userId": "06438107502629971890"
     },
     "user_tz": -120
    },
    "id": "OIrFZUQ9nWwv",
    "outputId": "03b5f74c-2dcb-43cb-b471-2d8175413a02"
   },
   "outputs": [],
   "source": [
    "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP_SHORT)\n",
    "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WlH9vxV7wvz1"
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('/content/drive/My Drive/Computer_vision_project/data/Opportunity/Opportunity_train_X.npz', X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1692,
     "status": "ok",
     "timestamp": 1585585031697,
     "user": {
      "displayName": "brain pinky",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSJ-MfHyLlQ17ipaf3IqBsqmMEcsDxuSrwhgT_Ng=s64",
      "userId": "06438107502629971890"
     },
     "user_tz": -120
    },
    "id": "BHBtHgiROCKF",
    "outputId": "e7bfeece-43eb-49ec-ec28-b4ae10e4da85"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqWwK8CWw-3F"
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('/content/drive/My Drive/Computer_vision_project/data/Opportunity/Opportunity_train_y.npz', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ponMBw8vxBQ5"
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('/content/drive/My Drive/Computer_vision_project/data/Opportunity/Opportunity_test_X.npz', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9WOp7zUxCZp"
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('/content/drive/My Drive/Computer_vision_project/data/Opportunity/Opportunity_test_Y.npz', y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPFuu1bLKLYNW1PGOm3lw8x",
   "collapsed_sections": [],
   "name": "OpportunityUCIDataset.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
